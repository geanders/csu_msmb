<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chapter 5 | CSU MSMB Group Study</title>
    <link>/tags/chapter-5/</link>
      <atom:link href="/tags/chapter-5/index.xml" rel="self" type="application/rss+xml" />
    <description>Chapter 5</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 12 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Chapter 5</title>
      <link>/tags/chapter-5/</link>
    </image>
    
    <item>
      <title>Exercise Solution for 5.1</title>
      <link>/post/exercise-solution-for-5-1/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-5-1/</guid>
      <description>


&lt;p&gt;This exercise asks us to interpret and validate the consistency within our clusters of data. To do this, we will employ the silhouette index, which gives us a silhouette value measuring how similar an object is to its own cluster compared to other clusters.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;silhouette index&lt;/strong&gt; is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\displaystyle S(i) = \frac{B(i) - A(i)}{max_i(A(i), B(i))} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The book explains the equation by first defining that the average dissimilarity of a point &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to a cluster &lt;span class=&#34;math inline&#34;&gt;\(C_k\)&lt;/span&gt; is the average of the distances from &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to all of the points in &lt;span class=&#34;math inline&#34;&gt;\(C_k\)&lt;/span&gt;. From this, let &lt;span class=&#34;math inline&#34;&gt;\(A(i)\)&lt;/span&gt; be the average dissimlarity of all points in the cluster that &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; belongs to, and &lt;span class=&#34;math inline&#34;&gt;\(B(i)\)&lt;/span&gt; is the lowest average of dissimlarity of &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to any other cluster of which &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is NOT a member.Basically, we are subtracting the mean distance to other instances in the same cluster from the mean distance to the instances of the next closest cluster, and dividing it by which of the two values is larger. The output is a coefficient that will vary between -1 and 1, where a value closer to 1 implies that the instance is closest to the correct cluster.&lt;/p&gt;
&lt;p&gt;The solution to this exercise requires the following R packages to be loaded into your environment.&lt;/p&gt;
&lt;div id=&#34;required-libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Required Libraries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cluster)
library(dplyr)
library(ggplot2)
library(purrr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;part-a&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part A&lt;/h2&gt;
&lt;p&gt;Question 5.1.a asks us to compute the silhouette index for the &lt;code&gt;simdat&lt;/code&gt; data that was simulated in Section &lt;strong&gt;5.7&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The provided code is used to simulate data coming from four separate groups. They use the pipe operator to concatenate four different, randomly generated, data sets. The &lt;code&gt;ggplot2&lt;/code&gt; package is used to take a look at the data as a barchart of the within-groups sum of squared distances (WSS) obtained from the &lt;em&gt;k&lt;/em&gt; means method.&lt;/p&gt;
&lt;p&gt;First off, we need to set the seed to ensure reproducible results with a randomly generated data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following chunk of code utilizes the &lt;code&gt;lapply&lt;/code&gt; function two times to generate a datset with four distinct clusters. The &lt;code&gt;lapply&lt;/code&gt; function comes from base R, and is most often used to apply a function over an entire list or vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)


simdat = lapply(c(0, 8), function(mx) {
  lapply(c(0,8), function(my) {
    
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
   }) %&amp;gt;% bind_rows
}) %&amp;gt;% bind_rows

simdatxy = simdat[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)] # data without class label&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The technique the authors used to generate a clustered dataset is tricky. The &lt;code&gt;lapply&lt;/code&gt; within an &lt;code&gt;lapply&lt;/code&gt;, paired with two &lt;code&gt;bind_rows&lt;/code&gt; functions can be confusing. The next sections are included to demonstrate what the data looks like through various steps in this process, and help bring understanding to the reader how the code is working.&lt;/p&gt;
&lt;div id=&#34;the-inner-lapply-function&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The inner &lt;code&gt;lapply&lt;/code&gt; function&lt;/h4&gt;
&lt;p&gt;The first &lt;code&gt;lapply&lt;/code&gt; is generating a vector of n = 100 normally distributed random numbers, and creating two separate dataframes packed into a list that consist of the mean (&lt;code&gt;my&lt;/code&gt;) and standard deviation, respectively. Each individual value is specifically assigned a 0 or an 8.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simdatmy = lapply(c(0,8), function(my) {
    
    tibble(y = rnorm(100, mean = my, sd = 2),
           class = paste(my, sep = &amp;quot;:&amp;quot;))
   })
summary(simdatmy)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Length Class  Mode
## [1,] 2      tbl_df list
## [2,] 2      tbl_df list&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-outer-lapply-function&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The outer &lt;code&gt;lapply&lt;/code&gt; function&lt;/h4&gt;
&lt;p&gt;The second (outer) &lt;code&gt;lapply&lt;/code&gt; uses the same idea to apply the same, random, 0 or 8 assignment to values in the &lt;code&gt;mx&lt;/code&gt; function. The ouput is now four separate dataframes within a list that contain all of the &lt;code&gt;mx&lt;/code&gt; data and all of the &lt;code&gt;my&lt;/code&gt; data. Within the &lt;code&gt;tibble&lt;/code&gt; function, they include the code &lt;code&gt;class =&lt;/code&gt; to ensure that each row in each of the 4 the lists is assigned one of the four possible two-way combinations of 0 and 8. This is important to simulate a clustered dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simdatmx = lapply(c(0, 8), function(mx) {
  lapply(c(0,8), function(my) {
    
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
    })})
summary(simdatmx)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Length Class  Mode
## [1,] 2      -none- list
## [2,] 2      -none- list&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-together&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Putting it together&lt;/h4&gt;
&lt;p&gt;The last step is to bind the list of dataframes into one single dataframe. The final dataframe includes all of the x and y data, each with assigned classes, defined by a combination of 0 and 8.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)


simdat = lapply(c(0, 8), function(mx) {
  lapply(c(0,8), function(my) {
    
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
   }) %&amp;gt;% bind_rows
}) %&amp;gt;% bind_rows

head(simdat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##        x       y class
##    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 -1.25  -1.24   0:0  
## 2  0.367  0.0842 0:0  
## 3 -1.67  -1.82   0:0  
## 4  3.19   0.316  0:0  
## 5  0.659 -1.31   0:0  
## 6 -1.64   3.53   0:0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unique(simdat$class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;0:0&amp;quot; &amp;quot;0:8&amp;quot; &amp;quot;8:0&amp;quot; &amp;quot;8:8&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final &lt;code&gt;simdat&lt;/code&gt; dataframe includes 400 random points witih an assigned class to simulate clustering. We can look at the data using a simple &lt;code&gt;ggplot&lt;/code&gt; scatterplot, color coded by the class of each point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(simdat, aes(x = x, y = y, color = class)) + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The next part of exploring the data is to compute the within-groups sum of squares (WSS) for the clusters that we just generated. The goal of this section is to observe how the WSS changes as the number of clusters is increased from 1 to 8 when using the k-means. Chapter 5 provides us with the following code and graph:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#1
wss = tibble(k = 1:8, value = NA_real_)

#2
wss$value[1] = sum(scale(simdatxy, scale = FALSE)^2)

#3
for (i in 2:nrow(wss)) {
  km  = kmeans(simdatxy, centers = wss$k[i])
  wss$value[i] = sum(km$withinss)
}

ggplot(wss, aes(x = k, y = value)) + geom_col()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What is really going on here?&lt;/p&gt;
&lt;p&gt;This first chunk is setting up a one-column dataframe with blank &lt;code&gt;NA&lt;/code&gt; values. The &lt;code&gt;NA&lt;/code&gt;s will be filled in with values as the rest of the code processes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#1
wss = tibble(k = 1:8, value = NA_real_)
wss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##       k value
##   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1    NA
## 2     2    NA
## 3     3    NA
## 4     4    NA
## 5     5    NA
## 6     6    NA
## 7     7    NA
## 8     8    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second chunk of code is calculating the value for k = 1 individually. They use the &lt;code&gt;scale&lt;/code&gt; function to scale down the value for k = 1 because it is so much larger than the rest of the k-values. Without scaling down the k = 1 value, it would be difficult to observe any sharp decreases that might indicate a “potential sweet spot” for the number of clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#2
wss$value[1] = sum(scale(simdatxy, scale = FALSE)^2)
wss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##       k  value
##   &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1 15781.
## 2     2    NA 
## 3     3    NA 
## 4     4    NA 
## 5     5    NA 
## 6     6    NA 
## 7     7    NA 
## 8     8    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last part of this chunk is running a k-means clustering on the remaining k 2 through 8 and then pulling out the &lt;code&gt;withinss&lt;/code&gt; value for all of the observations, summing it, and assigning that value to each individual k-value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#3
for (i in 2:nrow(wss)) {
  km  = kmeans(simdatxy, centers = wss$k[i])
  wss$value[i] = sum(km$withinss)
}

km$withinss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 275.2533 165.2368 199.8292 257.9090 285.8292 131.9047 239.8457 339.1308&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##       k  value
##   &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1 15781.
## 2     2  9055.
## 3     3  5683.
## 4     4  3088.
## 5     5  2755.
## 6     6  2441.
## 7     7  2152.
## 8     8  1895.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These corresponding values are then neatly displayed in a barchart of the WSS stastistic as a function of k. The sharp decrease between k = 3 and k = 4 (at the &lt;em&gt;elbow&lt;/em&gt;) is indicative of the number of clusters present in the dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(wss, aes(x = k, y = value)) + geom_col()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computing-the-silhouette-index-for-simdat&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Computing the silhouette index for &lt;code&gt;simdat&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Next up is the code necessary to plot the silhouette index. The &lt;code&gt;silhouette&lt;/code&gt; function comes from the &lt;code&gt;cluster&lt;/code&gt; package, and the resulting graph provides an average silhouette width for k = 4 clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam4 = pam(simdatxy, 4)
sil = silhouette(pam4, 4, border = NA)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;pam&lt;/code&gt; (partitioning around medoids) function is doing the same thing as the &lt;code&gt;kmeans&lt;/code&gt; call from the earlier chunk of code, but using the &lt;code&gt;cluster&lt;/code&gt; package’s algorithm to calculate the k-means clustering. We use the &lt;code&gt;pam&lt;/code&gt; function here because the we need the “pam” and “partition” output class to run the &lt;code&gt;silhouette&lt;/code&gt; function. With this information, we can then compute the silhouette index and view the output summary and plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(pam4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;pam&amp;quot;       &amp;quot;partition&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sil = silhouette(pam4, 4, border = NA)
summary(sil)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Silhouette of 400 units in 4 clusters from pam(x = simdatxy, k = 4) :
##  Cluster sizes and average silhouette widths:
##       103       100        99        98 
## 0.5279715 0.5047895 0.4815427 0.4785642 
## Individual silhouette widths:
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.04754  0.41232  0.54916  0.49858  0.63554  0.71440&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we explore the final output plot, it might be interesting to look at plots of the simulated values with their respective cluster assignments based on &lt;code&gt;pam&lt;/code&gt; k-means clustering and the silhouette index. With some (a lot of) help from Brooke, we have the following code to view this.&lt;/p&gt;
&lt;p&gt;For the most part, all of the points were assigned to the same cluster as the original, with the occational border point mis-assigned to the neighboring cluster. Interestingly, the silhouette index approaches zero when you near the border of of the cluster and is much higher near the center of the cluster. Although we would expect this, it can be helpful to view this graphically.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sil %&amp;gt;% 
  unclass() %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  tibble::rownames_to_column(var = &amp;quot;orig_order&amp;quot;) %&amp;gt;% 
  arrange(as.numeric(orig_order)) %&amp;gt;% 
  bind_cols(simdat) %&amp;gt;% 
  ggplot(aes(x = x, y = y, shape = as.factor(cluster), color = sil_width)) + 
  geom_point() + 
  facet_wrap(~ class)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And finally, a silhouette plot with the n = 400 data points. The average silhouette width is a metric that we can use to summarize everything at a level of the full clustering process. Essentially, the closer that this average is to 0.5, then the more accurate our number of clusters &lt;em&gt;k&lt;/em&gt; is. This concept is further explored in the &lt;strong&gt;Part B&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(sil, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-b&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part B&lt;/h2&gt;
&lt;p&gt;Question 5.1.b asks us to change the number of clusters &lt;em&gt;k&lt;/em&gt; and assess which &lt;em&gt;k&lt;/em&gt; value produces the best silhouette index.&lt;/p&gt;
&lt;p&gt;In this example, there are a couple of ways to assess which k gives the best silhouette index.One method would be trial and error and determining which k-value produces the highest silhouette index. This method works out for this example, but is impractical for much larger and complex datasets. Included below is the code for testing multiple different k-values and the resulting coefficient values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam2 = pam(simdatxy, 2)
sil2 = silhouette(pam2, 2)
plot(sil2, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam3 = pam(simdatxy, 3)
sil3 = silhouette(pam3, 3)
plot(sil3, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam4 = pam(simdatxy, 4)
sil = silhouette(pam4, 4)
plot(sil, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam12 = pam(simdatxy, 12)
sil12 = silhouette(pam12, 12)
plot(sil12, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam40 = pam(simdatxy, 40)
sil40 = silhouette(pam40, 40)
plot(sil40, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This trial and error method indicates that the highest silhouette index (that was tested) is achieved with k = 4.&lt;/p&gt;
&lt;p&gt;A different (seemingly more appropriate) method is to write a piece of code that will test a range of k-values automatically. This next piece of code is adapted from Amy Fox and the group that she worked with during class. This is a much more practical method that provides a clear answer of which &lt;em&gt;k&lt;/em&gt; gives the best silhouette index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k &amp;lt;- c(2:10)
df_test &amp;lt;- data.frame()
for (i in 2:10){
  
  pam_run &amp;lt;- pam(simdatxy, i)
  sil_run &amp;lt;- silhouette(pam_run, i)
  
  row_to_add &amp;lt;- data.frame(i, width = summary(sil_run)$avg.width)
  
  df_test &amp;lt;- rbind(df_test, row_to_add)
}
df_test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    i     width
## 1  2 0.4067400
## 2  3 0.4000560
## 3  4 0.4985801
## 4  5 0.4401518
## 5  6 0.3957347
## 6  7 0.3717875
## 7  8 0.3699929
## 8  9 0.3670770
## 9 10 0.3516570&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df_test, aes(i, width)) +
  geom_point() +
  geom_line() +
  xlab(&amp;quot;k&amp;quot;) +
  ylab(&amp;quot;Silhouette Index&amp;quot;) +
  ggtitle(&amp;quot;Testing different k values for Silhouette Index&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(sil_run)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Silhouette of 400 units in 10 clusters from pam(x = simdatxy, k = i) :
##  Cluster sizes and average silhouette widths:
##        63        38        40        52        33        40        35        33 
## 0.3885059 0.3273800 0.3622990 0.3703291 0.3573781 0.3257945 0.4429236 0.2807700 
##        31        35 
## 0.3944945 0.2335738 
## Individual silhouette widths:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -0.1778  0.2389  0.3703  0.3517  0.4946  0.6623&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result of &lt;code&gt;summary(sil_run)&lt;/code&gt; matches the trial and error method, but in a more efficient manner.&lt;/p&gt;
&lt;p&gt;In summary, k = 4 provides us with the best silhouette index value. This is because there truly are four groups in the dataset based on how we created it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-c&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part C&lt;/h2&gt;
&lt;p&gt;The last part of this exercise asks us to repeat by calculating the silhouette index on a uniform (unclustered) data distribution over a range of values.&lt;/p&gt;
&lt;p&gt;Here, a new data set is generated without clustering the randomly generated data. The 0 and 8 assignment values have been removed and replaced with a singular 1. This assigns all of the values to have the same class.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

simdat1 = lapply(c(1), function(mx) {
  lapply(c(1), function(my) {
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
   }) %&amp;gt;% bind_rows
}) %&amp;gt;% bind_rows

simdatxy1 = simdat1[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)]

ggplot(simdatxy1, aes(x = x, y = y)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam4.1 = pam(simdatxy1, 4)
sil.1 = silhouette(pam4.1, 4)
plot(sil.1, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The average silhouette width is 0.33, which is much lower than the clustered value of 0.50 that we see with the first simulation. It should be pointed out that several of the points end up with negative silhouette widths. These observations were assigned to the wrong group entirely.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://web.stanford.edu/class/bios221/book/Chap-Clustering.html#ques:ques-WSSclusters&#34;&gt;Modern Statistics for Modern Biology - Chapter 5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Silhouette_(clustering)&#34;&gt;Silhouette Clustering - Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@jyotiyadav99111/selecting-optimal-number-of-clusters-in-kmeans-algorithm-silhouette-score-c0d9ebb11308&#34;&gt;Blog on Selecting Optimal Number of Clusters&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 5 vocabulary quiz</title>
      <link>/post/chapter-5-vocabulary-quiz/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-5-vocabulary-quiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSe0N9FjDBrIbC3uCxEQBhpndhT6IvKHg2xCiqXzyb6JZJRi3w/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2987&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 5</title>
      <link>/post/vocabulary-for-chapter-5/</link>
      <pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-5/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 5 covers Clustering Analysis for large scale data anlysis like DNA/RNA sequencing outputs. These methods produce so much data that more unbiased approaches are required when attempting to make correlations.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
unsupervised method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A learning method where all variables are treated with the same status, rather than one variable being considered as an outcome or target.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
status
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A variable’s classification as an outcome/predictor (e.g. independent/dependent) in an analysis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the difference between two random variables.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
The Euclidean distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the “ordinary” straight-line distance between two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Manhattan distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the sum of the absolute differences between the coordinate values for two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Maximum distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the largest absolute difference between the coordinate values for two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Weighted Euclidean distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric, which is a generalization of the ordinary Euclidean distance, that differentially weights the differences between the coordinate values for two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Minkowski distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the mth root of the sum of the absolute differences between the coordinate values each raised to the mth power.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Edit or Hamming distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric for comparing character sequences that counts the number of differences between two character strings.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Binary distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric for binary strings based on the proportion of features having only one bit on amongst those features that have at least one bit on.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric that quantifies how dissimilar two sets are.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
co-occurrence
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The fact of two or more things occurring together or simultaneously.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A statistic used in quantifying the similarities between sample sets, which is formally defined as the size of the intersection between two sets divided by the size of the union of the sets.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard dissimilarity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
1 - the Jaccard index.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Correlation-based distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric that measures two objects to be similar if their features are highly correlated, even though the observed values may be far apart in terms of Euclidean distance.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Clusters of Differentiation (CDs)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
At different stages of their development, immune cells express unique combinations of proteins on their surfaces.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Rectangular gating
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of identifying groups of cells from a flow cytometry experiment using either a line (one-dimensional) or the quadrants created by two perpendicular lines (two-dimensional)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Hyperbolic Arcsine (asinh)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A transform function often preferred over the log tranform for flow cytometry data because it can be applied to negative values.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
density-based clustering (dbscan)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The dbscan method clusters points in dense regions according to the density-connectedness criterion. It looks at small neighborhood spheres to see if points are connected.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
curse of dimensionality
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
When the dimensionality increases, the volume of the space increases so fast that the available data become sparse
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
density-reachability
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A fundamental criterion in dbscan that quantifies whether two points are close enough together and surrounded by sufficiently many other points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
recursive partitioning methods
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A class of methods for dividing heterogeneous populations into more homogeneous subgroups, often used to make decision trees, that starts by separating the whole population into a few groups and iteratively continues separating each into subgroups.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
minimal jump method/single linkage method/nearest neighbor method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that computes the distance between clusters as the smallest distance between any two points in the two clusters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
maximum jump method/complete linkage method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that defines the distance between clusters as the largest distance between any two objects in the two clusters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
average linkage method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that defines the distance between clusters as the average distance between a point in one cluster and another point in the other cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Ward’s method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that takes an analysis of variance approach, where the goal is to minimize the variance within clusters. This method is very efficient, however, it tends to break the clusters up into ones of smaller sizes.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Within-groups sum of squares (WSS)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the variability among data points within an identified cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Calinski-Harabasz index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Quantifies the relative variability between groups (between group sum of squares) and within groups (within-groups sum of sqaures), similar to the F statistic used in analysis of variance.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Between-groups sum of squares (BSS)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the variability between clusters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gap statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A metric used to perform model selection which quantifies the amount of model fit improvement when using a more complex model. These can be used to select the number of clusters for a data set.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
technical / batch effects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Depedence in data observations that results from technical differences between samples, such as the type of sequencing machine or the technician that ran the sample, rather than from scientifically interesting causes.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
computational complexity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the computational resources needed to run an algorithm.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
noise
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Unexplained variability within a data sample.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
operational taxonomic unit (OTU)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of clustering organisms based on DNA sequence similarity of a certain taxonomic marker gene.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
bias
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The tendency of a statistic to overestimate or underestimate a parameter.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
representativeness heuristic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of learning or discovery that assesses similarity of objects and organizes them based around a category prototype (e.g., like goes with like, and causes and effects should resemble each other).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rare variants
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An alternative form of a gene that occur just once or twice in an individual sample but more often across all samples.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
insertion-deletion (indel)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
insertion or deletion of bases in the genome of an organism.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
neighboring cluster
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The cluster with the lowest average dissimilarity to a given cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
silhouette index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A metric quantifying the degree to which a given data point belongs to its designated cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Microbiome
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The aggregate of all microbiota that reside on or within an organim’s tissues and biofluids along with the corresponding anatomical sites in which they reside.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
filtering
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of low-quality rRNA reads removal of low-quality reads and trimming them to a consistent length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Histopathology
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The microscopic examination of tissue in order to study the manifestations of disease.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Molecular signature
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Sets of genes, proteins, genetic variants or other variables that can be used as markers for a particular phenotype
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Gene expression data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Gene expression measurements : from gene¬scale to genome¬scale
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Single-cell RNA-Seq experiment
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measurement of the gene expression profiles of individual cells.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gene transcript
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An RNA molecule of defined size over the length of a gene.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
cell lineage dynamics
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Visualized with tools such as scRNA-seq to track individual cells through their natural progression.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Flow cytometry
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A technique for identifying and sorting cells and their components (such as DNA) by staining with a fluorescent dye and detecting the fluorescence usually by laser beam illumination
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Mass cytometry
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A variation of flow cytometry in which antibodies are labeled with heavy metal ion tags rather than fluorochromes. Readout is by time-of-flight mass spectrometry.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Immune cells
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
cells that are part of the immune system and help the body fight infections and other diseases
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
CD marker / antigen marker
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
are specific types of molecules found on the surface of cells that help differentiate one cell type from another.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
CD4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A glycoprotein found on the surface of immune cells such as T helper cells, monocytes, macrophages, and dendritic cells.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
helper T cells
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A type of T cell that provides help to other cells in the immune response by recognizing foreign antigens and secreting substances called cytokines that activate T and B cells
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Isotope
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Two or more forms of the same element that contain equal numbers of protons but different numbers of neutrons in their nuclei, and hence differ in relative atomic mass but not in chemical properties;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Inner cell mass (ICM)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Pluripotent cell lineage in the blastocyst. forms within the blastocyst, prior to its implantation within the uterus.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Blastocyst
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A thin-walled hollow structure in early embryonic development that contains a cluster of cells called the inner cell mass from which the embryo arises.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Pluripotent epiblast (EPI)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The functional progenitors of soma and germ cells which later differentiate into three layers: definitive endoderm, mesoderm and ectoderm
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
primitive endoderm (PE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The second extraembryonic tissue to form during embryogenesis in mammals. The PE develops from pluripotent cells of the blastocyst inner cell mass
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variable regions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of taxon identification of bacteria bacterial 16S ribosomal RNA (rRNA) genes contain nine “hypervariable regions” (V1 – V9) that demonstrate considerable sequence diversity among different bacteria.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Chimera
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An organism or tissue that contains at least two different sets of DNA, most often originating from the fusion of as many different zygotes (fertilized eggs).
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources Consulted or Cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitons above are based in part or whole on listed definitions in the following sources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;http://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://academic.oup.com/biolreprod/article/85/5/946/2530522&#34; class=&#34;uri&#34;&gt;https://academic.oup.com/biolreprod/article/85/5/946/2530522&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://discovery.lifemapsc.com/in-vivo-development/inner-cell-mass/inner-cell-mass&#34; class=&#34;uri&#34;&gt;https://discovery.lifemapsc.com/in-vivo-development/inner-cell-mass/inner-cell-mass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://study.com/academy/lesson/inner-cell-mass-icm-definition-function-quiz.html&#34; class=&#34;uri&#34;&gt;https://study.com/academy/lesson/inner-cell-mass-icm-definition-function-quiz.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/&#34; class=&#34;uri&#34;&gt;https://www.sciencedirect.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.medicinenet.com/&#34; class=&#34;uri&#34;&gt;https://www.medicinenet.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.niaid.nih.gov/&#34; class=&#34;uri&#34;&gt;https://www.niaid.nih.gov/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iti.stanford.edu/&#34; class=&#34;uri&#34;&gt;https://iti.stanford.edu/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sysbiowiki.soe.ucsc.edu/node/323&#34; class=&#34;uri&#34;&gt;https://sysbiowiki.soe.ucsc.edu/node/323&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/between-group-variation/&#34; class=&#34;uri&#34;&gt;https://www.statisticshowto.datasciencecentral.com/between-group-variation/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vsoch.github.io/2013/the-gap-statistic/&#34; class=&#34;uri&#34;&gt;https://vsoch.github.io/2013/the-gap-statistic/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/488864042/flashcards/embed?i=2oqpc3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
