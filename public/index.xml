<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CSU MSMB Group Study</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>CSU MSMB Group Study</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 13 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>CSU MSMB Group Study</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Exercise Solution for Chapter 6</title>
      <link>/post/exercise-solution-for-chapter-6/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-chapter-6/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;chapter-6-exercise-6.4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Chapter 6, Exercise 6.4&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Make a less extreme example of correlated test statistics than the data duplication at the end of Section 6.5. Simulate data with true null hypotheses only, and let the data morph from having completely independent replicates (columns) to highly correlated as a function of some continuous-valued control parameter. Check type-I error control (e.g., with the p-value histogram) as a function of this control parameter.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We’ll go through a few data clean up and exploration steps first, then we’ll walk through the code related specifically to the exercise a little further down in the post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(purrr)
library(ggbeeswarm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this exercise we use the PlantGrowth dataset from the &lt;code&gt;datasets&lt;/code&gt; package in R. The dataset includes results from an experiment on plant growth comparing yields (as measured by dried weight of plants) obtained under a control and two different treatment conditions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;PlantGrowth&amp;quot;)
head(PlantGrowth)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   weight group
## 1   4.17  ctrl
## 2   5.58  ctrl
## 3   5.18  ctrl
## 4   6.11  ctrl
## 5   4.50  ctrl
## 6   4.61  ctrl&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we’re plotting the outcomes of the three groups (&lt;code&gt;ctrl&lt;/code&gt;, &lt;code&gt;trt1&lt;/code&gt;, and &lt;code&gt;trt2&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PlantGrowth %&amp;gt;% 
   mutate(group = fct_recode(group, 
                            Control = &amp;quot;ctrl&amp;quot;, 
                            `Treatment 1` = &amp;quot;trt1&amp;quot;, 
                            `Treatment 2` = &amp;quot;trt2&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x = group, y = weight)) + 
  geom_beeswarm() + 
  labs(x = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-13-exercise-solution-for-chapter-6_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;288&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Often in research one of the simplest comaparisons of data we can make is between two groups. The t-test is one of the many statistics used in hypothesis testing and can help us determine if the differences between two group means is “significant” or if the differences could have happened by chance. The test statistic is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(t=\frac{\bar{m_1}-\bar{m_2}}{\sqrt{s_1^2/N_1 + s_2^2/N_2}}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\bar{m_1}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{m_2}\)&lt;/span&gt; are the sample means in group 1 and
2, respectively, which have &lt;span class=&#34;math inline&#34;&gt;\(N_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_2\)&lt;/span&gt; observations each, and
&lt;span class=&#34;math inline&#34;&gt;\(s_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_2\)&lt;/span&gt; are the sample variances for each of the two groups.&lt;/p&gt;
&lt;p&gt;Next we’ll apply a t-test comparing weights in the &lt;code&gt;ctrl&lt;/code&gt; group to the &lt;code&gt;trt2&lt;/code&gt; group. We’re testing against the null hypothesis that there is no difference in mean dried plant weights between the two groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PlantGrowth %&amp;gt;% 
  filter(group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)) %&amp;gt;% 
    t.test(weight ~ group, data  = .) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  weight by group
## t = -2.134, df = 16.786, p-value = 0.0479
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.98287213 -0.00512787
## sample estimates:
## mean in group ctrl mean in group trt2 
##              5.032              5.526&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the tidy version:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;broom&amp;quot;)
(ttest_orig &amp;lt;- PlantGrowth %&amp;gt;% 
  filter(group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)) %&amp;gt;% 
  t.test(weight ~ group, data  = .) %&amp;gt;% 
    tidy())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 10
##   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1   -0.494      5.03      5.53     -2.13  0.0479      16.8   -0.983  -0.00513
## # … with 2 more variables: method &amp;lt;chr&amp;gt;, alternative &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we’ll duplicate the data, adding a second copy of the dataframe, before running the t-test.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(ttest_dup &amp;lt;- PlantGrowth %&amp;gt;% 
  bind_rows(PlantGrowth) %&amp;gt;% # Add the duplicate of the dataset
  filter(group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)) %&amp;gt;% 
  t.test(weight ~ group, data  = .) %&amp;gt;% 
  tidy())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 10
##   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1   -0.494      5.03      5.53     -3.10 0.00377      35.4   -0.817    -0.171
## # … with 2 more variables: method &amp;lt;chr&amp;gt;, alternative &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the p-value is smaller (now less than 0.05) even though the group means haven’t changed. This is due solely to the increase in sample size.&lt;/p&gt;
&lt;p&gt;However, we’ve violated the t-test assumption of independence. Paired (in this case blatantly duplicated) data is dependent and would be more appropriately tested by a two-sample paired test. A similar example with experimental data would involve taking duplicate measures (technical replicates) on 15 subjects (e.g., leaf, mouse, human) and assuming you now have 30 independent measurements; that would be incorrect. Taking repeated measurements on 15 subjects would leave you with just 15 independent measurments (and the
other 15 fully dependent on those).&lt;/p&gt;
&lt;p&gt;If the data sampled for a t-test violates one or more of the t-test assumptions, such as independence or normal distribution, results can be incorrect and misleading.&lt;/p&gt;
&lt;p&gt;Next we resample only half the data and then duplicated that sampled half to create a datset; so the size of the data set is the same as the original dataset (n = 30), but now half of the observations are fully dependent (exactly the same) as other observations in the dataset.&lt;/p&gt;
&lt;p&gt;The purpose of the &lt;code&gt;set.seed&lt;/code&gt; function is to set the seed of R’s random number generator. We use it below in our simulations so that the results of our sampled data don’t change each time the document is re-rendered and therefore can be reproduced.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(4234)

pg1 &amp;lt;- PlantGrowth %&amp;gt;% 
  sample_frac(size = 0.5) %&amp;gt;% 
  bind_rows(., .) 

(pg1_ttest &amp;lt;- pg1 %&amp;gt;% 
  filter(group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)) %&amp;gt;% 
  t.test(weight ~ group, data  = .) %&amp;gt;% 
  tidy())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 10
##   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1   -0.492      5.23      5.72     -1.98  0.0722      11.3    -1.04    0.0524
## # … with 2 more variables: method &amp;lt;chr&amp;gt;, alternative &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The p-value increases from 0.004 with a fully duplicated dataset to a value typically much higher with half the data duplicated.&lt;/p&gt;
&lt;p&gt;As discussed in section 6.5 of the text, the t-test function uses asymptotic theory to compute the t-statistic: “this theory states that under the null hypothesis of means in both groups, the statistic follows a known, mathematical distribution, the so called t-distribution with &lt;span class=&#34;math inline&#34;&gt;\(n^1 + n^2\)&lt;/span&gt; degrees of freedom” As we’ve discussed above, the theory also makes the assumption of independence, normality, and equal variance.&lt;/p&gt;
&lt;p&gt;There are often variations from these assumptions in real world data. In our plant growth example, weights are always positive while the normal distribution spans over the entire axis.&lt;/p&gt;
&lt;p&gt;Below we use permutation tests to assess whether the deviation from theoretical assumptions makes a difference. We first use &lt;code&gt;replicate&lt;/code&gt; to
run a lot of t-tests where we test our original data, but with the
&lt;code&gt;group&lt;/code&gt; column randomly re-ordered, so any true relationship between
the group and weight measurements is broken:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pg1_null = with(
  dplyr::filter(pg1, group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)),
    replicate(10000,
      abs(t.test(weight ~ sample(group))$statistic)))

# You can see that this results in a long vector of t statistic
# values, each estimated from a version of the data where we 
# randomized the group labels
head(pg1_null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         t         t         t         t         t         t 
## 0.5065581 0.9543497 0.5703743 0.5760347 0.5101952 1.6371872&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These should represent the pattern of how t statistics for this
data would be distributed under the null hypothesis that there is no
difference between the average weights of the two groups.
We can plot a histogram of all these t statistic values to visualize
the distribution of the t statistic under the null hypothesis, adding
a line to show the t statistic we observed in the real data (without
shuffling the &lt;code&gt;group&lt;/code&gt; column):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(tibble(`|t|` = pg1_null), aes(x = `|t|`)) +
  geom_histogram(binwidth = 0.1, boundary = 0) +
  geom_vline(xintercept = abs(pg1_ttest$statistic), col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-13-exercise-solution-for-chapter-6_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In general, a permutation test is a type of statistical significance test in which the distribution of the test statistic under the null hypothesis is obtained by calculating all possible values of the test statistic under all possible rearrangements of the observed data points (&lt;a href=&#34;https://wikipedia.org&#34; class=&#34;uri&#34;&gt;https://wikipedia.org&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The test essentially exchanges labels between samples and what they measure; if the connections between label and measurements are broken our t-test should show no connection between the two, demonstrating a true null hypothesis that there is no difference between group means.&lt;/p&gt;
&lt;p&gt;Now we’ll take the dataset with half resampled, and add random noise to each observation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)

pg2 &amp;lt;- pg1 %&amp;gt;% 
  mutate(noise = rnorm(30, mean = 0, sd = 0.2), 
         weight = weight + noise) %&amp;gt;% 
  select(-noise)
head(pg2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     weight group
## 1 5.908587  trt2
## 2 6.165486  ctrl
## 3 6.526888  trt2
## 4 4.030860  ctrl
## 5 4.775825  trt1
## 6 5.241211  ctrl&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(pg2_ttest &amp;lt;- pg2 %&amp;gt;% 
  filter(group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)) %&amp;gt;% 
  t.test(weight ~ group, data  = .) %&amp;gt;% 
  tidy())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 10
##   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1   -0.562      5.14      5.70     -1.97  0.0767      10.3    -1.20    0.0721
## # … with 2 more variables: method &amp;lt;chr&amp;gt;, alternative &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Permutation test data with half duplicated and random noise added:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pg2_null = with(
  dplyr::filter(pg2, group %in% c(&amp;quot;ctrl&amp;quot;, &amp;quot;trt2&amp;quot;)),
    replicate(10000,
      abs(t.test(weight ~ sample(group))$statistic)))

head(pg2_null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          t          t          t          t          t          t 
## 0.63521740 1.71201809 0.73541313 0.61678119 0.02298951 1.38779279&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(tibble(`|t|` = pg2_null), aes(x = `|t|`)) +
  geom_histogram(binwidth = 0.1, boundary = 0) +
  geom_vline(xintercept = abs(pg2_ttest$statistic), col = &amp;quot;red&amp;quot;)  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-13-exercise-solution-for-chapter-6_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If the t-test statistic we see in our permutation test looks different compared to our observed data then we can most likely conclude that our data was not generated under the null hypothesis of no significant difference between the treatment groups. We would therefore reject the null hypothesis.&lt;/p&gt;
&lt;p&gt;The table below summarizes the four different types of datasets we’ve explored with t-tests. Important to note is that all of these results are from random samples; the exact p-values and test statistics are variable and if someone were to run a code with a different seed, they would get different results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(kableExtra)

data_summary &amp;lt;- bind_rows(ttest_orig, ttest_dup, 
                          pg1_ttest, pg2_ttest) %&amp;gt;% 
  mutate(data = c(&amp;#39;original&amp;#39;, 
                  &amp;#39;doubled without random noise&amp;#39;,
                  &amp;#39;same size as original, half observations replicated&amp;#39;,
                  &amp;#39;half replicated, random noise added to each replicate&amp;#39;), 
         n = c(30, 60, 30 ,30)) %&amp;gt;% 
  select(data, n, statistic, p.value)

data_summary %&amp;gt;% 
   kable(align = c(&amp;quot;l&amp;quot;)) %&amp;gt;% 
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;,
                                      &amp;quot;condensed&amp;quot;)) %&amp;gt;% 
  column_spec(1, bold = T, border_right = T) %&amp;gt;% 
  column_spec(2:3, width = &amp;quot;6em&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
data
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
n
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt;
original
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
-2.134021
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0478993
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt;
doubled without random noise
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
60
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
-3.100660
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0037738
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt;
same size as original, half observations replicated
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
-1.982154
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0722163
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt;
half replicated, random noise added to each replicate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 6em; &#34;&gt;
-1.967597
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0766878
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exercise Solution for Chapter 12</title>
      <link>/post/exercise-solution-for-chapter-12/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-chapter-12/</guid>
      <description>


&lt;div id=&#34;exercise-12.2-from-modern-statistics-for-modern-biologists&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 12.2 from Modern Statistics for Modern Biologists&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Use &lt;code&gt;glmnet&lt;/code&gt; for a prediction of a continous variable, i.e., for regression. Use the prostate cancer data from Chapter 3 of (Hastie, Tibshirani, and Friedman 2008). The data are available in the CRAN package &lt;code&gt;ElemStatLearn&lt;/code&gt;. Explore the effects of using Ridge versus Lasso penalty.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here are the packages that need to be installed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)
library(glmnet) # perform generalize linear models
library(GGally) # used for ggpairs function
library(superheat) # used to show correlation between variables&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-for-the-exercise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data for the exercise&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;ElemStatPackage&lt;/code&gt; isn’t on CRAN anymore. But it is possible to download it from Github at: &lt;a href=&#34;https://github.com/cran/ElemStatLearn/blob/master/data/prostate.RData&#34; class=&#34;uri&#34;&gt;https://github.com/cran/ElemStatLearn/blob/master/data/prostate.RData&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;load(&amp;quot;./example_datasets/prostate.RData&amp;quot;)

prostate %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       lcavol  lweight age      lbph svi       lcp gleason pgg45       lpsa
## 1 -0.5798185 2.769459  50 -1.386294   0 -1.386294       6     0 -0.4307829
## 2 -0.9942523 3.319626  58 -1.386294   0 -1.386294       6     0 -0.1625189
## 3 -0.5108256 2.691243  74 -1.386294   0 -1.386294       7    20 -0.1625189
## 4 -1.2039728 3.282789  58 -1.386294   0 -1.386294       6     0 -0.1625189
## 5  0.7514161 3.432373  62 -1.386294   0 -1.386294       6     0  0.3715636
## 6 -1.0498221 3.228826  50 -1.386294   0 -1.386294       6     0  0.7654678
##   train
## 1  TRUE
## 2  TRUE
## 3  TRUE
## 4  TRUE
## 5  TRUE
## 6  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This data looks at correlating the level of prostate-specific antigen &lt;code&gt;lpsa&lt;/code&gt; and eight other clinical measures in men.&lt;/p&gt;
&lt;p&gt;Here’s what the variables mean:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;lcavol&lt;/code&gt;: log cancer volume&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lweight&lt;/code&gt;: log prostate weight&lt;/li&gt;
&lt;li&gt;&lt;code&gt;age&lt;/code&gt;: in years&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lbph&lt;/code&gt;: log of the amount of benign prostatic hyperplasia&lt;/li&gt;
&lt;li&gt;&lt;code&gt;svi&lt;/code&gt;: seminal vesicle invasion&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lcp&lt;/code&gt;: log of capsular penetration&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gleason&lt;/code&gt;: a numeric vector with the Gleason score&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pgg45&lt;/code&gt;: percent of Gleason score 4 or 5&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lpsa&lt;/code&gt;: response (the thing you are trying to predict), the
level of prostate-specific antigen&lt;/li&gt;
&lt;li&gt;&lt;code&gt;train&lt;/code&gt;: a logical vector, of whether the data was to be
part of the training dataset (TRUE) or the testing one (FALSE)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, you’re trying to predict the values of &lt;code&gt;lpsa&lt;/code&gt; based on all of the other variables. &lt;code&gt;lpsa&lt;/code&gt; is a continuous variable. To get a general view of the &lt;code&gt;lpsa&lt;/code&gt; values, we can view a summary of values and create a histogram.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prostate$lpsa %&amp;gt;%
  summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -0.4308  1.7317  2.5915  2.4784  3.0564  5.5829&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(prostate, aes(x = lpsa)) +
  geom_histogram(bins = 30) +
  ggtitle(&amp;quot;Histogram of lpsa response&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we can see the values range from -0.4 to values of almost 6. Based on the histogram, the data seems to also fit a close to normal distribution.&lt;/p&gt;
&lt;p&gt;Before actually performing any predictions, we may want to see if any of the variables are correlated to each other. This can show if there are potentially two variables measuring similar things. We use the &lt;code&gt;ggpairs&lt;/code&gt; function from the &lt;code&gt;GGally&lt;/code&gt; package to do this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggpairs(prostate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on this plot, we can see that some variables, such as&lt;code&gt;pgg45&lt;/code&gt; and &lt;code&gt;gleason&lt;/code&gt;, are highly correlated. We can also see the distribution of the data in the testing and training datasets (we will discuss the testing and training column later in this exercise).&lt;/p&gt;
&lt;p&gt;We can also visually view correlations between the variables using the &lt;code&gt;cor&lt;/code&gt; function and a heatmap from the&lt;code&gt;superheat&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prostate %&amp;gt;%
  select(-train) %&amp;gt;%
  cor() %&amp;gt;%
  superheat()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows the same data as the &lt;code&gt;ggpairs&lt;/code&gt; output, but we can visually see the correlation between each of the variables. If the correlation is high and positive, then the rectange is yellow, if the correlation between two variables is low, the rectangle is purple.&lt;/p&gt;
&lt;p&gt;We will first split the data into testing and training data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prostate_train &amp;lt;- prostate %&amp;gt;%
  filter(train == TRUE)

prostate_test &amp;lt;- prostate %&amp;gt;%
  filter(train == FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 67 samples in the training set and 30 samples in the testing set.&lt;/p&gt;
&lt;p&gt;Because this data was specifically posted to teach machine learning, the authors included a column called &lt;code&gt;train&lt;/code&gt; so that users can split the data into testing and training datasets. If this column had not been created, there are many ways to sample the data and split it into two datasets. Here is an example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;install.packages(&#34;rsample&#34;)&lt;/code&gt;
&lt;code&gt;library(rsample)&lt;/code&gt;
&lt;code&gt;prostate_split &amp;lt;- initial_split(prostate, prop = .75)&lt;/code&gt;
&lt;code&gt;prostate_test &amp;lt;- testing(prostate_split)&lt;/code&gt;
&lt;code&gt;prostate_train &amp;lt;- training(prostate_split)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-generalized-linear-model-glmnet-with-lasso-and-ridge-penalties&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit generalized linear model (glmnet) with Lasso and Ridge penalties&lt;/h2&gt;
&lt;p&gt;We will first pull out the predictors and reponse that we want to input into the &lt;code&gt;glmnet&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# pull outall of the predictors that we are using
predictors &amp;lt;- prostate_train %&amp;gt;%
  select(lcavol:pgg45) %&amp;gt;%
  as.matrix()

head(predictors)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          lcavol  lweight age      lbph svi       lcp gleason pgg45
## [1,] -0.5798185 2.769459  50 -1.386294   0 -1.386294       6     0
## [2,] -0.9942523 3.319626  58 -1.386294   0 -1.386294       6     0
## [3,] -0.5108256 2.691243  74 -1.386294   0 -1.386294       7    20
## [4,] -1.2039728 3.282789  58 -1.386294   0 -1.386294       6     0
## [5,]  0.7514161 3.432373  62 -1.386294   0 -1.386294       6     0
## [6,] -1.0498221 3.228826  50 -1.386294   0 -1.386294       6     0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this is the response
response &amp;lt;- prostate_train %&amp;gt;%
  pull(lpsa)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When performing statistical analysis on data with many variables, we often have a problem with variance as there are many parameters. We can use penalization to account for this variance-bias trade off. Two examples of penalization are the Lasso and Ridge penalty which we will use in this exercise.&lt;/p&gt;
&lt;p&gt;Based on the &lt;code&gt;glmnet&lt;/code&gt; package, when &lt;code&gt;alpha = 1&lt;/code&gt; the Lasso penalty is used, if &lt;code&gt;alpha = 0&lt;/code&gt;, then Ridge penalty is used. A great resource for the &lt;code&gt;glmnet&lt;/code&gt; package can be found here: &lt;a href=&#34;https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html&#34; class=&#34;uri&#34;&gt;https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here, we use a matrix of all of the predictors (&lt;code&gt;x&lt;/code&gt;) to try to predict the &lt;code&gt;lpsa&lt;/code&gt; column (&lt;code&gt;y&lt;/code&gt;). When we plot the penalized regressions, we use the &lt;code&gt;label = TRUE&lt;/code&gt; to show which lines correspond to which predictors. In this case, the order of the input vector &lt;code&gt;predictors&lt;/code&gt; matches with the variable numbers as follows.&lt;/p&gt;
&lt;p&gt;1: lcavol&lt;/p&gt;
&lt;p&gt;2: lweight&lt;/p&gt;
&lt;p&gt;3: age&lt;/p&gt;
&lt;p&gt;4: lbph&lt;/p&gt;
&lt;p&gt;5: svi&lt;/p&gt;
&lt;p&gt;6: lcp&lt;/p&gt;
&lt;p&gt;7: gleason&lt;/p&gt;
&lt;p&gt;8: pgg45&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Lasso 
lasso_glmnet &amp;lt;- glmnet(x = predictors, 
                    y = response, 
                    family = &amp;quot;gaussian&amp;quot;, alpha = 1)

plot(lasso_glmnet, label = TRUE)
title(&amp;quot;Lasso Penalty&amp;quot;, line = -2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Ridge
ridge_glmnet &amp;lt;- glmnet(x = predictors, 
                    y = response, 
                    family = &amp;quot;gaussian&amp;quot;, alpha = 0)

plot(ridge_glmnet, label = TRUE)
title(&amp;quot;Ridge Penalty&amp;quot;, line = -1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The plots show the estimated coefficients as L1 norm increases. L1 norm is the regularization term. It means that at small L1 norm values, there is a lot of regularization, but as it increases, more variables become part of the model as coefficients take non-zero values. The top axis shows the number of nonzero coefficients correspoding to the lamba at the current L1 norm. From these plots we can see that the variables 1 (log cancer volume), 2 (log prostate weight), and 5 (seminal vesicle invasion) are good predictors for the level of prostate-specific antigen (lpsa response).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cross Validation&lt;/h2&gt;
&lt;p&gt;After creating our models, we want to see how good they are. We can do this through cross-validation. In this case, we already split the data into training and testing data, but we could run the full modeling and cross-validation on all of the data. We use the &lt;code&gt;cv.glmnet&lt;/code&gt; function to do this. It utilizes k-fold cross validation, meaning that the input data is split multiple times into new trainng and testing sets of sizes n(k-1)/k and n/k, respectively. We use this cross-validation to determine the best &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;. Again we input a matrix of all of the predictors (&lt;code&gt;x&lt;/code&gt;) to look at the &lt;code&gt;lpsa&lt;/code&gt; response (&lt;code&gt;y&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2)

# Lasso
cvglmnet_lasso &amp;lt;- cv.glmnet(x = predictors, 
                    y = response, 
                    family = &amp;quot;gaussian&amp;quot;, alpha = 0)
cvglmnet_lasso&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:  cv.glmnet(x = predictors, y = response, family = &amp;quot;gaussian&amp;quot;,      alpha = 0) 
## 
## Measure: Mean-Squared Error 
## 
##     Lambda Measure      SE Nonzero
## min 0.0879  0.5939 0.09857       8
## 1se 0.9873  0.6873 0.08098       8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(cvglmnet_lasso)
title(&amp;quot;Lasso Cross Validation&amp;quot;, line = -1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Ridge
cvglmnet_ridge &amp;lt;- cv.glmnet(x = predictors, 
                    y = response, 
                    family = &amp;quot;gaussian&amp;quot;, alpha = 1)
cvglmnet_ridge&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:  cv.glmnet(x = predictors, y = response, family = &amp;quot;gaussian&amp;quot;,      alpha = 1) 
## 
## Measure: Mean-Squared Error 
## 
##      Lambda Measure      SE Nonzero
## min 0.01336  0.5753 0.07244       7
## 1se 0.13673  0.6408 0.09222       5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(cvglmnet_ridge)
title(&amp;quot;Ridge Cross Validation&amp;quot;, line = -1.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the data output, &lt;code&gt;1se&lt;/code&gt; is the data point that is within 1 standard error of the minimum &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; (&lt;code&gt;min&lt;/code&gt;). This is the value that the model suggests that we use in our ultiamate predictive model (indicated by the 2nd dotted line on the plots.)
The &lt;code&gt;1se Measure&lt;/code&gt; is similar to the mean squared error. If the measure is small, then the model is better. When comparing the &lt;code&gt;Measure&lt;/code&gt; of the &lt;code&gt;1se&lt;/code&gt; between the two penalties, we can see that the Ridge Penalty has a smaller &lt;code&gt;1se Measure&lt;/code&gt;, showing that it performs better.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Nonzero&lt;/code&gt; column describes the nonzero coefficients, or the number of predictors that are important in the particular model. There were a total of 8 predictors as the input. The Lasso penalty shows that all 8 predictors are important in building the model, but the Ridge penalty only uses 5 predictors.&lt;/p&gt;
&lt;p&gt;Based on this cross-validation, we can deduce that the Ridge penalty is the best predictive model to use for this data. We have also identified the best &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; to use with this model at 0.18074.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lasso-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lasso Prediction&lt;/h2&gt;
&lt;p&gt;Here we pull out the same variables that we used to create the model, but we use the values from the testing data instead of the training data. We will then use the predictors from the testing data to predict the &lt;code&gt;lpsa&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictors_test &amp;lt;- prostate_test %&amp;gt;% 
  dplyr::select(lcavol:pgg45) %&amp;gt;% 
  as.matrix()

head(predictors_test)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          lcavol  lweight age       lbph svi        lcp gleason pgg45
## [1,]  0.7371641 3.473518  64  0.6151856   0 -1.3862944       6     0
## [2,] -0.7765288 3.539509  47 -1.3862944   0 -1.3862944       6     0
## [3,]  0.2231436 3.244544  63 -1.3862944   0 -1.3862944       6     0
## [4,]  1.2059708 3.442019  57 -1.3862944   0 -0.4307829       7     5
## [5,]  2.0592388 3.501043  60  1.4747630   0  1.3480732       7    20
## [6,]  0.3852624 3.667400  69  1.5993876   0 -1.3862944       6     0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we used the training data to build the model, we can then test the generalized linear model with the Lasso penalty on the testing data.&lt;/p&gt;
&lt;p&gt;We start by using the &lt;code&gt;predict&lt;/code&gt; function to use the model to predict the &lt;code&gt;lpsa&lt;/code&gt; on the testing data. We can then see the correlation between the predicted values and actual values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s0 &amp;lt;- cvglmnet_lasso$lambda.1se 

lasso_predict &amp;lt;- predict(cvglmnet_lasso, newx = predictors_test, s = s0)

# create a data frame of the actual lpsa values and the predicted lpsa values
actual_lasso_predict_df &amp;lt;- data.frame(prediction = as.vector(lasso_predict), actual = prostate_test$lpsa)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then see how correlated the prediction and real data are using the &lt;code&gt;cor&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# look at the correlation of the prediction and real data
cor(actual_lasso_predict_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            prediction    actual
## prediction  1.0000000 0.7277086
## actual      0.7277086 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output shows that the actual and predicted values are 72% correlated.&lt;/p&gt;
&lt;p&gt;Finally, we can plot the actual vs. predicted values on a scatter plot. If the actual and predicted values match up exactly, they would sit on the y = x line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(actual_lasso_predict_df, aes(x = actual, y = prediction)) +
  geom_point(color = &amp;quot;#00B0F6&amp;quot;, size = 2) +
  geom_abline(slope=1, intercept=0)+
  ggtitle(&amp;quot;Lasso Prediction&amp;quot;) +
  theme_light()+
  coord_fixed(xlim = c(0.75, 5.6),
              ylim = c(0.75, 5.6))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see in regions of the plot above the y = x line that the model overpredicted the actual values. If a point is below the y = x line, the model underpredicted the values.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ridge-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ridge Prediction&lt;/h2&gt;
&lt;p&gt;We can then perform the same functions using the generalized linear model with the Ridge penalty to test on the testing data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s0 &amp;lt;- cvglmnet_ridge$lambda.1se 

ridge_predict &amp;lt;- predict(cvglmnet_ridge, newx = predictors_test, s = s0)

# create a data frame of the predicted values and actual values
actual_ridge_predict_df &amp;lt;- data.frame(prediction = as.vector(ridge_predict), actual = prostate_test$lpsa) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then see how correlated the prediction and real data are using the &lt;code&gt;cor&lt;/code&gt; function again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(actual_ridge_predict_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            prediction    actual
## prediction  1.0000000 0.7765403
## actual      0.7765403 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Ridge prediction and actual values are 77% correlated.&lt;/p&gt;
&lt;p&gt;Finally, we can plot the actual vs. predicted values on a scatter plot. If the actual and predicted values matched up exactly, they would sit on the y = x line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(actual_ridge_predict_df, aes(x = actual, y = prediction)) +
  geom_point(color = &amp;quot;#FF62BC&amp;quot;, size = 2) +
  geom_abline(slope=1, intercept=0) +
  ggtitle(&amp;quot;Ridge Prediction&amp;quot;) +
  theme_light() +
  coord_fixed(xlim = c(0.75, 5.6),
              ylim = c(0.75, 5.6))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-12-exercise-solution-for-chapter-12_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see in regions of the plot above the y = x line that the model overpredicted the actual values. If a point is below the y = x line, the model underpredicted the values.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Comparing the Lasso and Ridge penalty, based on the cross-validation, the Ridge penalty had a smaller &lt;code&gt;1se Measure&lt;/code&gt;, showing that it performs better. When looking at the actual predictions on the testing data, the Ridge penalty had a higher correlation between the predicted and actual values (77%) compared to the Lasso penalty correlation (72%). In conclusion, the &lt;strong&gt;Ridge penalty performed better on this particular data set.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Resources
- &lt;a href=&#34;https://stats.stackexchange.com/questions/68431/interpretting-lasso-variable-trace-plots&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/questions/68431/interpretting-lasso-variable-trace-plots&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class on May 14</title>
      <link>/post/details-for-class-on-may-14/</link>
      <pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-on-may-14/</guid>
      <description>


&lt;div id=&#34;links-for-may-14&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for May 14&lt;/h2&gt;
&lt;p&gt;We are looking forward to hearing about everyone’s exercise solutions
today! Please plan for about 10 minutes to talk through yours. We will
let you share the screen when it’s your turn. If you would like to follow
along with each post, the “Schedule” section of our website now has
links to all the final versions of blog posts, so you can open those
for all the currently finalized exercise posts as we get to them.&lt;/p&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class on May 7</title>
      <link>/post/details-for-class-on-may-7/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-on-may-7/</guid>
      <description>


&lt;div id=&#34;links-for-may-7&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for May 7&lt;/h2&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group 1 (Sierra, Camron, Sherry, James): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_NjA3Y2Q5MDYtYTM5OS00MzAyLWEwMzAtMzdmNWMzYzhmMTUw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 2 (Sarah, Burton, Daniel): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_M2I3YmViYjMtNWJlNC00M2E5LTg5NTItNzI0N2VlYmVkNzUz%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 3 (Amy, Sere, Mikaela): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_YjE4ZGJhNjItYTViMS00MjZjLTk4NWUtMjBhY2E3OTJiOGQw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;vocabulary-quiz-for-may-7&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vocabulary quiz for May 7&lt;/h2&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSexbNrbbdBDfOFImZiNHIMs4eOvL_DEA3eNPHjDrzZ4aatb0g/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;3297&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 12</title>
      <link>/post/vocabulary-for-chapter-12/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-12/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 12 covers supervised learning and the statistics of predicting categorical variables. Also discussed are the issues of overfitting and generalizability and how to “train” statistical models.&lt;/p&gt;
&lt;p&gt;The vocabulary words for Chapter 12 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
predictors
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
characteristics measured for an observation that may be useful in predicting the target variable
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
overfitting
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future obervations reliably
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
generalization
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
refers to how well the concepts learned by a machine learning model apply to specific examples not seen by the model when it was learning
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
statistical learning
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
framework for machine learning drawing from the fields of statistics and functional analysis. Deals with the problem of finding a predictive function based on data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
objective response
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of supervised learning, a measurable response
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
kernel methods
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM). These use kernel functions, which enable them to operate in a high-dimensional, implicit feature space without ever computing the coordinates of the data in that space
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
statistical method that attempts to determine the strength and character of the relationship between one dependent variable (usually denoted by Y) and a series of other variables (known as independent variables)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
classification
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process of grouping observations in a dataset by their similarities in terms of measured characteristics
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
linear discriminant analysis (LDA)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a common technique used both for supervised learning classification and as a pre-processing dimension reduction step that finds a linear combination of features to help in classification
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
misclassification rate (MCR)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in regards to statistical learning, the fraction of times the prediction is wrong, specifically when relating to classification of models
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
leave-one out cross-validation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
k-fold cross validation taken to its logical extreme, with K equal to N, the number of data points in the set
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
k-fold cross-validation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a technique where observations are repeatedly split into a training set of size around n(k-1)/k and a test set of size of around n/k. Mainly used in prediction when one wants to estimate how accurately a predictive model will perform in practice
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
curse of dimensionality
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
refers to the fact that high-dimensional spaces are very hard, if not impossible, to sample thoroughly, because data in any particular region becomes very sparse as dimensions increase
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
confusion table
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the field of machine learning and specifically the problem of statistical classification, a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one. By counting the number of observations truly within each class versus the number predicted by the model to be in each class
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sensitvity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
true positivity rate or recall, measures the proportion of actual positives that are correctly identified as such
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
specificity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
true negative rate, the probability, measures the proportion of actual negatives that are correctly identified as negative
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
receiver operating characteristic(ROC)/precision recall curve
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a statistic used in quantifying the similarities between sample sets, which is formally defined as the size of the intersection between two sets divided by the size of the union of the sets
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
mean-squared error (MSE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the average squared error
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
risk function/cost function/objective function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the function that you optimize during the training of a predictive model (e.g., the maximum likelihood function for a classic regression model)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
bias
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measure of how different the average of all the different estimates is from the truth
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
how much an individual estimate might scatter from the average value
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
penalization
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a tool to actively control and exploit the variance-bias tradeoff
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
regularization
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method used to to ensure stable estimates by helping to prevent overfitting of the model to the training data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
logistic regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a statistical model that in its basic form uses a logistic function to model a binary dependent variable. A binary logistic model has a dependent variable with two possible values (e.g, healthy/sick) which are represented by indicator variables (0,1)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
penalty function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a term added to the objective function that consists of a penalty parameter multiplied by a measure of violation of the constraints
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
ridge regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method of regression in which the cost function is altered by adding a penalty equivalent to square of the magnitude of the coefficients. Doing this shrinks coefficients and helps reduce model complexity and mutli-collinearity
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
lasso
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of statistical regression modeling, Least Absolute Shrinkage and Selection Operator that is used in one type of regression modeling to reduce over-fitting and select useful features of hte data for predicting the outcome
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
elastic net
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the fitting of linear or logistic regression models, a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
ExperimentalHub
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of Bioconductor, provides a central location where curated data from experiments, publications or training courses can be accessed
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
kingdom
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the second highest taxonomic rank, just below domain
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
phylum
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a level of classification of taxonomic rank below kingdom and above class
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
species
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the basic unit of classification and a taxonomic rank of an organism, as well as unit of biodiversity
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
diagnostic plots
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
statistical influence plots that help to visualize how well a model fits the data (e.g. Normal Q-Q, Residuals vs Fitted)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
tuning parameters
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
parameters that control the strength of the penalty term in certain types of regression algorithms (e.g., ridge and lasso regression), controlling the amount of shrinkage (where parameter estimates are shrunk towards a central point, like the mean) when fitting the mode
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
p-value hacking
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
manipulation of the data until finding a statistic that yields a desired result
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
workflow
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of a computational analysis, the chaining of software tools together in a series of steps that operate on data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
scale invariance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a feature of objects or laws that do not change if scales, length, energy, or other variables, are multiplied by a common factor, and thus represent universality
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitions above are based in part or whole on listed definitions in the following source:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/&#34; class=&#34;uri&#34;&gt;https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://.statisticshowto.com&#34; class=&#34;uri&#34;&gt;https://.statisticshowto.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~schneide/tut5/node42.html&#34; class=&#34;uri&#34;&gt;https://www.cs.cmu.edu/~schneide/tut5/node42.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com&#34; class=&#34;uri&#34;&gt;https://towardsdatascience.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bioconductor.org&#34; class=&#34;uri&#34;&gt;https://bioconductor.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pfern.gtihub.io&#34; class=&#34;uri&#34;&gt;https://pfern.gtihub.io&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/506486027/flashcards/embed?i=takib&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exercise solution for Chapter 8, Part 1</title>
      <link>/post/ex-8-1/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/ex-8-1/</guid>
      <description>


&lt;div id=&#34;exercise-8.1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exercise 8.1&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Do the analyses of Section 8.5 with the &lt;code&gt;edgeR&lt;/code&gt; package and compare the results: make a scatterplot of the
log 10 p-values, pick some genes where there are large differences,
and visualize the raw data to see what is going on. Based on this can you explain the differences?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Most of the following code is taken straight from the book in section 8.5 for data cleaning/wrangling and the &lt;code&gt;DESeq2&lt;/code&gt; analysis. The steps performed in &lt;code&gt;edgeR&lt;/code&gt; are quite similar but we do see some differences that we will get to towards the end.&lt;/p&gt;
&lt;p&gt;First, we load our libraries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(pasilla)
library(edgeR)
library(dplyr)
library(DESeq2)
library(ggplot2)
library(pheatmap)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will use the same data used in the &lt;code&gt;DESeq2&lt;/code&gt; examples from the section 8.5.&lt;/p&gt;
&lt;p&gt;Load the example data using the &lt;code&gt;system.file()&lt;/code&gt; call for R data stored as part of a R package.
We then convert our data to a matrix object called &lt;code&gt;counts&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fn = system.file(&amp;quot;extdata&amp;quot;, &amp;quot;pasilla_gene_counts.tsv&amp;quot;,
                  package = &amp;quot;pasilla&amp;quot;, mustWork = TRUE)
counts = as.matrix(read.csv(fn, sep = &amp;quot;\t&amp;quot;, row.names = &amp;quot;gene_id&amp;quot;))

head(counts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             untreated1 untreated2 untreated3 untreated4 treated1 treated2
## FBgn0000003          0          0          0          0        0        0
## FBgn0000008         92        161         76         70      140       88
## FBgn0000014          5          1          0          0        4        0
## FBgn0000015          0          2          1          2        1        0
## FBgn0000017       4664       8714       3564       3150     6205     3072
## FBgn0000018        583        761        245        310      722      299
##             treated3
## FBgn0000003        1
## FBgn0000008       70
## FBgn0000014        0
## FBgn0000015        0
## FBgn0000017     3334
## FBgn0000018      308&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The matrix tallies the number of reads seen for each gene in each sample. We call it the count table. It has 14599 rows, corresponding to the genes, and 7 columns, corresponding to the samples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(counts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 14599     7&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;edger&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;edgeR&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Now begins the analysis with the &lt;code&gt;edgeR&lt;/code&gt; package. To do this, we follow the vignette for the package that is a downloadable .pdf file that you can get in your Rstudio session &lt;code&gt;vignette(&#34;edgeR&#34;)&lt;/code&gt; or online with &lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf&#34; class=&#34;uri&#34;&gt;https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here we make the &lt;code&gt;group&lt;/code&gt; object which is a vector with values representing the treatment status of each of the 7 samples, where 1 refers to the untreated group, and 2 refers to the treated group. With this &lt;code&gt;group&lt;/code&gt; object we can make a &lt;code&gt;DGEList()&lt;/code&gt;, from the &lt;code&gt;edgeR&lt;/code&gt; package, with our count data and the groups we just made. A &lt;code&gt;DGEList()&lt;/code&gt; object is very similar to any traditional R list object and can be manipulated like any other list in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;group &amp;lt;- factor(c(1,1,1,1,2,2,2))
x &amp;lt;- DGEList(counts=counts, group=group)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RNA-seq provides a measure of the relative abundance of each gene in each RNA
sample, but does not provide any measure of the total RNA output on a per-cell basis. In other words, RNA-seq measures relative expression rather than absolute expression. This can become an issue in RNA-seq when a small number of highly expressed genes consume a substantial proportion of the total library for a sample causing under sampling of the other expressed genes.&lt;br /&gt;
To help combat this we turn to normalization. &lt;code&gt;calcNormFactors&lt;/code&gt; normalizes by finding a set of scaling factors for the library sizes that minimizes the log-fold changes between the samples for most genes. Using a trimmed mean of M-values (TMM) between each pair of samples. If we receive a &lt;code&gt;norm.factors&lt;/code&gt; &lt;span class=&#34;math inline&#34;&gt;\(\lt\)&lt;/span&gt; 1 that means a small number of high count genes are monopolizing the sequencing reducing the counts of other genes. Conversely, a &lt;code&gt;norm.factors&lt;/code&gt; &lt;span class=&#34;math inline&#34;&gt;\(\gt\)&lt;/span&gt; 1 scales up the library size, analogous to downscaling the counts. This normalization can help account for things like varying sequencing depth, length of genes, and RNA composition.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;normalization &amp;lt;- calcNormFactors(x)
normalization&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class &amp;quot;DGEList&amp;quot;
## $counts
##             untreated1 untreated2 untreated3 untreated4 treated1 treated2
## FBgn0000003          0          0          0          0        0        0
## FBgn0000008         92        161         76         70      140       88
## FBgn0000014          5          1          0          0        4        0
## FBgn0000015          0          2          1          2        1        0
## FBgn0000017       4664       8714       3564       3150     6205     3072
##             treated3
## FBgn0000003        1
## FBgn0000008       70
## FBgn0000014        0
## FBgn0000015        0
## FBgn0000017     3334
## 14594 more rows ...
## 
## $samples
##            group lib.size norm.factors
## untreated1     1 13972512    0.9995731
## untreated2     1 21911438    1.0081519
## untreated3     1  8358426    0.9843974
## untreated4     1  9841335    0.9525077
## treated1       2 18670279    1.0651817
## treated2       2  9571826    0.9957012
## treated3       2 10343856    0.9978557&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;model.matrix()&lt;/code&gt; function creates a design matrix which is a matrix of values of &lt;strong&gt;explanatory variables&lt;/strong&gt; of a set of objects. Each row represents an individual object, with the successive columns corresponding to the variables and their specific values for that object. The purpose of this conversion is to prepare the data in a manner that facilitates regression-like modelling (ex. &lt;code&gt;glm&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;design &amp;lt;- model.matrix(~group)
head(design)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   (Intercept) group2
## 1           1      0
## 2           1      0
## 3           1      0
## 4           1      0
## 5           1      1
## 6           1      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;estimateDisp()&lt;/code&gt; function, “Maximizes the negative binomial likelihood to give the estimate of the common, trended and tagwise dispersions across all tags.” We have to use this negative binomial (aka gamma-Poisson) model since our experiments vary from replicate to replicate more than the traditional Poisson can account for. This variance can be due to seemingly miniscule experimental conditions such as, temperature of cell culture, pipettor calibration, etc. In the case of the gamma-Poisson we have two inputs for variance and mean instead of just having &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; for both variance and mean in the normal Poisson.
An important consideration that the &lt;code&gt;edgeR&lt;/code&gt; package has taken into account is the fact that RNA-seq and other Next Generation Sequencing projects are extremely expensive and generally have few samples. Accounting for dispersion with a small number of samples can be challenging and the &lt;code&gt;edgeR&lt;/code&gt; package tackles this conundrum using a qCML method. The qCML method calculates the likelihood by conditioning on the total counts for each tag, and uses pseudo counts after adjusting for library sizes. Given a table of counts or a &lt;code&gt;DGEList&lt;/code&gt; object, the qCML common dispersion and tagwise dispersions can be estimated using the &lt;code&gt;estimateDisp()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;design_matrix &amp;lt;- estimateDisp(normalization, design)
design_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## An object of class &amp;quot;DGEList&amp;quot;
## $counts
##             untreated1 untreated2 untreated3 untreated4 treated1 treated2
## FBgn0000003          0          0          0          0        0        0
## FBgn0000008         92        161         76         70      140       88
## FBgn0000014          5          1          0          0        4        0
## FBgn0000015          0          2          1          2        1        0
## FBgn0000017       4664       8714       3564       3150     6205     3072
##             treated3
## FBgn0000003        1
## FBgn0000008       70
## FBgn0000014        0
## FBgn0000015        0
## FBgn0000017     3334
## 14594 more rows ...
## 
## $samples
##            group lib.size norm.factors
## untreated1     1 13972512    0.9995731
## untreated2     1 21911438    1.0081519
## untreated3     1  8358426    0.9843974
## untreated4     1  9841335    0.9525077
## treated1       2 18670279    1.0651817
## treated2       2  9571826    0.9957012
## treated3       2 10343856    0.9978557
## 
## $design
##   (Intercept) group2
## 1           1      0
## 2           1      0
## 3           1      0
## 4           1      0
## 5           1      1
## 6           1      1
## 7           1      1
## attr(,&amp;quot;assign&amp;quot;)
## [1] 0 1
## attr(,&amp;quot;contrasts&amp;quot;)
## attr(,&amp;quot;contrasts&amp;quot;)$group
## [1] &amp;quot;contr.treatment&amp;quot;
## 
## 
## $common.dispersion
## [1] 0.0228685
## 
## $trended.dispersion
## [1] 0.12060195 0.04196786 0.11986264 0.12040360 0.01632837
## 14594 more elements ...
## 
## $tagwise.dispersion
## [1] 0.12060195 0.02742256 0.70902130 0.09430132 0.01321566
## 14594 more elements ...
## 
## $AveLogCPM
## [1] -2.636763  2.953356 -1.966526 -2.223010  8.454625
## 14594 more elements ...
## 
## $trend.method
## [1] &amp;quot;locfit&amp;quot;
## 
## $prior.df
## [1] 5.886884
## 
## $prior.n
## [1] 1.177377
## 
## $span
## [1] 0.3013916&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have our &lt;code&gt;design_matrix&lt;/code&gt; we can begin fitting modified linear models to it. Here we use a quasi-likelihood negative binomial generalized log-linear model, which is a mouth full. “Quasi-likelihood estimation is one way of allowing for overdispersion, that is, greater variability in the data than would be expected from the statistical model used.” Since we have already stated that we will have variation in our experiments, possibly due to the most minute factors, this issue of overdispersion is apparent. Instead of using traditional probability functions, a variance function is used (variance as a function of the mean) and allows for an overdispersion parameter input which is used to “fix” the variance function to resemble that of an existing probability function (ex. Poisson).&lt;/p&gt;
&lt;p&gt;The goal of this fit is to identify genes where the intensity level (gene expression level) is notably different between our treated and untreated groups.
Running the &lt;code&gt;glmQLF...()&lt;/code&gt; functions gives the null model against which the full model is compared. Tags can then be ranked in order of evidence for differential expression, based on the p-value computed for each tag.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit &amp;lt;- glmQLFit(design_matrix, design)
qlf &amp;lt;- glmQLFTest(fit, coef=2)
edgeRoutput &amp;lt;- topTags(qlf)

edgeRoutput&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Coefficient:  group2 
##                 logFC   logCPM        F       PValue          FDR
## FBgn0039155 -4.601317 5.882317 953.1722 1.646470e-14 2.403682e-10
## FBgn0025111  2.905756 6.923428 714.2877 1.257310e-13 9.177735e-10
## FBgn0035085 -2.548257 5.684922 452.3866 3.068717e-12 1.311741e-08
## FBgn0003360 -3.173036 8.452776 442.2207 3.594058e-12 1.311741e-08
## FBgn0029167 -2.188103 8.221274 412.0926 5.866109e-12 1.404698e-08
## FBgn0039827 -4.142255 4.397963 408.8548 6.195926e-12 1.404698e-08
## FBgn0034736 -3.492036 4.186934 403.9614 6.735313e-12 1.404698e-08
## FBgn0029896 -2.434452 5.305827 336.3777 2.386477e-11 4.355023e-08
## FBgn0000071  2.685868 4.795202 288.1793 6.900283e-11 1.119303e-07
## FBgn0034434 -3.624878 3.214994 282.6144 7.884818e-11 1.151105e-07&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(as.data.frame(qlf))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   logFC    logCPM          F     PValue
## FBgn0000003  1.90105753 -2.636763 1.40991069 0.25938432
## FBgn0000008  0.01020453  2.953356 0.00282599 0.95833875
## FBgn0000014 -0.21077864 -1.966526 0.03020978 0.86444776
## FBgn0000015 -1.61118380 -2.223010 1.65428857 0.21877991
## FBgn0000017 -0.23044399  8.454625 3.99686462 0.06492692
## FBgn0000018 -0.09673451  5.088412 0.53070377 0.47805393&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our outputs can be summarized by looking at our &lt;code&gt;logFC&lt;/code&gt; column (log fold change) where the higher the number the higher the count of that particular gene was read during the sequencing run. Secondly our &lt;code&gt;PValue&lt;/code&gt;, if it meets threshold (typically pvalue &amp;lt;= 0.05) allows the rejection of our null hypothesis, which is, there is equal expression regardless of what gene you look at.&lt;/p&gt;
&lt;p&gt;Now we want to visualize the data points after their regression fits. We must tidy up the data sets a bit to apply some &lt;code&gt;tidyverse&lt;/code&gt; magic. First the data is converted to a data frame, using &lt;code&gt;as.data.frame()&lt;/code&gt;, then we use the &lt;code&gt;rownames_to_column()&lt;/code&gt; function which sounds like its name, and pulls the row names, in this case &lt;code&gt;gene_id&lt;/code&gt;, into a new column of the dataframe. Lastly, we subset the data using the &lt;code&gt;select()&lt;/code&gt; function for only the columns we want, and order the data using the &lt;code&gt;arrange()&lt;/code&gt; function to start with the largest values with respect to the &lt;code&gt;padj&lt;/code&gt; via the &lt;code&gt;desc()&lt;/code&gt; argument inside &lt;code&gt;arrange()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_pasilla &amp;lt;- pasilla %&amp;gt;% 
  results() %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  rownames_to_column(var = &amp;quot;gene_id&amp;quot;) %&amp;gt;% 
  select(gene_id, pvalue, padj) %&amp;gt;% 
  arrange(desc(padj))

tidy_edgeR &amp;lt;- qlf %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  rownames_to_column(var = &amp;quot;gene_id&amp;quot;) %&amp;gt;%
  select(gene_id, PValue)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using &lt;code&gt;full_join()&lt;/code&gt; from &lt;code&gt;dplyr&lt;/code&gt; package we are able to subset these two data frames based on the &lt;code&gt;gene_id&lt;/code&gt; column and keeping all other matching columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_join(tidy_pasilla, tidy_edgeR, 
          &amp;quot;gene_id&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = pvalue, y = PValue)) +
  labs(x = &amp;quot;DESeq2 pvalue&amp;quot;, y = &amp;quot;edgeR PValue&amp;quot;) +
  scale_x_log10() +
  scale_y_log10() +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = &amp;quot;blue&amp;quot;) +
  geom_vline(xintercept = 1e-25, color = &amp;quot;red&amp;quot;) +
  ggtitle(&amp;quot;DESeq2 vs EdgeR&amp;quot;, subtitle = &amp;quot;Each point represents a single gene, p-value is for whether 
          the gene has differential expression between groups&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-30-exercise-solution-for-chapter-8_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The reference line drawn in blue here using &lt;code&gt;geom_abline()&lt;/code&gt; is to show what the data would look like if the two methods were identical.
Looking at the graph above, we see that most of the data are falling relatively close to one another when our pvalue &lt;span class=&#34;math inline&#34;&gt;\(\gt\)&lt;/span&gt; 1e-25. We know this because the alpha of the &lt;code&gt;ggplot&lt;/code&gt; object is set to 0.5, so if we see a black dot, it means there are two points, one on top of each other. This is what we would expect considering these packages &lt;code&gt;DESeq2&lt;/code&gt; and &lt;code&gt;edgeR&lt;/code&gt; have the same purpose in mind and is why we are comparing their outputs in this exercise!&lt;/p&gt;
&lt;p&gt;Below we subset the data again, this time selecting those points with pvalues &lt;span class=&#34;math inline&#34;&gt;\(\leq\)&lt;/span&gt; 1e-25 (log10 transform). When plotting these we don’t see much overlapping, supporting the variation between the &lt;code&gt;edgeR&lt;/code&gt; and &lt;code&gt;DESeq2&lt;/code&gt; modes of analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_join(tidy_pasilla, tidy_edgeR,&amp;quot;gene_id&amp;quot;) %&amp;gt;% 
  filter(pvalue &amp;lt;= 1e-25) %&amp;gt;%
  ggplot(aes(x = pvalue, y = PValue)) +
  labs(x = &amp;quot;DESeq2 pvalue&amp;quot;, y = &amp;quot;edgeR PValue&amp;quot;) +
  geom_point(alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle(&amp;quot;Genes with DESeq pvalue &amp;lt;= -25&amp;quot;, subtitle = &amp;quot;Each point represents a single gene, p-value is for whether 
          the gene has differential expression between groups&amp;quot;) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-30-exercise-solution-for-chapter-8_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf&#34; class=&#34;uri&#34;&gt;https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Quasi-likelihood&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Quasi-likelihood&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/bios221/book/Chap-CountData.html&#34; class=&#34;uri&#34;&gt;http://web.stanford.edu/class/bios221/book/Chap-CountData.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf&#34; class=&#34;uri&#34;&gt;https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://geanders.github.io/RProgrammingForResearch/&#34; class=&#34;uri&#34;&gt;https://geanders.github.io/RProgrammingForResearch/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class on April 30</title>
      <link>/post/details-for-class-on-april-30/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-on-april-30/</guid>
      <description>


&lt;div id=&#34;links-for-april-30&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for April 30&lt;/h2&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group 1 (Sierra, Camron, Sere): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_NjA3Y2Q5MDYtYTM5OS00MzAyLWEwMzAtMzdmNWMzYzhmMTUw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 2 (Burton, Mikaela, Sherry, Amy): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_M2I3YmViYjMtNWJlNC00M2E5LTg5NTItNzI0N2VlYmVkNzUz%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 3 (Daniel, James, Sarah): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_YjE4ZGJhNjItYTViMS00MjZjLTk4NWUtMjBhY2E3OTJiOGQw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-links&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional links&lt;/h2&gt;
&lt;p&gt;More on spatial point processes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://crd150.github.io/lab6.html&#34; class=&#34;uri&#34;&gt;https://crd150.github.io/lab6.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://spatstat.org/&#34; class=&#34;uri&#34;&gt;http://spatstat.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://training.fws.gov/courses/references/tutorials/geospatial/CSP7304/documents/PointPatterTutorial.pdf&#34; class=&#34;uri&#34;&gt;https://training.fws.gov/courses/references/tutorials/geospatial/CSP7304/documents/PointPatterTutorial.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More on &lt;code&gt;EBImages&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/vignettes/EBImage/inst/doc/EBImage-introduction.html&#34; class=&#34;uri&#34;&gt;https://www.bioconductor.org/packages/release/bioc/vignettes/EBImage/inst/doc/EBImage-introduction.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;vocabulary-quiz-for-april-30&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vocabulary quiz for April 30&lt;/h2&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdyhEmMFLukgfMVzG2SNBbqXk4wYr0bzcTQM5KbxQUYsc0pIg/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2972&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 11</title>
      <link>/post/vocabulary-for-chapter-11/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-11/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 11 is focused on learning how to read, write, and manipulate images in R. The first sections are helping the reader understand when to apply different filters and transformations to an image and why it is necessary. It then touches on segmentation and feature extraction, two components that are utilized to simplify an image for machine learning and recognition. Finally, statistal methods are introduced to analyze spacial distributions and spatial point process is introduced on a basic level.&lt;/p&gt;
&lt;p&gt;The vocabulary words for Chapter 11 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
segmentation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
partitioning an image to assign a label to every pixel or group of pixels with similar characteristics
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
slot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a part, element, or “property” of an object in the context of object-oriented programming in R
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
classification
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process of grouping observations in a dataset by their similarities in terms of measured characteristics
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
feature extraction
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process of building derived values to describe observations or features from the initial set of measured data, with the aim of creating a new set of characteristics that is informative.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
spatial point process
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
mechanism that generates a random collection of coordinates or points randomly located along an underlying mathematical space. There is at most one point observed at any location.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Poisson process
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
mechanism that generates instantaneous events (in time and/or space) based on the Poisson distribution
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Ripley’s K function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a descriptive statistic for detecting the deviations from spatial homogeneity that can help determine if points are random, dispersed, or clustered
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
pair correlation function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a description of how the point density varies as a function of distance from the point of reference
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
spatial transformation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
changes to a coordinate system that provides a new approach to defining variation of material parameters
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
linear filter
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a tool for refining an image such that the output pixel is a combination of the time-varying input pixels subject to the constraint of linearity
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dynamic range
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the ratio or logarithmic value of the difference between the largest and smallest values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
noise reduction
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process of removing the undesirable variation in image pixelation
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
adaptive thresholding
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
segmenting an image using smaller regions that are defined by the range of local intensity values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
binary image
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an image consisting of pixels that can only have one of exactly two values, usually black and white
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
morphological operation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
image processing in which each individual pixel in the image is adjusted based on the other pixels in the neighborhood
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Voronoi tessellation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
partitioning an image plane into regions closest to each set of points. Line segments are formed equidistant to the two nearest points
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
convex hull
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the smallest polygon that encloses all of the points of interest in a set
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
spatial dependence
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the propensity for nearby points to influence each other and possess similar attributes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
virion
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
infectious nucleic acid surrounded by a protective protein capsid
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
actin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
globular proteins that form the microfilaments essential for cell mobility and division
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
macrophages
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
immune cells responsible for engulfing potential pathogens and other lymphatic particles
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dendritic cells
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
immune cells responsible for processing foreign material and presenting it to other cells in the immune system
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
light sheet microscopy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method that illuminates a specimen in a single plane and detected from the perpendicular direction
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources Consulted&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cso.ie/en/methods/classifications/classificationsexplained/&#34; class=&#34;uri&#34;&gt;https://www.cso.ie/en/methods/classifications/classificationsexplained/&lt;/a&gt;
&lt;a href=&#34;http://www.stat.umn.edu/geyer/8501/points.pdf&#34; class=&#34;uri&#34;&gt;http://www.stat.umn.edu/geyer/8501/points.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4528837/&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4528837/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.e-education.psu.edu/natureofgeoinfo/c1_p18.html&#34; class=&#34;uri&#34;&gt;https://www.e-education.psu.edu/natureofgeoinfo/c1_p18.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.leica-microsystems.com/science-lab/topics/light-sheet-microscopy/&#34; class=&#34;uri&#34;&gt;https://www.leica-microsystems.com/science-lab/topics/light-sheet-microscopy/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.mathworks.com/help/images/morphological-filtering.html&#34; class=&#34;uri&#34;&gt;https://www.mathworks.com/help/images/morphological-filtering.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/504650205/flashcards/embed?i=22uyf&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class on April 23</title>
      <link>/post/details-for-class-on-april-23/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-on-april-23/</guid>
      <description>


&lt;div id=&#34;links-for-april-23&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for April 23&lt;/h2&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group 1 (Sierra, Sarah, Daniel, Sere): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_NjA3Y2Q5MDYtYTM5OS00MzAyLWEwMzAtMzdmNWMzYzhmMTUw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 2 (Mikaela, Sherry, James): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_M2I3YmViYjMtNWJlNC00M2E5LTg5NTItNzI0N2VlYmVkNzUz%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 3 (Burton, Camron, Amy): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_YjE4ZGJhNjItYTViMS00MjZjLTk4NWUtMjBhY2E3OTJiOGQw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-links&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Link for HIV amino acid sequences: &lt;a href=&#34;https://www.hiv.lanl.gov/content/sequence/NEWALIGN/align.html&#34; class=&#34;uri&#34;&gt;https://www.hiv.lanl.gov/content/sequence/NEWALIGN/align.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Online book on &lt;code&gt;ggtree&lt;/code&gt;: &lt;a href=&#34;https://yulab-smu.github.io/treedata-book/&#34; class=&#34;uri&#34;&gt;https://yulab-smu.github.io/treedata-book/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Introductory vignette for &lt;code&gt;phangorn&lt;/code&gt;: &lt;a href=&#34;https://cran.r-project.org/web/packages/phangorn/vignettes/Trees.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/phangorn/vignettes/Trees.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vignette for &lt;code&gt;ape&lt;/code&gt;: &lt;a href=&#34;https://cran.r-project.org/web/packages/ape/vignettes/MoranI.pdf&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/ape/vignettes/MoranI.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Online book with (much!) more on studying networks: &lt;a href=&#34;http://networksciencebook.com/&#34; class=&#34;uri&#34;&gt;http://networksciencebook.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Relevant COVID-19 article: &lt;a href=&#34;https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30273-5/fulltext#.Xp_6SyUko0Y.twitter&#34; class=&#34;uri&#34;&gt;https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30273-5/fulltext#.Xp_6SyUko0Y.twitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;slido-comments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Slido comments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://admin.sli.do/event/lkcufqsv/questions&#34; class=&#34;uri&#34;&gt;https://admin.sli.do/event/lkcufqsv/questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;vocabulary-quiz-for-april-23&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vocabulary quiz for April 23&lt;/h2&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSetjCYOqAoDU3J-6mVx8QEbTWfjy1u7u26Dl40dOGARA4Hm4A/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2907&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 10</title>
      <link>/post/vocabulary-for-chapter-10/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-10/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 10 discusses the use of networks and trees to visualize biological data. It covers the main components of each and how different data sets can be appropriately transformed into specific networks and trees based on what you are trying to present. The vocabulary words for Chapter 10 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Graph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A structure formed by a set of nodes or vertices and a set of edges between these vertices
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Adjacency matrix
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The matrix representation of edges of a graph with as many rows as nodes in the graph
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Network
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A weighted, directed graph
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Sparse
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of graphs, a term to describe a graph when the number of edges is similar to the number of nodes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Dense
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of graphs, a term to describe a graph when the number of edges is (approximately) a quadratic function of the nodes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Arrows/directed edges
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Graph edges that directionally connect nodes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Annotation variables
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Graph visualization characteristics that help to demonstrate strength of a link in a graph by changing the width of the edge or covariates associated to the size or color of the node
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Graph layouts
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Different ways to plot a graph, either for aesthetic or practical reasons
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Binary data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Data in which each observation can take only one of two values (e.g., 0 or 1)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Differentially expressed genes
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A term to describe changes in gene expression levels between different experimental groups
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bipartite graph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A graph where each edge connects a node
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Overrepresented or enriched
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of gene expresion, a term to describe increased expression of a gene / set of genes of interest
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Gene Ontology (GO)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A resource aimed to unify the vocabulary to describe genes and gene product attributes across all species
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Fisher’s exact test / Hypergeometric testing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Two-way table testing used to account for the fact that some categories are extremely numerous and others are rarer
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Known skeleton graph
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A graph that projects significance scores such as p-values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Perturbation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of a network, an alteration of the function of a biological system, induced by external or internal mechanisms
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Hotspots
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of a graph, areas with high event density
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Rooted binary tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A data tree in which each node has at most two children
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Cycles
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of graphs, another word for loops: either self-loops or ones that go through several vertices
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Ancestral taxa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Correspond to inner nodes and are inferred from the contemporaneous data on the tips
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Contemporaneous
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of data for phylogenetic tress, organisms at terminal nodes that exist at the same time and are related to each other, thus revealing information about their common ancestors
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
OTUs (Operational Taxonomic Units)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of clustering organisms based on DNA similarity of a certain taxonomic marker gene (Tips of the tree)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Parameter
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of statistics, numerical value that describes a population
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Gene trees
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Structures produced when different genes show differences in their evolutionary histories
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Markov chain
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A sequence where given the current state, the next state is conditionally independent of all previous states
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Molecular clock hypothesis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A term that describes a technique that uses the mutation rate to infer what happened to a species historically
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Non-identifiability
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The inability to distinguish a parameterization of a model based on observed data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Time homogeneity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of Markov chains, the state of the mutation rate being constant across history
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Generator
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of Markov chains, the instantaneous change probability matrix describing transitions between steps of the chain
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Transition matrix
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A matrix that contains all probabilities of any state changes for a Markov chain
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Parsimony tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A structure created using nonparametric method that minimizes the number of changes necessary to explain the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Maximum likelihood tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A structure created using a parametric method that uses efficient optimization algorithms to maximize the likelihood of a tree under the model assumptions.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bayesian posterior distributions for trees
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method that uses MCMC to find posterior distributions of the phylogenies
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Distance-based methods
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Semi-parametric methods similar to the hierarchical clustering algorithms but use the parametric evolutionary models
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Aligning
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Arranging different sequences of DNA, RNA, or protein together to identify similarities or differences between them
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
indel (inserted-deleted) event
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Insertion or deletion of bases in the genome of an organism
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Filtering operations
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of low-quality rRNA reads, the removal of low-quality reads and trimming of remaining reads to a consistent length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Interactive
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of a plot, enabling direct actions on a graphical plot to change elements and link multiple plots
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Spanning tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A tree that goes through all points at least once
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Minimum spanning tree (MST)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Given distances between vertices, a tree that spans all the points and has the minimum total length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jitter
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
To slightly move coordinates on a graph to avoid too much overlapping
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Undirected network
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A term describing a graph without arrows between nodes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Associated
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A term indicating that two variables are related
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Friedman-Rafsky tests
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Tests for two/multiple sample segregation on a minimum spanning tree
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Pure edges
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of graphs, edges whose two nodes have the same level of the factor variable
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Microbiome
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The aggregate of all microbiota that reside on or within an organism tissues and biofluids along with the corresponding anatomical sites in which they reside
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Exponential random graph models (ERGMs)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Models that can be used to predict vertex covariates
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Protein interaction networks
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of graphing, a way to visualize observed protein-protein interactions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Phylogenetic tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A tree used to visualize evolutionary relationships among species
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Strain
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of a virus, a genetic variant or subtype
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Taxa
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A group of one or more populations of an organism making up a single unit, typically disected to the level of genus and species
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Protein
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A compound made up of amino acids; one of the four types of macromolecules that make up living organisms.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitions above are based in part or whole on listed definitions
in the following sources.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Everitt and Skrondal, 2010. &lt;em&gt;The Cambridge Dictionary of Statistics (Fourth Edition).&lt;/em&gt; Cambridge University Press, Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;http://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/333490771/flashcards/embed?i=km5j1&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exercise solution for Chapter 9</title>
      <link>/post/exercise-solution-for-chapter-9/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-chapter-9/</guid>
      <description>


&lt;div id=&#34;exercise-9.2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 9.2&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;“Correspondence Analysis on color association tables:
Here is an example of data collected by looking at the number of Google hits resulting from queries of pairs of words. The numbers in Table 9.4 &lt;em&gt;[not reproduced]&lt;/em&gt; are to be multiplied by 1000. For instance, the combination of the words “quiet” and “blue” returned 2,150,000 hits. Perform a correspondence analysis of these data. What do you notice when you look at the two-dimensional biplot?&#34;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this exercise, we will essentially be repeating the correspondence analysis process seen in section 9.4.2, this time using associations between color and sentiment terms in search engine queries, rather than hair and eye color. Rather than testing whether certain hair/eye combinations are more likely to co-occur, we will be exploring whether a given color is more or less likely to be associated with certain sentiments (e.g. would we expect “orange” and “happy” to co-occur more frequently than would be expected by chance?). The same general steps can be repeated without many changes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-loading-libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step 1: Loading libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ade4)
library(sva)
library(tidyverse)
library(factoextra)
library(janitor) #optional; function `clean_names()` makes column names easier to work with
library(ggplot2)
library(ggrepel)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-two-ways-to-load-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step 2: Two ways to load data:&lt;/h1&gt;
&lt;p&gt;At least working from the online version of the text, there are two ways to obtain (roughly) equal data for this exercise. One option is to copy table 9.4 directly from the book into Excel, shift the header one cell to the right to align columns with their proper names, export a .csv (&lt;code&gt;ex_9.2_color_table.csv&lt;/code&gt; in this example), and load it into R using a command like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_matrix &amp;lt;- read_csv(&amp;quot;example_datasets/ex_9_2_color_table.csv&amp;quot;, col_names = TRUE) %&amp;gt;%
  column_to_rownames(var = &amp;#39;X1&amp;#39;) %&amp;gt;%
  as.matrix&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Something to note is that this data is rounded to units of thousands (e.g. “19” is ~19,000), while the course data in the downloadable &lt;code&gt;data&lt;/code&gt; file gives more-precise values. I don’t know that this would disrupt any major correlations, but it could cause some minor discrepancies on comparison.&lt;/p&gt;
&lt;p&gt;Alternatively, the file is included in the course data as &lt;code&gt;colorsentiment.csv&lt;/code&gt;, although in a different, three-column format:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(read_csv(&amp;quot;example_datasets/colorsentiment.csv&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   `&amp;lt;X&amp;gt;` = col_character(),
##   `&amp;lt;Y&amp;gt;` = col_character(),
##   Results = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   `&amp;lt;X&amp;gt;` `&amp;lt;Y&amp;gt;`     Results
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 blue  happy     8310000
## 2 blue  depressed  957000
## 3 blue  lively    1250000
## 4 blue  clever    1270000
## 5 blue  perplexed   71300
## 6 blue  virtuous    80200&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can be converted to match our correspondence table format using the &lt;code&gt;pivot_wider&lt;/code&gt; function and other &lt;code&gt;tidyverse&lt;/code&gt; formatting tools:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_matrix &amp;lt;- read_csv(&amp;quot;example_datasets/colorsentiment.csv&amp;quot;) %&amp;gt;%
  janitor::clean_names() %&amp;gt;% #standardizes column name format
  arrange(desc(results)) %&amp;gt;% # Rearranging to match row/col order in table 9.4
  pivot_wider(names_from = x, values_from = results) %&amp;gt;% # converts colors from column entries (`x`) to column names
  column_to_rownames(var = &amp;#39;y&amp;#39;) 

color_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              black   white   green    blue  orange  purple    grey
## happy     19300000 9150000 8730000 8310000 4220000 2610000 1920000
## angry      2970000 1730000 1740000 1530000 1040000  710000  752000
## quiet      2770000 2510000 2140000 2150000 1220000  821000  875000
## lively     1840000 1480000 1350000 1250000  621000  488000  659000
## clever     1650000 1420000 1320000 1270000  693000  416000  495000
## depressed  1480000 1270000  983000  957000  330000  102000  147000
## virtuous    179000  165000  102000   80200   24700   17300   20000
## perplexed   110000  109000   80100   71300   23300   15200   18900&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;correspondence-analysis-following-section-9.4.2-as-a-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correspondence Analysis (following section 9.4.2 as a model)&lt;/h1&gt;
&lt;p&gt;Setting up the correspondence analysis object using the correspondence analysis &lt;code&gt;dudi&lt;/code&gt; function from the &lt;code&gt;ade4&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_matrix_ca &amp;lt;- dudi.coa(color_matrix, n = 2, scannf = FALSE) # scannf = FALSE stops automatic printing of eigenvalues&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a special “&lt;em&gt;Du&lt;/em&gt;ality &lt;em&gt;Di&lt;/em&gt;agram” list object (used by the &lt;code&gt;ade4&lt;/code&gt; package for correspondence analysis, but also principal component analysis and other methods) containing a variety of data generated by the analysis; the call &lt;code&gt;?dudi()&lt;/code&gt; will give a list of what each component contains (axis weights, point coordinates, etc.).Stored features include as the base data table (&lt;code&gt;tab&lt;/code&gt;), a vector of eigenvalues (&lt;code&gt;eig&lt;/code&gt;), and a variety of information on row and column data (e.g. weights, coordinates, and principal components).&lt;/p&gt;
&lt;p&gt;Question 9.2 specifies that we use two dimensions, but visualizing the eigenvalues with the &lt;code&gt;factoextra&lt;/code&gt; package confirms that this is a good representation of the system, with almost all variance being explained by the first two dimensions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fviz_eig(color_matrix_ca, geom = &amp;#39;bar&amp;#39;) # visualizing eigenvalues &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Following the book’s example in 9.4.2, we can explicitly calculate a residual matrix, which shows the difference between expected (assuming random distribution) and observed values for given row/column intercepts, in the following steps. This doesn’t feed into visualizations, but it may be helpful to have a quantitative reference for residuals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rowsums_colors &amp;lt;- as.matrix(apply(color_matrix, 1, sum))
colsums_colors &amp;lt;- as.matrix(apply(color_matrix, 2, sum))
expected_colors &amp;lt;- rowsums_colors %*% t(colsums_colors) / sum(colsums_colors) # using matrix multiplication to see what 
# &amp;quot;average&amp;quot; values should look like if row and column sums are distributed evenly across the dataset

#sum((color_matrix - expected_colors)^2 / expected_colors)

# subtracting the &amp;quot;expected&amp;quot; matrix from the observed  values to see discrepancies

(residual_table_colors &amp;lt;- color_matrix - expected_colors %&amp;gt;% 

    t() %&amp;gt;% 

    round())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              black    white    green     blue   orange  purple    grey
## happy      2604538  7252731  6644019  7090159  3616948 2332753 1890798
## angry     -6856953   -19511  -241131   891748   657779  448415  620320
## quiet     -6291637   848427  1103422  1745469   859372  639948  797493
## lively    -6766161   610622   693006   868322 -1000836  381433  587529
## clever    -2852964   868979   700121  -965911  -261613  317732  427122
## depressed -1374026   750108 -1383422  -359058  -550269    8671  111484
## virtuous  -2513797 -3678280 -1290876 -1133364  -811323  -31532   -2510
## perplexed -3113357 -2153156 -1204300 -1081265  -414128  -15750   -2339&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, we can see that, for instance, the combination of “happy” and “black” in searches occurs significantly more often (~26,000,000 additional instances) than we’d expect given no correlations between colors and sentiments, while e.g. “happy” and “grey” is much rarer.&lt;/p&gt;
&lt;p&gt;To take these patterns more intuitively, we can use a mosaic plot to visualize the proportional distribution of color/sentiment terms in searches (e.g. “back” and “happy” are both popular terms, so could be expected to occur more frequently than e.g. “perplexed” and “purple” in any case), as well as color coding for residuals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mosaicplot(t(color_matrix / 2000), las = 2, shade = TRUE, type = &amp;#39;pearson&amp;#39;) # dividing values by 2,000 because the mosaic plot function doesn&amp;#39;t seem to auto-scale colors, meaning that the unaltered matrix is all &amp;quot;flattened&amp;quot; to the &amp;lt;4 or &amp;gt;4 category.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  #transposing is just aesthetic; seems easier to follow with sentiments on the y axis as far as labels and visual row/column continuity. &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From this pattern, it’s easier to see broad patterns and associations among colors and sentiments. For instance, if we focus on colors, we can see &lt;code&gt;black&lt;/code&gt; is quite distinct from most colors, with more than expected with &lt;code&gt;happy&lt;/code&gt; and lower for other sentiments. All other sentiments behave more like each other than &lt;code&gt;black&lt;/code&gt;, but do show a smaller division between &lt;code&gt;white&lt;/code&gt;, &lt;code&gt;blue&lt;/code&gt;, and &lt;code&gt;green&lt;/code&gt;; this is distinguished from &lt;code&gt;orange&lt;/code&gt;, &lt;code&gt;purple&lt;/code&gt;, and &lt;code&gt;grey&lt;/code&gt; by being rarer than expected (under random distribution) with &lt;code&gt;angry&lt;/code&gt; and more common with &lt;code&gt;depressed&lt;/code&gt;, &lt;code&gt;virtuous&lt;/code&gt;, and &lt;code&gt;perplexed&lt;/code&gt;. Based on this, in a 2D projection we might expect to see the largest separation between &lt;code&gt;black&lt;/code&gt; and all other colors, with a smaller but obvious distinction between the two other color clusters. Because &lt;code&gt;quiet&lt;/code&gt;, &lt;code&gt;lively&lt;/code&gt;, and &lt;code&gt;clever&lt;/code&gt; are more common than expected for everything but black, the will likely be about equidistant between these clusters.&lt;/p&gt;
&lt;p&gt;To check how close we got with these eyeballed estimates, we can use the &lt;code&gt;factoextra&lt;/code&gt; biplot visualization function &lt;code&gt;fviz_ca_biplot&lt;/code&gt; for correspondence analysis to see our biplot for sentiment and color searches. I thought using the option to represent one as vector arrow, rather than points, also improves legibility (e.g. the relationship between &lt;code&gt;angry&lt;/code&gt; and &lt;code&gt;orange&lt;/code&gt;/&lt;code&gt;purple&lt;/code&gt; become more obvious):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fviz_ca_biplot(color_matrix_ca, arrows = c(FALSE, TRUE), repel = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/fviz%20biplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As we can see, sentiment and color groups show similar relationships from what we might expect comparing patterns of positive/negative residuals in the mosaic plot. However, this makes it easier to see some patterns, such as the strong opposition between &lt;code&gt;black&lt;/code&gt; and &lt;code&gt;grey&lt;/code&gt; on dimension 1, or the fact that most of dimension 2 is due to the differences of &lt;code&gt;green-white-blue&lt;/code&gt; and &lt;code&gt;perplexed-depressed-virtuous&lt;/code&gt; from the rest of the data. We can also make out some smaller trends that weren’t obvious (at least to me) from the mosaic visualization, like &lt;code&gt;grey&lt;/code&gt; being more distinct from &lt;code&gt;orange&lt;/code&gt; and &lt;code&gt;purple&lt;/code&gt; than we could make out with the mosaic plot’s effective “resolution”. This separation appears to be driven by higher co-occurrence with &lt;code&gt;lively&lt;/code&gt;, &lt;code&gt;quiet&lt;/code&gt;, and &lt;code&gt;clever&lt;/code&gt;. Looking back to our mosaic plot, the latter three have lighter shades of blue in &lt;code&gt;orange&lt;/code&gt; and &lt;code&gt;purple&lt;/code&gt;, with no obvious difference with &lt;code&gt;angry&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-directly-with-ggplot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plotting directly with &lt;code&gt;ggplot&lt;/code&gt;:&lt;/h1&gt;
&lt;p&gt;While &lt;code&gt;factoextra&lt;/code&gt; uses custom functions to streamline the process, it’s possible to approximate the same visualization using &lt;code&gt;ggplot&lt;/code&gt; and components of the &lt;code&gt;dudi&lt;/code&gt; object. In the &lt;code&gt;color_matrix_ca&lt;/code&gt; object, the ‘row’ and ‘column’ factor coordinates (emotion and color, respectively) are stored at &lt;code&gt;.$li&lt;/code&gt; and &lt;code&gt;.$co&lt;/code&gt;, This allows direct plotting; you could also look at e.g. normalized scores in &lt;code&gt;.$l1&lt;/code&gt; and &lt;code&gt;.$c1&lt;/code&gt; as well. I was able to get a general sense of how the &lt;code&gt;factoextra&lt;/code&gt; authors approached this using the call &lt;code&gt;View(fviz_ca_biplot)&lt;/code&gt; to pull up the function’s R code; this ultimately pointed to the more fundamental &lt;code&gt;fviz&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Using this information, we can render single plots for color:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Single plots: (roughly equivalent to default output for `fviz_ca_col` and `fviz_ca_row`)

color_nmds &amp;lt;- color_matrix_ca$co %&amp;gt;%
  ggplot() + 
  aes(x = Comp1, y = Comp2) +
  geom_point(color = &amp;#39;blue&amp;#39;) +
  geom_text(label = rownames(color_matrix_ca$co), nudge_y = 0.01, color = &amp;#39;blue&amp;#39;) + 
  coord_fixed()

color_nmds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/ggplot_single_plots-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and sentiment (&lt;em&gt;below&lt;/em&gt;). We can also use the &lt;code&gt;geom_segment&lt;/code&gt; function in &lt;code&gt;ggplot&lt;/code&gt; to replicate the arrows seen in the &lt;code&gt;factoExtra&lt;/code&gt; biplot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;emotion_nmds &amp;lt;- color_matrix_ca$li %&amp;gt;%
  ggplot() + 
  aes(x = Axis1, y = Axis2) +
  geom_point(color = &amp;#39;red&amp;#39;) +
  ggrepel::geom_text_repel(label = rownames(color_matrix_ca$li), nudge_y = 0.01, color = &amp;#39;red&amp;#39;) +
  geom_segment(aes(x = 0, y = 0, xend = Axis1, yend = Axis2), 

               arrow = arrow(length = unit(0.3,&amp;quot;cm&amp;quot;)), 

               color = &amp;quot;red&amp;quot;) +
  coord_fixed()
  

emotion_nmds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/emotion_nmds_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can combine these elements into a biplot by combining the above dataframes, with one column for each value, and plotting the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Biplot (there are probably more efficient/correct approaches)

#manually joining the two datasets using a common index (generates a partial row of NAs, with 8 sentiments and 7 colors)

color_component &amp;lt;- color_matrix_ca$co %&amp;gt;%
  rownames_to_column(var = &amp;quot;color&amp;quot;) %&amp;gt;%
  rownames_to_column(var = &amp;quot;index&amp;quot;)

emotion_component &amp;lt;- color_matrix_ca$li %&amp;gt;%
  rownames_to_column(var = &amp;quot;emotion&amp;quot;) %&amp;gt;%
  rownames_to_column(var = &amp;quot;index&amp;quot;)

biplot_composite &amp;lt;- color_component %&amp;gt;%
  full_join(emotion_component, by = &amp;quot;index&amp;quot;)

(biplot_composite)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   index  color       Comp1       Comp2   emotion       Axis1       Axis2
## 1     1  black  0.17794592  0.04039331     happy  0.11532145  0.01602901
## 2     2  white -0.05317953 -0.10399481     angry -0.10756934  0.09837664
## 3     3  green -0.03347037 -0.03237667     quiet -0.20048082 -0.01564279
## 4     4   blue -0.03552655 -0.04588027    lively -0.20105512  0.01174266
## 5     5 orange -0.09284092  0.07047109    clever -0.17886743 -0.03423825
## 6     6 purple -0.15049601  0.15422498 depressed  0.03935532 -0.24782949
## 7     7   grey -0.36826914  0.10335528  virtuous  0.05572888 -0.24684976
## 8     8   &amp;lt;NA&amp;gt;          NA          NA perplexed -0.04792928 -0.22173448&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;biplot_composite_plot &amp;lt;- biplot_composite %&amp;gt;%
  ggplot() +
  aes(x = Comp1, y = Comp2) +
  geom_point(color = &amp;#39;red&amp;#39;) +
  geom_text(label = biplot_composite$color, nudge_y = 0.01, color = &amp;#39;red&amp;#39;) +
   geom_segment(aes(x = 0, y = 0, xend = Comp1, yend = Comp2), 

               arrow = arrow(length = unit(0.3,&amp;quot;cm&amp;quot;)), 

               color = &amp;quot;red&amp;quot;) + 
  geom_point(aes(x = Axis1, y = Axis2), color = &amp;#39;blue&amp;#39;) +
  geom_text_repel(aes(x = Axis1, y = Axis2), label = biplot_composite$emotion, nudge_y = 0.01, color = &amp;#39;blue&amp;#39;) +
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = paste0(&amp;quot;Dim1(&amp;quot;,round(color_matrix_ca$eig[1]/sum(color_matrix_ca$eig)*100, 1),&amp;quot;%)&amp;quot;),
       y = paste0(&amp;quot;Dim2(&amp;quot;,round(color_matrix_ca$eig[2]/sum(color_matrix_ca$eig)*100, 1),&amp;quot;%)&amp;quot;) +
       coord_fixed()
       ) 

biplot_composite_plot&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 1 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 1 rows containing missing values (geom_text).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 1 rows containing missing values (geom_segment).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/biplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;second-approach&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Second Approach&lt;/h1&gt;
&lt;p&gt;Dr. Anderson also worked out a more-efficient approach making use of &lt;code&gt;purrr&lt;/code&gt; package function, &lt;code&gt;unclass&lt;/code&gt;, &lt;code&gt;map_at&lt;/code&gt; and other tools to unite the two &lt;code&gt;coa / dudi&lt;/code&gt; objects with fewer intermediate steps:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_matrix_ca %&amp;gt;% 
  # `unclass` to work with this as a regular list
  unclass() %&amp;gt;% 
  # `keep` lets you keep just some elements of a list. We&amp;#39;ll keep &amp;quot;co&amp;quot; and &amp;quot;li&amp;quot; elements
  keep(names(.) %in% c(&amp;quot;co&amp;quot;, &amp;quot;li&amp;quot;)) %&amp;gt;% 
  # both of these have important info in their rownames, so move those into a column.
  # `map` allows you to do the same thing to every element of the list (now just &amp;quot;co&amp;quot; and &amp;quot;li&amp;quot;
  map(rownames_to_column) %&amp;gt;% 
  # `map_at` lets you do something to *just* some elements of a list. So here, to be able
  # to bind the two dataframe elements in the list into one dataframe, you need to 
  # make sure they have the same column names. Currently, they don&amp;#39;t, so we need to 
  # change the column names for one of them.
  map_at(&amp;quot;co&amp;quot;, ~ rename(.x, Axis1 = Comp1, Axis2 = Comp2)) %&amp;gt;% 
  # Now that we have a list where each element is a dataframe with the same number
  # of columns, and where those columns have the same names and data types, you 
  # can use `bind_rows` to stick them together into one dataframe (it turns out that
  # this is a *super* helpful function). After this step, you have a tidy dataframe. The
  # `.id` parameter is adding a column with the original list element name, so you can 
  # tell which rows originally came from &amp;quot;co&amp;quot; and which from &amp;quot;li&amp;quot;
  bind_rows(.id = &amp;quot;id&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = Axis1, y = Axis2, color = id)) + 
  geom_point() + 
  # You can add arrows to your segments with the `arrow` function (from the
  # `grid` package, which is very old school graphics and what ggplot is built on)
  # To have everything come from the center, you set the starting point to 0 for
  # both x- and y-axes
  geom_segment(aes(x = 0, y = 0, xend = Axis1, yend = Axis2),
               arrow = arrow(length = unit(0.1, &amp;quot;inches&amp;quot;))) + 
  geom_text_repel(aes(label = rowname)) + 
  # `coord_fixed` ensures that the x- and y-axes are scaled so they have the 
  # same unit size
  coord_fixed() + 
  # `str_c` lets you stick character strings together (`paste0` would also work here)
  labs(x = str_c(&amp;quot;Dim 1 (&amp;quot;, 
                 round(100 * color_matrix_ca$eig[1] / sum(color_matrix_ca$eig), 1), 
                 &amp;quot;%)&amp;quot;), 
       y = str_c(&amp;quot;Dim 2 (&amp;quot;, 
                 round(100 * color_matrix_ca$eig[2] / sum(color_matrix_ca$eig), 1), 
                 &amp;quot;%)&amp;quot;)) + 
  scale_color_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;)) + 
  # Get rid of the color legend
  theme(legend.position = &amp;quot;none&amp;quot;) + 
  # Add some reference lines for 0 on the x- and y-axes
  geom_hline(aes(yintercept = 0), linetype = 3) + 
  geom_vline(aes(xintercept = 0), linetype = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-16-chapter-9-exercise-solution_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class April 16</title>
      <link>/post/details-for-class-april-16/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-april-16/</guid>
      <description>


&lt;div id=&#34;links-for-april-16&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for April 16&lt;/h2&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group 1 (Sarah, James, Burton, Mikeala): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_NjA3Y2Q5MDYtYTM5OS00MzAyLWEwMzAtMzdmNWMzYzhmMTUw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 2 (Daniel, Amy, Sierra): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_M2I3YmViYjMtNWJlNC00M2E5LTg5NTItNzI0N2VlYmVkNzUz%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 3 (Sere, Camron, Sherry): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_YjE4ZGJhNjItYTViMS00MjZjLTk4NWUtMjBhY2E3OTJiOGQw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;space-for-comments-questions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Space for comments, questions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For Chapter 9: &lt;a href=&#34;https://www.sli.do/&#34; class=&#34;uri&#34;&gt;https://www.sli.do/&lt;/a&gt; Event code: #MSMB_CH9&lt;/li&gt;
&lt;li&gt;For Chapter 10 (will be live starting this weekend): &lt;a href=&#34;https://www.sli.do/&#34; class=&#34;uri&#34;&gt;https://www.sli.do/&lt;/a&gt; Event code: #MSMB_CH10&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;vocabulary-quiz-for-april-16&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vocabulary quiz for April 16&lt;/h2&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLScXzy-0EBhDha2uKu3OJB3eeb6eAfVgbpGwQuhgsap7StK_pw/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;3207&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 9</title>
      <link>/post/vocabulary-for-chapter-9/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-9/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 9 covers multivariate methods for heterogenous data. It builds on methods covered in Chapter 7, like dimension reduction, by extending these ideas to more complex, heterogenous data.&lt;/p&gt;
&lt;p&gt;The vocabulary words for Chapter 9 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
multidimensional scaling (MDS)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a linear dimension reduction method applied in cases where distances between observations are available
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
clusters
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of data analysis, data points that group together
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
robust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of a statistical method, a ‘sturdy’ estimator that is not heavily influenced by outliers
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
outlier
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a single data point with large distances to other data points, thus potentially dominating and skewing the analysis
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
breakdown point
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measure of the robustness of an estimator; larger values indicate more robust estimators
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
non-metric multidimensional scaling (NMDS)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a robust ordination method which attempts to embed data points in a new space while maintaining their respective order to one another
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
metadata
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
information, data, or descriptions that characterize other data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
batch effects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
hidden factors that affect the data but are not documented; e.g. running samples at the same time have a degree of similarity from being run in the same batch
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
confounded effects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a term describing when there is uncertainty in the source of variation impacting data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
supplementary
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of variables for a statistical model, categorical variables added to continuous variables in heterogenous data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
supplementary points
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
points created using the group-means of points in each of the groups
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
interactive
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of plots, data visualizations that can be manipulated in real time by the observer
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
contingency table
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the result of counting the co-occurrence of any pair of categorical variables measured in a set of observations; for example, two phenotypes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
chi-square distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
weighted Eucledian distance using relative counts and standardized by the mean, not the variance
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
biplots
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of exploratory graph that displays information on both the observations and the variables of a data matrix
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
co-occurence matrix
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a matrix that captures the extent to which variables are jointly observed in observations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
correspondence analysis (CA) / dual scaling
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method for computing low dimensional projections that explain dependencies in categorical data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
ordination method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method which enables one to detect and interpret a hidden ordering, gradient or latent variable in the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
clustering
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of statistical methods, a way to detect and interpret a hidden factor/categorical variable
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
kernel
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a linear algorithm designed to determine a non-linear decision boundary; used in pattern analysis to better understand general types of relations like clusters, rankings, principal components, or correlations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
local linear embedding (LLE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a nonlinear method for estimating nonlinear trajectories by points in the relevant state spaces
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
isomap
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a nonlinear method for estimating nonlinear trajectories by points in the relevant state spaces
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
inertia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of counts in a contingency table, the weighted sum of the squares of distances between observed and expected frequencies
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
covariance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
measure of the joint variability of two random variables
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
matrix association
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
correlation of vectors derived from matrices based on dissimilarity
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
RV coefficient
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the global measure of similarity of two data tables as opposed to two vectors; correlation coefficient for tables
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
penalty
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method to constrain the typical optimization algorithm, added to interpret correlation when there are too many degrees of freedom
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sparsity penalty
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an approach to maintain the number of non-zero coefficients to a minimum
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
heterogenous data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a mixture of many continuous and a few categorical variables
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
canonical correlation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method for finding a few linear combinations of variables from each table that are as correlated as possible
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
nonlinear
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a regression equation where the equation is not ‘linear in the parameters,’ meaning the relationship between parameters cannot be calulated by multiplying, exponentiating, or transforming independent variables
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
species tree
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a simplified term for a diagram showing the relatedness of organisms based on biological, often genetic sequence, information
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
assay
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an investigative (analytic) procedure in laboratory medicine, pharmacology, environmental biology and molecular biology for qualitatively assessing or quantitatively measuring the presence, amount, or functional activity of a target entity (the analyte)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
protocol
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a predefined written procedural method of conducting experiments
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
microarray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a ‘lab-on-a-chip’ method to assess many samples at once, often used in gene expression studies
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
taxon
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a group of one or more populations of an organism making up a single unit, typically disected to the level of genus and species
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
mutation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an alteration in the nucleotide sequence of the genome of an organism or virus
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
phenotype
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a visually observed genetic trait or characteristic
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
cell development
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process of a cell transitioning from one state to another, such as in the case of a cell transitioning from growth to division in mitosis
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
metabolite
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an intermediate or end product of metabolism; typically a small, organic molecule
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;Some of the definitions above are based in part or whole on listed definitions in the following sources.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. Modern Statistics for Modern Biology. Cambridge University Press, Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.econ.upf.edu/~michael/stanford/maeb4.pdf&#34; class=&#34;uri&#34;&gt;http://www.econ.upf.edu/~michael/stanford/maeb4.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://statisticsbyjim.com/regression/difference-between-linear-nonlinear-regression-models/&#34; class=&#34;uri&#34;&gt;https://statisticsbyjim.com/regression/difference-between-linear-nonlinear-regression-models/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.wikipedia.org&#34; class=&#34;uri&#34;&gt;https://www.wikipedia.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/501633373/flashcards/embed?i=2stug3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exercise solution for Chapter 7</title>
      <link>/post/exercise-solution-for-chapter-7/</link>
      <pubDate>Thu, 09 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-chapter-7/</guid>
      <description>


&lt;div id=&#34;exercise-7.4-from-modern-statistics-for-modern-biology&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exercise 7.4 from Modern Statistics for Modern Biology&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Let’s revisit the Hiiragi data and compare the weighted and unweighted approaches. 7.4a Make a correlation circle for the unweighted Hiiragi data &lt;code&gt;xwt&lt;/code&gt;. Which genes have the best projections on the first principal plane (best approximation)? 7.4b Make a biplot showing the labels of the extreme gene-variables that explain most of the variance in the first plane. Add the the sample-points.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;read-in-and-clean-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Read in and clean data&lt;/h2&gt;
&lt;p&gt;We start by loading the libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;Hiiragi2013&amp;quot;)
library(&amp;quot;ade4&amp;quot;)
library(&amp;quot;factoextra&amp;quot;)
library(&amp;quot;pander&amp;quot;)
library(&amp;quot;knitr&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;ggrepel&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can install the libraries using &lt;code&gt;install.packages&lt;/code&gt; for the &lt;code&gt;ade4&lt;/code&gt; and &lt;code&gt;factoextra&lt;/code&gt; packages and such, and the following line for &lt;code&gt;Hiiragi2013&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BiocManager::install(&amp;quot;Hiiragi2013&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will analyze data from the &lt;code&gt;Hiiragi2013&lt;/code&gt; package containing a gene expression microarray dataset describing the transcriptomes of about 100 cells from mouse embryos at different times during early development.&lt;/p&gt;
&lt;p&gt;I copied the code from the textbook to clean the data. A tidyverse version of this code is available on
&lt;a href=&#34;https://github.com/geanders/csu_msmb_practice/blob/master/ch_7_examples.pdf&#34;&gt;Brooke Andersons’s github&lt;/a&gt;. In either case, we select the wildtype (WT) samples. Then we select the 100 features with the largest variance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;x&amp;quot;, package = &amp;quot;Hiiragi2013&amp;quot;)
xwt &amp;lt;- x[, x$genotype == &amp;quot;WT&amp;quot;]
sel &amp;lt;- order(rowVars(Biobase::exprs(xwt)), decreasing = TRUE)[1:100]
xwt &amp;lt;- xwt[sel, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting data is of the &lt;code&gt;ExpressionSet&lt;/code&gt; class, a class designed to combine many types of data such as microarray data, metadata, and protocol information. The data is shown below. I transposed the data so the rows correspond to samples and the first 101 columns correspond to different genes. I only showed the first the columns and then skipped to the end for brevity. The last columns give additional data about each sample, such as the total number of cells and the scan date.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kable(head(as.data.frame(xwt)[,c(1:3,102:108)]))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;X1434584_a_at&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;X1437325_x_at&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;X1420085_at&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Embryonic.day&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Total.number.of.cells&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;lineage&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;genotype&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;ScanDate&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sampleGroup&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sampleColour&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1 E3.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13.24888&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.332223&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.027715&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WT&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2011-03-16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#CAB2D6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2 E3.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.98757&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.475742&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.293017&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WT&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2011-03-16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#CAB2D6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3 E3.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.72695&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.955642&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.940142&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WT&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2011-03-16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#CAB2D6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;4 E3.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.51926&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.061255&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.715243&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WT&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2011-03-16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#CAB2D6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5 E3.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.01299&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.308667&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8.924228&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WT&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2011-03-16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#CAB2D6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;6 E3.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.50750&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.202948&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.325952&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;WT&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2011-03-16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E3.25&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;#CAB2D6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;a-make-a-correlation-circle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;a) Make a correlation circle&lt;/h2&gt;
&lt;p&gt;Next we plot a correlation circle. This allows us to plot the original genes projected onto the first two principal axes. We can interpret the angles between the vectors as a measure of the correlation between the two corresponding genes. The length of the arrows indicates the correlation of a gene with the first principal axes. This allows us to visualize the correlation between genes, as well as see which genes are best described by our first two principal components. The first principal component is the linear combination of the genes with maximum variance. The second principal component is the linear combination of the genes with maximum variance while being orthogonal to the first principal component.&lt;/p&gt;
&lt;p&gt;First I used &lt;code&gt;dudi.pca&lt;/code&gt; to perform principal component analysis and get a pca and dudi class object. In the text book, they performed a weighted PCA because the groups had very different sample sizes ranging from 4 to 36. A weighted analysis would give the groups equal weight, while an unweighted would give each observation equal weight (and thus give less weight to groups with less members). We are interested in the difference in the genes at the various developmental phases, so in general it would make sense to do a weighted analysis in order to let each developmental phase group have an equal say. To compare the weighted with an unweighted PCA I didn’t use the &lt;code&gt;row.w&lt;/code&gt; option as the textbook did in order to fit an unweighted PCA.&lt;/p&gt;
&lt;p&gt;In the following code &lt;code&gt;t&lt;/code&gt; takes the transpose so the rows correspond to samples. The &lt;code&gt;exprs&lt;/code&gt; function is used to access the expression and error measurements of the data. I chose to center and scale the data, meaning make each column have a mean of 0 and a variance of 1. The &lt;code&gt;scannf&lt;/code&gt; option prevents the function from plotting a scree plot and &lt;code&gt;nf&lt;/code&gt; tells it to keep two axes (i.e. 2 principal components).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pcaMouse &amp;lt;- dudi.pca(as.data.frame(t(Biobase::exprs(xwt))),
                            center = TRUE, scale = TRUE, nf = 2, scannf = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I used the &lt;code&gt;fviz_pca_var&lt;/code&gt; function to plot the correlation circle. I used &lt;code&gt;geom= &#34;arrow&#34;&lt;/code&gt; to remove the labels of each arrow as they were all overlapping. The default for this argument is to print both arrows and text labels for each line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fviz_pca_var(pcaMouse, col.circle = &amp;quot;black&amp;quot;,geom= &amp;quot;arrow&amp;quot;) + ggtitle(&amp;quot;&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-09-exercise-solution-for-chapter-7_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can compare that plot to the one below showing the correlation circle from a weighted analysis. We can see in the weighted analysis the first principal plane does a better job of explaining the variation as indicated by the percent of variation explained by each dimension as well as the length of the arrows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tab = table(xwt$sampleGroup)
xwt$weight = 1 / as.numeric(tab[xwt$sampleGroup])
pcaMouseWeighted &amp;lt;- dudi.pca(as.data.frame(t(Biobase::exprs(xwt))),
                    row.w = xwt$weight,
                    center = TRUE, scale = TRUE, nf = 2, scannf = FALSE)
fviz_pca_var(pcaMouseWeighted, col.circle = &amp;quot;black&amp;quot;,geom= &amp;quot;arrow&amp;quot;) + ggtitle(&amp;quot;&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-09-exercise-solution-for-chapter-7_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The genes that have the best projections on the first principal plane (meaning those with the strongest correlation with the principal axes) are those with the longest arrows on the plots above. I extracted the genes with arrow lengths greater than 0.8 from the unweighted PCA plot with the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrCircle &amp;lt;- fviz_pca_var(pcaMouse, col.circle = &amp;quot;black&amp;quot;)$data
arrowLengths &amp;lt;- sqrt(corrCircle$x^2+corrCircle$y^2)
cutoff &amp;lt;- 0.8
kpInd &amp;lt;- order(arrowLengths, decreasing=TRUE)[1:sum(arrowLengths&amp;gt;cutoff)]
genes &amp;lt;- corrCircle[kpInd,&amp;quot;name&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;genes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;1456270_s_at&lt;/em&gt;, &lt;em&gt;1450624_at&lt;/em&gt;, &lt;em&gt;1449134_s_at&lt;/em&gt;, &lt;em&gt;1418153_at&lt;/em&gt;, &lt;em&gt;1420085_at&lt;/em&gt;, &lt;em&gt;1420086_x_at&lt;/em&gt;, &lt;em&gt;1434584_a_at&lt;/em&gt;, &lt;em&gt;1450843_a_at&lt;/em&gt;, &lt;em&gt;1429483_at&lt;/em&gt;, &lt;em&gt;1437308_s_at&lt;/em&gt;, &lt;em&gt;1456598_at&lt;/em&gt;, &lt;em&gt;1460605_at&lt;/em&gt;, &lt;em&gt;1429388_at&lt;/em&gt;, &lt;em&gt;1426990_at&lt;/em&gt;, &lt;em&gt;1436392_s_at&lt;/em&gt; and &lt;em&gt;1452270_s_at&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To summarize, the code above saves output from the &lt;code&gt;fviz_pca_var&lt;/code&gt; function to an object called &lt;code&gt;corrCircle&lt;/code&gt;. I used the output (which included x and y coordinates) to calculate the arrow length for each gene. I then created a vector, &lt;code&gt;kpInd&lt;/code&gt;, with the indice number for genes that had a length greater then the cutoff of 0.8. Finally, I output the names of those genes with length great than 0.8. Below is a plot showing just these genes with the ``best projection,&#34; meaning they are most correlated with the plane of maximum variation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corrCircle %&amp;gt;% 
  mutate(length = sqrt(x^2 + y^2)) %&amp;gt;% 
  filter(length &amp;gt;= 0.8) %&amp;gt;% 
  ggplot(aes(x = 0, xend = x, y = 0, yend = y)) + 
  geom_segment(arrow = arrow(length = unit(0.1, &amp;quot;inches&amp;quot;))) + 
  geom_label_repel(aes(x = x, y = y, label = name), 
                   size = 2, alpha = 0.7) + 
  coord_fixed()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-09-exercise-solution-for-chapter-7_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;b-make-a-biplot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;b) Make a biplot&lt;/h2&gt;
&lt;p&gt;Next we make a biplot to visualize samples and the genes in one plot. I used the &lt;code&gt;fviz_pca_biplot&lt;/code&gt; function. The &lt;code&gt;col.var&lt;/code&gt; and &lt;code&gt;col.ind&lt;/code&gt; options allow you to color the different genes and sample points, respectively, by particular groups. I used &lt;code&gt;label=&#34;&#34;&lt;/code&gt; to remove the labels on the vectors and points. The &lt;code&gt;above8&lt;/code&gt; variable is simply a vector of either “Less than 0.8” or “Greater than 0.8” to indicate if each gene’s vector length was less than or greater than our cutoff value on the correlation circle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;above8 &amp;lt;- rep(&amp;quot;Less than 0.8&amp;quot;, dim(xwt)[1])
above8[1:100 %in% kpInd] &amp;lt;- &amp;quot;Greater than 0.8&amp;quot;
fviz_pca_biplot(pcaMouse, col.var=above8, col.ind=xwt$sampleGroup, label=&amp;quot;&amp;quot;) +
  ggtitle(&amp;quot;&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-09-exercise-solution-for-chapter-7_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The colors/shapes of the point indicate the sample group of each sample point. The colors of the arrows indicate whether or not the corresponding gene had length greater than or less than 0.8 on the correlation circle.&lt;/p&gt;
&lt;p&gt;We can see the EPI and PE groups (the groups with the fewest samples) appear more extreme in the first principle plane when using the unweighted PCA. This was not the case in the weighted PCA (shown below) because then groups were weighted equally. Here, the PCA mostly depends on the larger groups (to best understand the most observations), so the smaller groups appear more extreme on the principal plane.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;above8 &amp;lt;- rep(&amp;quot;Less than 0.8&amp;quot;, dim(xwt)[1])
above8[1:100 %in% kpInd] &amp;lt;- &amp;quot;Greater than 0.8&amp;quot;
fviz_pca_biplot(pcaMouseWeighted, col.var=above8, col.ind=xwt$sampleGroup, label=&amp;quot;&amp;quot;) +
  ggtitle(&amp;quot;&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-04-09-exercise-solution-for-chapter-7_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class on April 9</title>
      <link>/post/details-for-class-on-april-9/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-on-april-9/</guid>
      <description>


&lt;div id=&#34;links-for-april-9&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for April 9&lt;/h2&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group 1 (Sierra, Daniel, Burton): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_NjA3Y2Q5MDYtYTM5OS00MzAyLWEwMzAtMzdmNWMzYzhmMTUw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 2 (Camron, Sarah, Mikaela): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_M2I3YmViYjMtNWJlNC00M2E5LTg5NTItNzI0N2VlYmVkNzUz%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 3 (Sere, James, Sherry, Amy): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_YjE4ZGJhNjItYTViMS00MjZjLTk4NWUtMjBhY2E3OTJiOGQw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-links&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/DESeq/inst/doc/DESeq.pdf&#34;&gt;&lt;code&gt;DESeq2&lt;/code&gt; vignette&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf&#34;&gt;&lt;code&gt;edgeR&lt;/code&gt; vignette&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;vocabulary-quiz-for-april-9&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vocabulary quiz for April 9&lt;/h2&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSeBAzaWodnzNYNy3xOjn_MBIQQIOvX4NcBZlMoJptgazKfX9w/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2952&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 8 Vocabulary List</title>
      <link>/post/chapter-8-vocabulary-list/</link>
      <pubDate>Mon, 06 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-8-vocabulary-list/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 8 covers high-throughput count data, like data generated through RNA-seq. It introduces a number of tools that are useful for analyzing this type of data. The vocabulary terms for Chapter 8 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
RNA-Seq
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
sequencing of RNA molecules found in a population of cells or in a tissue
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
ChIP-Seq
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
sequencing of DNA regions that are bound to particular DNA-binding proteins (selected by immunoprecipitation)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
RIP-Seq
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
sequencing of RNA molecules, or regions of them, bound to a particular RNA-binding protein
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
DNA-Seq
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
sequencing of genomic DNA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
HiC
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
high-throughput chromatin conformation capture; a technique that aims to map the 3D spatial arrangement of DNA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
cDNA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
complementary DNA made from RNA templates and reverse transcriptase; used in RNA-Seq
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
genetic screens
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a technique looking at the proliferation or survival of cells upon gene knockdown, knockout, or modification
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
read
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the sequence obtained from a fragment
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sequencing library
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the collection of DNA molecules used as input for the sequencing machine
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
fragments
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
molecules being sequenced during a sequencing analysis
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
count table
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a matrix with the tallies of the number of occurrences of subpopulations from a larger population/sample
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dynamic range
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a ratio between the maximum and minimum values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
heteroskedasticity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a phenomenon where the variance and distribution shape of the data in different parts of the dynamic range are very different
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
normalization
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a technique that adjusts for the nature and magnitude of systematic sampling biases
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rare events
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
occurrences in the tail(s) of a distribution; observations that are extraordinarily high or low
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dispersion
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measure of the spread of the data; a common measure is the standard deviation or variance
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gamma-Poisson
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
negative binomial distribution with 2 parameters; 𝛼 and 𝛽
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
systematic biases
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
systematic distortions that affect the data generation and need to be accounted for in the analysis; one example would be variations in the total number of reads for each sample in a sequencing experiment
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
metadata
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a set of data that describes or gives information about other data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
multifactorial design
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an experimental design with more than one independent variable
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
balanced
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of study design, these are where there is an equal number of observations of all combinations of factors being tested
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
differential expression analysis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of analysis that uses the normalized read count data to investigate quantitative changes in expression levels between different experimental groups
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
intercept
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a coefficient representing the base level of the measurement in the negative control
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
design factors
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
binary indicator variables
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
interaction effect
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a parameter in a model that accounts for the effects of two experimental factors that combine in a more complicated fashion than a simple summation
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
design matrix
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a matrix encoding the design of an experiment where the columns correspond to experimental factors and the rows correspond to different experimental conditions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
residuals
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a term in a model that reflects the experimental fluctuations (i.e. random noise)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
least sum-of-squares fitting
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of model fitting that minimizes the sum of the squared residuals
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
linear model
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a model that is a linear function of parameters, i.e. takes the form: y_j = sum_k (x_jk * beta_k + e_j)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
analysis of variance (ANOVA)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an analysis that decomposes patterns in the data into systematic variability and noise
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
noise
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
variability unaccounted for by model parameters
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
systematic variability
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
variability accounted for by model parameters
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
breakdown point
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measure of the robustness of an estimator; larger values indicate more robust estimators
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
robust
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a “sturdy” estimator that is not heavily influenced by outliers
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
least absolute deviations
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
minimization of the sum of the absolute values of the residuals
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
least quantile of squares
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of regression where the difference between the model quantile and empirical quantile is minimized
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
least trimmed sum of squares
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of regression that minimized the sum of squared residuals, where the sum is over only a fraction of the smallest residuals
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
logistic regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of generalized linear regression for binary data where the outcome is transformed by the logistic function and bounded between 0 and 1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
maximum likelihood
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a method for parameter estimation that finds the parameter value that maximizes the probablity of the observed data under the model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
likelihood
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a function of a model parameter which is equal to the probability of the observed data under the model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
maximum-likelihood estimates
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
model parameters that are estimated by maximizing the probability of the observed data under the model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
nuisance factor / blocking factor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a factor that has some effect on the response but is of no interest to the experiment
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
batch effects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
hidden factors that affect the data but are not documented; e.g. running samples at the same time have a degree of similarity from being run in the same batch
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
pseudocounts
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
transformations that take the form y = log2(n + n_0) where n is the count and n_0 is a chosen positive constant
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variance stabilizing transformation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a transformation that has finite values and finite slope, even for counts close to zero
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
regularized logarithm (rlog) transformation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a technique that transforms the original count data to a log2-like scale by fitting a “trivial” model with a separate term for each sample and a prior distribution on the coefficients which is estimated from the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Cook’s distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measure of how much a single sample is influencing the coefficients in a model; large values indicate an outlier count
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sampling without replacement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a random sample in which no observation occurs more than one time in the sample
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
null hypothesis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
often, a hypothesis of “no association” that is used as a counterpart to a more interesting alternative hypothesis in hypothesis testing.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variability
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in statistics, the amount by which a set of observations deviate from their mean
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
outlier
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a data point that does not follow the pattern of the rest of the data; often this data point will have a large residual
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
M-estimation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of regression analysis that is more robust than OLS to outliers or data that does not follow a normal distribution; it minimizes the sum of the penalization function applied to the residuals
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
conservative
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an approach that prioritizes reducing false positives
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
splicing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a process in eukaryotic organisms where mRNA is cut down from the full-length gene to just the exons before being translated
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
exons
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
segments of a gene that actually get used during translation or encode for a protein
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
isoforms
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
different forms of the same gene that result from splicing events that combine different exons in an mRNA script
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
upregulated
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a term used to describe the increased expression of a gene
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gene knockdown
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a way of inactivating a gene by targeting its mRNA transcript for inactivation or degradation
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gene knockout
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
deletion of a gene from the genome
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
transcriptome
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the total of all of the mRNA expressed from genes in an organism
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
polymorphism
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
genetic variation within a population
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitions above are based in part or whole on listed definitions in the following sources.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Lexico: &lt;a href=&#34;https://www.lexico.com&#34; class=&#34;uri&#34;&gt;https://www.lexico.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Statistics How To: &lt;a href=&#34;https://www.statisticshowto.com&#34; class=&#34;uri&#34;&gt;https://www.statisticshowto.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lavrakas, 2008. Sampling without replacement. &lt;em&gt;Encyclopedia of Survey Research Methods.&lt;/em&gt; &lt;a href=&#34;https://dx.doi.org/10.4135/9781412963947.n516&#34; class=&#34;uri&#34;&gt;https://dx.doi.org/10.4135/9781412963947.n516&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/501110916/flashcards/embed?i=2shf5e&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Details for class on April 2</title>
      <link>/post/details-for-class-on-april-2/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/details-for-class-on-april-2/</guid>
      <description>


&lt;div id=&#34;general-course-information&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General course information&lt;/h2&gt;
&lt;p&gt;We are going to try meeting each week using Microsoft Teams during our usual time on Thursdays, 3-5pm. The class structure will remain the same as before, however everything will be online:&lt;/p&gt;
&lt;p&gt;3:00-3:10 pm: Take the quiz through the online blog post.
3:10-4:00 pm: Large group meeting for group discussion.
4:00-5:00 pm: Smaller meetings for groups to work on the chapter exercise.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;links-for-april-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Links for April 2&lt;/h2&gt;
&lt;p&gt;Large group: &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZWY5MTczNDUtOTIzYS00ZGUyLTk4ODctMjdhZWI4MmE4NjMx%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group 1 (Sierra, Camron, James): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_NjA3Y2Q5MDYtYTM5OS00MzAyLWEwMzAtMzdmNWMzYzhmMTUw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 2 (Sherry, Amy, Mikaela): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_M2I3YmViYjMtNWJlNC00M2E5LTg5NTItNzI0N2VlYmVkNzUz%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Group 3 (Daniel, Burton, Sarah, Sere): &lt;a href=&#34;https://teams.microsoft.com/l/meetup-join/19%3ameeting_YjE4ZGJhNjItYTViMS00MjZjLTk4NWUtMjBhY2E3OTJiOGQw%40thread.v2/0?context=%7b%22Tid%22%3a%22afb58802-ff7a-4bb1-ab21-367ff2ecfc8b%22%2c%22Oid%22%3a%2205ade929-16e7-49a7-96bb-775f26ed73d5%22%7d&#34;&gt;meeting link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;vocabulary-quiz-for-april-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vocabulary quiz for April 2&lt;/h2&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLScO4ZmG2HuhTsyoXNuYHajBJ802_3RnzXkeDjDdcMHYRCLXxg/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2942&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 7</title>
      <link>/post/vocabulary-for-chapter-7/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-7/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 7 covers multivariate analysis, with a focus on principal component analysis and
dimension reduction in general.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
principal component analysis (PCA)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an unsupervised ordination method used to reduce the dimensionality of data by creating scores that maximize the explained variation in the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
matrix
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a two dimensional arrangement of rows and columns used to store data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
mass spectroscopy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measurement procedure based on the mass-to-charge ratio of ions, often used to measure metabolite abundance
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
correlation coefficient
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measure of how two variables co-vary, reported as a single summary value
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
centering
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
subtracting the mean of the data so the new mean is 0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
scaling / standardizing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
dividing data values by the data’s standard deviation so the new standard deviation is 1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
data simplification
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a broadly applicable term referring to the process of summarizing or reducing the dimensions of multivariate data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dimension reduction
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
summarizing data to reduce the number of variables for downstream analyses
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
principal scores
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a normally distributed z-score assigned to each subject that corresponds with the specific ordering and weighting of original variables within a given principal component
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
unsupervised learning
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a machine learning method used to find patterns in the data without a priori variable ranking or labeling
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
status
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of variables in a statistical learning algorithm, a ranking or labeling of variables (e.g., to consider one variable as the outcome or goal and the rest as potential predictive variables)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
projection
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a representation of data from a higher dimensional space to a lower dimensional space
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
linear
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of a statistical technique, a description that describes the search for relationships between variables that can be expressed as a linear combination of predictors
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
regression line
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a linear function of the form y = mx + b which is used to project two-dimensional data onto a 1 dimensional line
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
linear regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a supervised method that models the relationship between explanatory and response variables by minimizing the residual sum of squares with respect to the response variable
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
supervised learning
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of a statistical learning technique, a machine learning method that uses specified, user defined inputs to map patterns (input/output associations) in data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
predictor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an independent, explanatory, or ‘x’ variable in a model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
response
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an outcome or ‘y’ variable in a model that is thought to be affected by a predictor
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
principal components
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
uncorrelated latent variables created by the PCA procedure, of which there are as many as there are original variables entered into the procedure
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
inertia
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of variability of points, the total variance of a point cloud based on the sum of squares of the projection of points
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
linear combination
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
mathematical expression in which terms are scaled by constants and then added together
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
loadings
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of principal components, these values quantify the weight of each original variable in a principal component
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
singular value decomposition (SVD)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a way to decompose a rectangular matrix by factoring it into three different matrices in a way that has some useful mathematical applications
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rank
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of a matrix, the maximum number of linearly independent column or row vectors
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
norm
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of a vector, a positive scalar quantity reflecting its size/magnitude
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
singular value
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a non-negative, normalizing value from a singular value decomposition quantifying the relative importance of the corresponding singular vectors
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
orthonormal
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the characteristic of a set of vectors that are both orthogonal (uncorrelated) and normalized
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
principal plane
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a 2-dimensional space across which the data are most spread out or variable
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
trace
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of matrices, the sum of the diagonal elements of a square matrix
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
supplementary information
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
extra information or instruction to help clarify research question, procedure or results
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
metadata
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
information, data, or descriptions that characterize other data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
biplot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a type of exploratory graph that displays information on both the observations and the variables of a data matrix
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
biometric characteristics
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
physical, physiological, demographic, or behavioral features of an organism that can be measured and quantified
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
proliferation rate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
speed at which the number of cells increase through the process of cellular division
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gene expression profile
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a snapshot measure of the level of activity/expression (transcription) of a collection (thousands) of genes, representing a global measure of gene function
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
T-cell populations
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
groups of differentiated white blood cells that function in immune response
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
operational taxonomic units (OTUs)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
clusters of closely related species of bacteria based on sequence similarity
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
transcriptome data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the complete set of all RNA molecules measured from a biological sample generated from genome-wide sequencing methods, like RNA-seq
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sequence read
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an inferred sequence of base pairs, or fragments of the genome, generated from one of many genomics methods
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
proteomic profile
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a snapshot measure of the levels of all proteins measured in a biological sample
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
molecule
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
two or more chemically bond atoms that lack a charge
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
m/z ratio
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
mass to charge ratio used in mass spectrometry to differentiation molecules
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
wild-type
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a normal allele or phenotype that occurs under natural conditions
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;source-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Source Consulted or Cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitons above are based in part or whole on listed definitions in the following source:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;http://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/499545557/flashcards/embed?i=2ldef3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 6 vocabulary quiz</title>
      <link>/post/chapter-6-vocabular-zuiz/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-6-vocabular-zuiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdNNTPez-hy4wz8fJcG7IBu9F3FL-Kxfit74dbgAcjsBjkJjA/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;3437&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Exercise Solution for 5.1</title>
      <link>/post/exercise-solution-for-5-1/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-5-1/</guid>
      <description>


&lt;p&gt;This exercise asks us to interpret and validate the consistency within our clusters of data. To do this, we will employ the silhouette index, which gives us a silhouette value measuring how similar an object is to its own cluster compared to other clusters.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;silhouette index&lt;/strong&gt; is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\displaystyle S(i) = \frac{B(i) - A(i)}{max_i(A(i), B(i))} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The book explains the equation by first defining that the average dissimilarity of a point &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to a cluster &lt;span class=&#34;math inline&#34;&gt;\(C_k\)&lt;/span&gt; is the average of the distances from &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to all of the points in &lt;span class=&#34;math inline&#34;&gt;\(C_k\)&lt;/span&gt;. From this, let &lt;span class=&#34;math inline&#34;&gt;\(A(i)\)&lt;/span&gt; be the average dissimlarity of all points in the cluster that &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; belongs to, and &lt;span class=&#34;math inline&#34;&gt;\(B(i)\)&lt;/span&gt; is the lowest average of dissimlarity of &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; to any other cluster of which &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is NOT a member.Basically, we are subtracting the mean distance to other instances in the same cluster from the mean distance to the instances of the next closest cluster, and dividing it by which of the two values is larger. The output is a coefficient that will vary between -1 and 1, where a value closer to 1 implies that the instance is closest to the correct cluster.&lt;/p&gt;
&lt;p&gt;The solution to this exercise requires the following R packages to be loaded into your environment.&lt;/p&gt;
&lt;div id=&#34;required-libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Required Libraries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cluster)
library(dplyr)
library(ggplot2)
library(purrr)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;part-a&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part A&lt;/h2&gt;
&lt;p&gt;Question 5.1.a asks us to compute the silhouette index for the &lt;code&gt;simdat&lt;/code&gt; data that was simulated in Section &lt;strong&gt;5.7&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The provided code is used to simulate data coming from four separate groups. They use the pipe operator to concatenate four different, randomly generated, data sets. The &lt;code&gt;ggplot2&lt;/code&gt; package is used to take a look at the data as a barchart of the within-groups sum of squared distances (WSS) obtained from the &lt;em&gt;k&lt;/em&gt; means method.&lt;/p&gt;
&lt;p&gt;First off, we need to set the seed to ensure reproducible results with a randomly generated data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following chunk of code utilizes the &lt;code&gt;lapply&lt;/code&gt; function two times to generate a datset with four distinct clusters. The &lt;code&gt;lapply&lt;/code&gt; function comes from base R, and is most often used to apply a function over an entire list or vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)


simdat = lapply(c(0, 8), function(mx) {
  lapply(c(0,8), function(my) {
    
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
   }) %&amp;gt;% bind_rows
}) %&amp;gt;% bind_rows

simdatxy = simdat[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)] # data without class label&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The technique the authors used to generate a clustered dataset is tricky. The &lt;code&gt;lapply&lt;/code&gt; within an &lt;code&gt;lapply&lt;/code&gt;, paired with two &lt;code&gt;bind_rows&lt;/code&gt; functions can be confusing. The next sections are included to demonstrate what the data looks like through various steps in this process, and help bring understanding to the reader how the code is working.&lt;/p&gt;
&lt;div id=&#34;the-inner-lapply-function&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The inner &lt;code&gt;lapply&lt;/code&gt; function&lt;/h4&gt;
&lt;p&gt;The first &lt;code&gt;lapply&lt;/code&gt; is generating a vector of n = 100 normally distributed random numbers, and creating two separate dataframes packed into a list that consist of the mean (&lt;code&gt;my&lt;/code&gt;) and standard deviation, respectively. Each individual value is specifically assigned a 0 or an 8.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simdatmy = lapply(c(0,8), function(my) {
    
    tibble(y = rnorm(100, mean = my, sd = 2),
           class = paste(my, sep = &amp;quot;:&amp;quot;))
   })
summary(simdatmy)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Length Class  Mode
## [1,] 2      tbl_df list
## [2,] 2      tbl_df list&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-outer-lapply-function&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The outer &lt;code&gt;lapply&lt;/code&gt; function&lt;/h4&gt;
&lt;p&gt;The second (outer) &lt;code&gt;lapply&lt;/code&gt; uses the same idea to apply the same, random, 0 or 8 assignment to values in the &lt;code&gt;mx&lt;/code&gt; function. The ouput is now four separate dataframes within a list that contain all of the &lt;code&gt;mx&lt;/code&gt; data and all of the &lt;code&gt;my&lt;/code&gt; data. Within the &lt;code&gt;tibble&lt;/code&gt; function, they include the code &lt;code&gt;class =&lt;/code&gt; to ensure that each row in each of the 4 the lists is assigned one of the four possible two-way combinations of 0 and 8. This is important to simulate a clustered dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simdatmx = lapply(c(0, 8), function(mx) {
  lapply(c(0,8), function(my) {
    
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
    })})
summary(simdatmx)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Length Class  Mode
## [1,] 2      -none- list
## [2,] 2      -none- list&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-it-together&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Putting it together&lt;/h4&gt;
&lt;p&gt;The last step is to bind the list of dataframes into one single dataframe. The final dataframe includes all of the x and y data, each with assigned classes, defined by a combination of 0 and 8.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)


simdat = lapply(c(0, 8), function(mx) {
  lapply(c(0,8), function(my) {
    
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
   }) %&amp;gt;% bind_rows
}) %&amp;gt;% bind_rows

head(simdat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##        x       y class
##    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 -1.25  -1.24   0:0  
## 2  0.367  0.0842 0:0  
## 3 -1.67  -1.82   0:0  
## 4  3.19   0.316  0:0  
## 5  0.659 -1.31   0:0  
## 6 -1.64   3.53   0:0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unique(simdat$class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;0:0&amp;quot; &amp;quot;0:8&amp;quot; &amp;quot;8:0&amp;quot; &amp;quot;8:8&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final &lt;code&gt;simdat&lt;/code&gt; dataframe includes 400 random points witih an assigned class to simulate clustering. We can look at the data using a simple &lt;code&gt;ggplot&lt;/code&gt; scatterplot, color coded by the class of each point.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(simdat, aes(x = x, y = y, color = class)) + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The next part of exploring the data is to compute the within-groups sum of squares (WSS) for the clusters that we just generated. The goal of this section is to observe how the WSS changes as the number of clusters is increased from 1 to 8 when using the k-means. Chapter 5 provides us with the following code and graph:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#1
wss = tibble(k = 1:8, value = NA_real_)

#2
wss$value[1] = sum(scale(simdatxy, scale = FALSE)^2)

#3
for (i in 2:nrow(wss)) {
  km  = kmeans(simdatxy, centers = wss$k[i])
  wss$value[i] = sum(km$withinss)
}

ggplot(wss, aes(x = k, y = value)) + geom_col()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What is really going on here?&lt;/p&gt;
&lt;p&gt;This first chunk is setting up a one-column dataframe with blank &lt;code&gt;NA&lt;/code&gt; values. The &lt;code&gt;NA&lt;/code&gt;s will be filled in with values as the rest of the code processes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#1
wss = tibble(k = 1:8, value = NA_real_)
wss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##       k value
##   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1    NA
## 2     2    NA
## 3     3    NA
## 4     4    NA
## 5     5    NA
## 6     6    NA
## 7     7    NA
## 8     8    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second chunk of code is calculating the value for k = 1 individually. They use the &lt;code&gt;scale&lt;/code&gt; function to scale down the value for k = 1 because it is so much larger than the rest of the k-values. Without scaling down the k = 1 value, it would be difficult to observe any sharp decreases that might indicate a “potential sweet spot” for the number of clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#2
wss$value[1] = sum(scale(simdatxy, scale = FALSE)^2)
wss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##       k  value
##   &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1 15781.
## 2     2    NA 
## 3     3    NA 
## 4     4    NA 
## 5     5    NA 
## 6     6    NA 
## 7     7    NA 
## 8     8    NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last part of this chunk is running a k-means clustering on the remaining k 2 through 8 and then pulling out the &lt;code&gt;withinss&lt;/code&gt; value for all of the observations, summing it, and assigning that value to each individual k-value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#3
for (i in 2:nrow(wss)) {
  km  = kmeans(simdatxy, centers = wss$k[i])
  wss$value[i] = sum(km$withinss)
}

km$withinss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 275.2533 165.2368 199.8292 257.9090 285.8292 131.9047 239.8457 339.1308&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wss&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##       k  value
##   &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1 15781.
## 2     2  9055.
## 3     3  5683.
## 4     4  3088.
## 5     5  2755.
## 6     6  2441.
## 7     7  2152.
## 8     8  1895.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These corresponding values are then neatly displayed in a barchart of the WSS stastistic as a function of k. The sharp decrease between k = 3 and k = 4 (at the &lt;em&gt;elbow&lt;/em&gt;) is indicative of the number of clusters present in the dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(wss, aes(x = k, y = value)) + geom_col()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computing-the-silhouette-index-for-simdat&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Computing the silhouette index for &lt;code&gt;simdat&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Next up is the code necessary to plot the silhouette index. The &lt;code&gt;silhouette&lt;/code&gt; function comes from the &lt;code&gt;cluster&lt;/code&gt; package, and the resulting graph provides an average silhouette width for k = 4 clusters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam4 = pam(simdatxy, 4)
sil = silhouette(pam4, 4, border = NA)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;pam&lt;/code&gt; (partitioning around medoids) function is doing the same thing as the &lt;code&gt;kmeans&lt;/code&gt; call from the earlier chunk of code, but using the &lt;code&gt;cluster&lt;/code&gt; package’s algorithm to calculate the k-means clustering. We use the &lt;code&gt;pam&lt;/code&gt; function here because the we need the “pam” and “partition” output class to run the &lt;code&gt;silhouette&lt;/code&gt; function. With this information, we can then compute the silhouette index and view the output summary and plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(pam4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;pam&amp;quot;       &amp;quot;partition&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sil = silhouette(pam4, 4, border = NA)
summary(sil)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Silhouette of 400 units in 4 clusters from pam(x = simdatxy, k = 4) :
##  Cluster sizes and average silhouette widths:
##       103       100        99        98 
## 0.5279715 0.5047895 0.4815427 0.4785642 
## Individual silhouette widths:
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.04754  0.41232  0.54916  0.49858  0.63554  0.71440&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we explore the final output plot, it might be interesting to look at plots of the simulated values with their respective cluster assignments based on &lt;code&gt;pam&lt;/code&gt; k-means clustering and the silhouette index. With some (a lot of) help from Brooke, we have the following code to view this.&lt;/p&gt;
&lt;p&gt;For the most part, all of the points were assigned to the same cluster as the original, with the occational border point mis-assigned to the neighboring cluster. Interestingly, the silhouette index approaches zero when you near the border of of the cluster and is much higher near the center of the cluster. Although we would expect this, it can be helpful to view this graphically.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sil %&amp;gt;% 
  unclass() %&amp;gt;% 
  as.data.frame() %&amp;gt;% 
  tibble::rownames_to_column(var = &amp;quot;orig_order&amp;quot;) %&amp;gt;% 
  arrange(as.numeric(orig_order)) %&amp;gt;% 
  bind_cols(simdat) %&amp;gt;% 
  ggplot(aes(x = x, y = y, shape = as.factor(cluster), color = sil_width)) + 
  geom_point() + 
  facet_wrap(~ class)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And finally, a silhouette plot with the n = 400 data points. The average silhouette width is a metric that we can use to summarize everything at a level of the full clustering process. Essentially, the closer that this average is to 0.5, then the more accurate our number of clusters &lt;em&gt;k&lt;/em&gt; is. This concept is further explored in the &lt;strong&gt;Part B&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(sil, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-b&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part B&lt;/h2&gt;
&lt;p&gt;Question 5.1.b asks us to change the number of clusters &lt;em&gt;k&lt;/em&gt; and assess which &lt;em&gt;k&lt;/em&gt; value produces the best silhouette index.&lt;/p&gt;
&lt;p&gt;In this example, there are a couple of ways to assess which k gives the best silhouette index.One method would be trial and error and determining which k-value produces the highest silhouette index. This method works out for this example, but is impractical for much larger and complex datasets. Included below is the code for testing multiple different k-values and the resulting coefficient values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam2 = pam(simdatxy, 2)
sil2 = silhouette(pam2, 2)
plot(sil2, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam3 = pam(simdatxy, 3)
sil3 = silhouette(pam3, 3)
plot(sil3, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam4 = pam(simdatxy, 4)
sil = silhouette(pam4, 4)
plot(sil, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam12 = pam(simdatxy, 12)
sil12 = silhouette(pam12, 12)
plot(sil12, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam40 = pam(simdatxy, 40)
sil40 = silhouette(pam40, 40)
plot(sil40, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-18-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This trial and error method indicates that the highest silhouette index (that was tested) is achieved with k = 4.&lt;/p&gt;
&lt;p&gt;A different (seemingly more appropriate) method is to write a piece of code that will test a range of k-values automatically. This next piece of code is adapted from Amy Fox and the group that she worked with during class. This is a much more practical method that provides a clear answer of which &lt;em&gt;k&lt;/em&gt; gives the best silhouette index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k &amp;lt;- c(2:10)
df_test &amp;lt;- data.frame()
for (i in 2:10){
  
  pam_run &amp;lt;- pam(simdatxy, i)
  sil_run &amp;lt;- silhouette(pam_run, i)
  
  row_to_add &amp;lt;- data.frame(i, width = summary(sil_run)$avg.width)
  
  df_test &amp;lt;- rbind(df_test, row_to_add)
}
df_test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    i     width
## 1  2 0.4067400
## 2  3 0.4000560
## 3  4 0.4985801
## 4  5 0.4401518
## 5  6 0.3957347
## 6  7 0.3717875
## 7  8 0.3699929
## 8  9 0.3670770
## 9 10 0.3516570&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df_test, aes(i, width)) +
  geom_point() +
  geom_line() +
  xlab(&amp;quot;k&amp;quot;) +
  ylab(&amp;quot;Silhouette Index&amp;quot;) +
  ggtitle(&amp;quot;Testing different k values for Silhouette Index&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(sil_run)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Silhouette of 400 units in 10 clusters from pam(x = simdatxy, k = i) :
##  Cluster sizes and average silhouette widths:
##        63        38        40        52        33        40        35        33 
## 0.3885059 0.3273800 0.3622990 0.3703291 0.3573781 0.3257945 0.4429236 0.2807700 
##        31        35 
## 0.3944945 0.2335738 
## Individual silhouette widths:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -0.1778  0.2389  0.3703  0.3517  0.4946  0.6623&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result of &lt;code&gt;summary(sil_run)&lt;/code&gt; matches the trial and error method, but in a more efficient manner.&lt;/p&gt;
&lt;p&gt;In summary, k = 4 provides us with the best silhouette index value. This is because there truly are four groups in the dataset based on how we created it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-c&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part C&lt;/h2&gt;
&lt;p&gt;The last part of this exercise asks us to repeat by calculating the silhouette index on a uniform (unclustered) data distribution over a range of values.&lt;/p&gt;
&lt;p&gt;Here, a new data set is generated without clustering the randomly generated data. The 0 and 8 assignment values have been removed and replaced with a singular 1. This assigns all of the values to have the same class.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

simdat1 = lapply(c(1), function(mx) {
  lapply(c(1), function(my) {
    tibble(x = rnorm(100, mean = mx, sd = 2),
           y = rnorm(100, mean = my, sd = 2),
           class = paste(mx, my, sep = &amp;quot;:&amp;quot;))
   }) %&amp;gt;% bind_rows
}) %&amp;gt;% bind_rows

simdatxy1 = simdat1[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)]

ggplot(simdatxy1, aes(x = x, y = y)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pam4.1 = pam(simdatxy1, 4)
sil.1 = silhouette(pam4.1, 4)
plot(sil.1, col=c(&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;purple&amp;quot;), main=&amp;quot;Silhouette&amp;quot;, border = &amp;quot;NA&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-12-exercise-solution-for-5-1_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The average silhouette width is 0.33, which is much lower than the clustered value of 0.50 that we see with the first simulation. It should be pointed out that several of the points end up with negative silhouette widths. These observations were assigned to the wrong group entirely.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://web.stanford.edu/class/bios221/book/Chap-Clustering.html#ques:ques-WSSclusters&#34;&gt;Modern Statistics for Modern Biology - Chapter 5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Silhouette_(clustering)&#34;&gt;Silhouette Clustering - Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@jyotiyadav99111/selecting-optimal-number-of-clusters-in-kmeans-algorithm-silhouette-score-c0d9ebb11308&#34;&gt;Blog on Selecting Optimal Number of Clusters&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 6</title>
      <link>/post/vocabulary-for-chapter-6/</link>
      <pubDate>Fri, 06 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-6/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 6 covers Statistical Testing, including a review of null and alternative hypotheses (and associated distributions), types of error (I and II), as well as challenges and opportunities introduced by multiple testing.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Occam’s razor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Heuristic stating that the simplest explanation for a phenomenon is often the best
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rejection region
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Subset of possible outcomes for which probabilities under the null hypothesis fall under a low probability threshold, e.g. outcomes with a null-distribution probability &amp;lt; 0.05; if an outcome falls within this region (e.g., p &amp;lt; 0.05), it suggests that the null hypothesis is not true.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
test statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Metric for measuring how well a null hypothesis fits the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
null hypothesis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Hypothesis describing some ‘uninteresting’ outcome (e.g., that no difference exists between certain groups of events/outcomes)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
null distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Distribution of possible outcomes, given that the null hypothesis is true
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
alternative hypothesis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A hypothesis providing a different probability distribution than the null hypothesis; conceptually, holds that some difference from the null hypothesis exists (e.g. different means, frequencies, trends)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
significance level/false positive rate/Type I error
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Probability of incorrectly rejecting the null hypothesis due to outcomes falling within the rejection region by chance; in terms of the null distribution, total probability that the outcome could fall within the rejection region given that the null hypothesis is true.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
power
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
True positive rate of a test (i.e., probability that an outcome falls in the rejection region of the null distribution, given that the alternative hypothesis is true)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
false negative rate/Type II error
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Probability of incorrectly failing to reject the null hypothesis when an outcome from the alternative hypothesis distribution fails to fall within the rejection region of the null hypothesis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
specificity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Complement of false positive rate (Type I error); probability of a test failing to reject the null hypothesis when it is true.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
power/sensitivity/true negative rate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Complement of false negative rate (Type II error); probability of correctly rejecting null hypothesis if the alternative hypothesis is true.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
assumption of independence
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Treating every observation in a dataset as if it has no influence on the outcomes of other observations (or at least none unaccounted-for in the model).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
p-value hacking
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Fallaciously ‘fishing’ for significant results by running tests until a small p-value is obtained by chance; this can be deliberate or inadvertently caused by a scattershot approach to testing.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
hypothesis switching
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Fallacy of generating and/or changing hypotheses for a set of known results until a significant result is obtained by chance.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
family-wide error rate (FWER)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Probability of at least one false positive occurring in repeated tests. Assuming independent tests, this is the complement of the probability of only true positives occurring, and approaches 1.0 as the number of tests approaches infinity.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
p-value histogram
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Visualization to get a quick sense of p-value distribution of possible test outcomes for a null hypothesis. The distribution is a mixture of cases where the null hypothesis is rejected (small p-values) or retained (larger p-values).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
false discovery rate (FDR)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The proportion of false positives among all cases where the null hypothesis is rejected across an entire distribution.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
local false discovery rate (fdr)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The probability of Type I Error at a given p-value when the distribution of the p-values is treated as a mixture model of the null distribution and alternative hypothesis distribution. This varies based on the p-value, rather than being a property of the entire distribution.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
tail-area false disovery rate (Fdr)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Integration-based extension of the local false discovery rate to obtain a false discovery rate for the entire distribution.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
independent filtering
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Method to increase test power by filtering variables with criteria that are independent under the null hypothesis, but correlated under the alternative
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
independent hypothesis weighting
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of improving power of multiple testing by weighting hypotheses based on their power
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bonferroni adjustment
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Method used to compensate for inflated Type I (false positive) error in multiple testing by dividing the test significance level/hypothesis threshold (e.g., alpha = 0.05) by the number of tests performed
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
whole genome sequencing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Method used to determine and record the DNA base values and order across all of an organism’s genes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
marker gene
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A gene used to determine membership in a group of interest (e.g., a taxon, genotype within a population, or possessing a certain metabolic trait)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
expression level
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The realtive abundance of transcriptions of a gene of interest present in, e.g., a cell or environment
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
reagent
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a compound used in creating a chemical reaction like an assay
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
hypothesis testing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Evaluating whether outcomes are sufficently unlikely under the null hypothesis (holding that outcomes are determined fully by chance) that it can be rejected in favor of an alternative hypothesis
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
workflow
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A sequence of steps used in carrying out a larger operation or process
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
two-sided test
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A statistical test which rejects the null hypothesis if an observed test statistic is either too large or too small compared to that expected under the null hypothesis
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
one-sided test
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A statistical test which rejects the null hypothesis if an observed test statistic departs from the expected range in a single, predetermined direction (i.e. larger or smaller)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
two-sample
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of statistical testing, a situation whether the data belong to two known groups.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
unpaired
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of statistical tests, these are used when comparing groups with independent measurements (e.g. the observations for one group have no association with observations from the other group)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
equal variances
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
When groups being compared have (substantially) equivalent levels of variability.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dependence
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
When the outcomes of two variables are associated with one another.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
expected value
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
For a random quantity, this is the value of the mean, i.e. “average value”.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources Consulted or Cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitons above are based in part or whole on listed definitions in the following sources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;http://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bourgon, R., Gentleman, R. &amp;amp; Huber, W. Independent filtering increases detection power for high-throughput experiments. Proceedings of the National Academy of Sciences 107, 9546–9551 (2010).&lt;/li&gt;
&lt;li&gt;Ignatiadis, N., Klaus, B., Zaugg, J. et al. Data-driven hypothesis weighting increases detection power in genome-scale multiple testing. Nat Methods 13, 577–580 (2016). &lt;a href=&#34;https://doi.org/10.1038/nmeth.3885&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1038/nmeth.3885&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.statisticssolutions.com/bonferroni-correction/&#34; class=&#34;uri&#34;&gt;https://www.statisticssolutions.com/bonferroni-correction/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html&#34; class=&#34;uri&#34;&gt;https://bioconductor.org/packages/release/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/familywise-error-rate/&#34; class=&#34;uri&#34;&gt;https://www.statisticshowto.datasciencecentral.com/familywise-error-rate/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/&#34; class=&#34;uri&#34;&gt;https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.biostars.org/p/273537/&#34; class=&#34;uri&#34;&gt;https://www.biostars.org/p/273537/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;practice&#34;&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/488864042/flashcards/embed?i=2oqpc3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 5 vocabulary quiz</title>
      <link>/post/chapter-5-vocabulary-quiz/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-5-vocabulary-quiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSe0N9FjDBrIbC3uCxEQBhpndhT6IvKHg2xCiqXzyb6JZJRi3w/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2987&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 4 vocabulary quiz</title>
      <link>/post/chapter-4-vocabulary-quiz/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-4-vocabulary-quiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSd7UnxDl9NTR8vvqgeWzallGB5IJdM5_s1BRRWWtyTtuDVKTw/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2787&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Exercise solution for Chapter 2, Part 2</title>
      <link>/post/ex-2-6/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/ex-2-6/</guid>
      <description>


&lt;div id=&#34;exercise-2.6&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exercise 2.6&lt;/h1&gt;
&lt;p&gt;The first part of the exercise asks you to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Choose your own prior for the parameters of the beta distribution. You can do this by sketching it here: &lt;a href=&#34;https://jhubiostatistics.shinyapps.io/drawyourprior&#34; class=&#34;uri&#34;&gt;https://jhubiostatistics.shinyapps.io/drawyourprior&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After sketching a plot, I chose the parameters to set up a prior: &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; = 2.47 and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; = 8.5.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-this-prior&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using this prior&lt;/h1&gt;
&lt;p&gt;Next, the exercise asks you:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Once you have set up a prior, re-analyse the data from Section 2.9.2, where we saw Y = 40 successes out of n = 300 trials.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To be able to use the &lt;code&gt;loglikelihood&lt;/code&gt; function from the text, I first needed to redefine it here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loglikelihood = function(theta, n = 300, k = 40) { ## Function definition from the textbook
  log(choose(n, k)) + k * log(theta) + (n - k) * log(1 - theta)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I created a vector of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; values between 0 and 1, spaced 0.001 units wide. The plot below shows different possible values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; and the log likelihood for each of these values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;thetas = seq(0, 1, by = 0.001)
plot(thetas, loglikelihood(thetas), xlab = expression(theta),
     ylab = expression(paste(&amp;quot;log f(&amp;quot;, theta, &amp;quot; | y)&amp;quot;)),type = &amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next, I used &lt;code&gt;rbeta&lt;/code&gt; to draw 1,000,000 random samples from a beta distribution with my new picks for the parameters for &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rtheta = rbeta(1000000, shape1 = 2.47, shape2 = 8.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After running the above, for each of these &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; values, we then generate a random sample of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; as observed in the histogram (with orange bars):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y = vapply(rtheta, function(th) {
  rbinom(1, prob = th, size = 300)
}, numeric(1))
hist(y, breaks = 50, col = &amp;quot;orange&amp;quot;, main = &amp;quot;&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our next step is to use this information to generate a posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; at a fixed &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; value. In this example they used &lt;span class=&#34;math inline&#34;&gt;\(Y=40\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;After running the above, for each of these thetas, we generated simulated values for the posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; at &lt;span class=&#34;math inline&#34;&gt;\(Y=40\)&lt;/span&gt; as observed in this histogram (with green bars).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;thetaPostEmp = rtheta[ y == 40 ]
hist(thetaPostEmp, breaks = 40, col = &amp;quot;chartreuse4&amp;quot;, main = &amp;quot;&amp;quot;,
     probability = TRUE, xlab = expression(&amp;quot;posterior&amp;quot;~theta), ylim=c(0,40))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;densPostTheory  =  dbeta(thetas, 42.47, 268.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can check how this compares to the theoretical posterior distribution
for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; at &lt;span class=&#34;math inline&#34;&gt;\(Y = 40\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(thetaPostEmp, breaks = 40, col = &amp;quot;chartreuse4&amp;quot;, main = &amp;quot;&amp;quot;,
  probability = TRUE, xlab = expression(&amp;quot;posterior&amp;quot;~theta))
lines(thetas, densPostTheory, type=&amp;quot;l&amp;quot;, lwd = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also check the means of both distributions computed above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(thetaPostEmp) # Empirical&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1363246&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dtheta = thetas[2]-thetas[1]
sum(thetas * densPostTheory * dtheta) # Theoretical&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1365727&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;monte-carlo-integration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monte Carlo integration&lt;/h2&gt;
&lt;p&gt;We can use Monte Carlo integration instead and then check the agreement between our Monte Carlo sample &lt;code&gt;thetaPostMC&lt;/code&gt; and our sample &lt;code&gt;thetaPostEmp&lt;/code&gt; with a QQ plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;thetaPostMC = rbeta(n = 1e6, 42.47, 268.5)
mean(thetaPostMC)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1365813&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqplot(thetaPostMC, thetaPostEmp, type = &amp;quot;l&amp;quot;, asp = 1)
abline(a = 0, b = 1, col = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;densPost2 = dbeta(thetas, 42.47, 268.5)
mcPost2   = rbeta(1e6, 42.47, 268.5)
sum(thetas * densPost2 * dtheta)  # mean, by numeric integration&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1365727&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(mcPost2)                     # mean, by MC&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1365487&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;thetas[which.max(densPost2)]      # MAP estimate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.134&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(mcPost2, c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      2.5%     97.5% 
## 0.1007321 0.1767921&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 5</title>
      <link>/post/vocabulary-for-chapter-5/</link>
      <pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-5/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 5 covers Clustering Analysis for large scale data anlysis like DNA/RNA sequencing outputs. These methods produce so much data that more unbiased approaches are required when attempting to make correlations.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
unsupervised method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A learning method where all variables are treated with the same status, rather than one variable being considered as an outcome or target.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
status
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A variable’s classification as an outcome/predictor (e.g. independent/dependent) in an analysis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the difference between two random variables.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
The Euclidean distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the “ordinary” straight-line distance between two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Manhattan distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the sum of the absolute differences between the coordinate values for two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Maximum distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the largest absolute difference between the coordinate values for two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Weighted Euclidean distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric, which is a generalization of the ordinary Euclidean distance, that differentially weights the differences between the coordinate values for two points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Minkowski distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric equal to the mth root of the sum of the absolute differences between the coordinate values each raised to the mth power.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Edit or Hamming distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric for comparing character sequences that counts the number of differences between two character strings.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Binary distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric for binary strings based on the proportion of features having only one bit on amongst those features that have at least one bit on.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric that quantifies how dissimilar two sets are.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
co-occurrence
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The fact of two or more things occurring together or simultaneously.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A statistic used in quantifying the similarities between sample sets, which is formally defined as the size of the intersection between two sets divided by the size of the union of the sets.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Jaccard dissimilarity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
1 - the Jaccard index.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Correlation-based distance
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distance metric that measures two objects to be similar if their features are highly correlated, even though the observed values may be far apart in terms of Euclidean distance.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Clusters of Differentiation (CDs)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
At different stages of their development, immune cells express unique combinations of proteins on their surfaces.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Rectangular gating
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of identifying groups of cells from a flow cytometry experiment using either a line (one-dimensional) or the quadrants created by two perpendicular lines (two-dimensional)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Hyperbolic Arcsine (asinh)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A transform function often preferred over the log tranform for flow cytometry data because it can be applied to negative values.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
density-based clustering (dbscan)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The dbscan method clusters points in dense regions according to the density-connectedness criterion. It looks at small neighborhood spheres to see if points are connected.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
curse of dimensionality
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
When the dimensionality increases, the volume of the space increases so fast that the available data become sparse
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
density-reachability
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A fundamental criterion in dbscan that quantifies whether two points are close enough together and surrounded by sufficiently many other points.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
recursive partitioning methods
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A class of methods for dividing heterogeneous populations into more homogeneous subgroups, often used to make decision trees, that starts by separating the whole population into a few groups and iteratively continues separating each into subgroups.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
minimal jump method/single linkage method/nearest neighbor method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that computes the distance between clusters as the smallest distance between any two points in the two clusters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
maximum jump method/complete linkage method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that defines the distance between clusters as the largest distance between any two objects in the two clusters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
average linkage method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that defines the distance between clusters as the average distance between a point in one cluster and another point in the other cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Ward’s method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A clustering method that takes an analysis of variance approach, where the goal is to minimize the variance within clusters. This method is very efficient, however, it tends to break the clusters up into ones of smaller sizes.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Within-groups sum of squares (WSS)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the variability among data points within an identified cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Calinski-Harabasz index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Quantifies the relative variability between groups (between group sum of squares) and within groups (within-groups sum of sqaures), similar to the F statistic used in analysis of variance.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Between-groups sum of squares (BSS)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the variability between clusters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gap statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A metric used to perform model selection which quantifies the amount of model fit improvement when using a more complex model. These can be used to select the number of clusters for a data set.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
technical / batch effects
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Depedence in data observations that results from technical differences between samples, such as the type of sequencing machine or the technician that ran the sample, rather than from scientifically interesting causes.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
computational complexity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A measure of the computational resources needed to run an algorithm.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
noise
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Unexplained variability within a data sample.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
operational taxonomic unit (OTU)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of clustering organisms based on DNA sequence similarity of a certain taxonomic marker gene.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
bias
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The tendency of a statistic to overestimate or underestimate a parameter.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
representativeness heuristic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of learning or discovery that assesses similarity of objects and organizes them based around a category prototype (e.g., like goes with like, and causes and effects should resemble each other).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rare variants
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An alternative form of a gene that occur just once or twice in an individual sample but more often across all samples.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
insertion-deletion (indel)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
insertion or deletion of bases in the genome of an organism.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
neighboring cluster
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The cluster with the lowest average dissimilarity to a given cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
silhouette index
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A metric quantifying the degree to which a given data point belongs to its designated cluster.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Microbiome
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The aggregate of all microbiota that reside on or within an organim’s tissues and biofluids along with the corresponding anatomical sites in which they reside.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
filtering
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of low-quality rRNA reads removal of low-quality reads and trimming them to a consistent length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Histopathology
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The microscopic examination of tissue in order to study the manifestations of disease.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Molecular signature
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Sets of genes, proteins, genetic variants or other variables that can be used as markers for a particular phenotype
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Gene expression data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Gene expression measurements : from gene¬scale to genome¬scale
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Single-cell RNA-Seq experiment
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a measurement of the gene expression profiles of individual cells.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gene transcript
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An RNA molecule of defined size over the length of a gene.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
cell lineage dynamics
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Visualized with tools such as scRNA-seq to track individual cells through their natural progression.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Flow cytometry
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A technique for identifying and sorting cells and their components (such as DNA) by staining with a fluorescent dye and detecting the fluorescence usually by laser beam illumination
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Mass cytometry
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A variation of flow cytometry in which antibodies are labeled with heavy metal ion tags rather than fluorochromes. Readout is by time-of-flight mass spectrometry.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Immune cells
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
cells that are part of the immune system and help the body fight infections and other diseases
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
CD marker / antigen marker
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
are specific types of molecules found on the surface of cells that help differentiate one cell type from another.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
CD4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A glycoprotein found on the surface of immune cells such as T helper cells, monocytes, macrophages, and dendritic cells.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
helper T cells
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A type of T cell that provides help to other cells in the immune response by recognizing foreign antigens and secreting substances called cytokines that activate T and B cells
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Isotope
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Two or more forms of the same element that contain equal numbers of protons but different numbers of neutrons in their nuclei, and hence differ in relative atomic mass but not in chemical properties;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Inner cell mass (ICM)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Pluripotent cell lineage in the blastocyst. forms within the blastocyst, prior to its implantation within the uterus.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Blastocyst
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A thin-walled hollow structure in early embryonic development that contains a cluster of cells called the inner cell mass from which the embryo arises.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Pluripotent epiblast (EPI)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The functional progenitors of soma and germ cells which later differentiate into three layers: definitive endoderm, mesoderm and ectoderm
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
primitive endoderm (PE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The second extraembryonic tissue to form during embryogenesis in mammals. The PE develops from pluripotent cells of the blastocyst inner cell mass
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variable regions
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of taxon identification of bacteria bacterial 16S ribosomal RNA (rRNA) genes contain nine “hypervariable regions” (V1 – V9) that demonstrate considerable sequence diversity among different bacteria.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Chimera
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An organism or tissue that contains at least two different sets of DNA, most often originating from the fusion of as many different zygotes (fertilized eggs).
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources Consulted or Cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitons above are based in part or whole on listed definitions in the following sources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;http://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://academic.oup.com/biolreprod/article/85/5/946/2530522&#34; class=&#34;uri&#34;&gt;https://academic.oup.com/biolreprod/article/85/5/946/2530522&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://discovery.lifemapsc.com/in-vivo-development/inner-cell-mass/inner-cell-mass&#34; class=&#34;uri&#34;&gt;https://discovery.lifemapsc.com/in-vivo-development/inner-cell-mass/inner-cell-mass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://study.com/academy/lesson/inner-cell-mass-icm-definition-function-quiz.html&#34; class=&#34;uri&#34;&gt;https://study.com/academy/lesson/inner-cell-mass-icm-definition-function-quiz.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/&#34; class=&#34;uri&#34;&gt;https://www.sciencedirect.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.medicinenet.com/&#34; class=&#34;uri&#34;&gt;https://www.medicinenet.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.niaid.nih.gov/&#34; class=&#34;uri&#34;&gt;https://www.niaid.nih.gov/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iti.stanford.edu/&#34; class=&#34;uri&#34;&gt;https://iti.stanford.edu/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sysbiowiki.soe.ucsc.edu/node/323&#34; class=&#34;uri&#34;&gt;https://sysbiowiki.soe.ucsc.edu/node/323&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/between-group-variation/&#34; class=&#34;uri&#34;&gt;https://www.statisticshowto.datasciencecentral.com/between-group-variation/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vsoch.github.io/2013/the-gap-statistic/&#34; class=&#34;uri&#34;&gt;https://vsoch.github.io/2013/the-gap-statistic/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/488864042/flashcards/embed?i=2oqpc3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 4</title>
      <link>/post/vocabulary-for-chapter-4/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-4/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 4 covers how to generate both finite and infinite mixture models from various distributions. It introduces a number of terms relating to these models. The vocabulary words for Chapter 4 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
finite mixture
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of statistic, when the distribution of interest is a combination of a few different probability distributions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
infinite mixture
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of statistic, when the distribution of interest is a combination of many probability distributions (as many or more probability distributions as observations)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
mixture model
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a model for a combination of two or more different probability distributions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
probability density function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a function giving the relative likelihood that a continuous random variable is equal to a given value. When this function is integrated over the sample space, it equals 1.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
bimodal distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a distribution comprised of two modes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
expectation-maximization (EM) algorithm
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an algorithm that allows for parameter estimation in probabilistic models with incomplete data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
data augmentation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
adding variables that are not measured (latent variables) to the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
latent variables
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
variables not measured in the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
bivariate distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a combined distribution made of two random variables
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
mixture fraction
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a fraction used to describe the inhomogeneity in the mixture composition
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
identifiability
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an issue where there can be several explanations for the same observed values; occurs when there are too many degrees of freedom in parameters
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
marginal likelihood
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the sum of the marginal distributions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
expectation function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a function that calculates the average of all possible values of the group that an observation belongs to
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
maximization step
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a step to optimize the parameters of a model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
soft averaging
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process in which observations are not assigned to groups, rather they are added to multiple groups by using probabilities of memberships as weights
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
model averaging
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the process of using several models and combining them together into a weighted model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
zero-inflated data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
data that contains a large number of zero counts
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
ChIP-Seq data
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
sequencing data that identifies DNA binding sites for proteins
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
chromosome
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a DNA molecule that contains the genetic material of an organism
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
binding site
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of molecular biology, a specific region to which a macromolecule binds
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
deoxyribonucleotide monophosphate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a single phosphate group in a unit of DNA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gene expression measurement
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the measurement of a functional gene product (i.e., protein or RNA)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
microarray
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a laboratory tool used to detect gene expression
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
promoter
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of genetics, a region of DNA that initiates transcription of a gene
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
point mass
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a finite probabiliity concentrated at a point in the proability mass distribution at which there is a discontinuous segment in probability density function
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sampling distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the probability distribution calculated from a random sample
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
empirical cumulative distribution function (ECDF)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a step distribution function based on empirical data measurements
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
density
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of probability distributions, the derivitive of the distribution function
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
bootstrap
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an approximation of the true sampling distribution; created by drawing new samples from the empirical distribution of the original sample
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
non-parametric method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a statistical method that does not make assumptions about population distribution or sample size
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
nonparametric bootstrap
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
an approximation of the true sampling distribution not based off of a specific assumption or a particular model
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Laplace distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a distribution that shows differences between two independent variates with identical exponential distributions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
gamma distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a distribution that is positively valued and continuous with two parameters: shape and scale
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
negative binomial distribution/ gamma-Poisson distubtion
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the probability distribution of the number of failures before the kth success in a sequence of Bernoulli trials
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
dispersion
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the amount by which a set of observations deviate from their mean
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variance-stabilizing transformations
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
transformations designed to give approximate independence between mean and variance
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
heteroscedasticity
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the variance of the data is different in different regions of the data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
delta method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a calculus procedure that uses random variables to approximate the expected value and variance of a function
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitions above are based in part or whole on listed definitions
in the following sources.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Everitt and Skrondal, 2010. &lt;em&gt;The Cambridge Dictionary of Statistics (Fourth Edition).&lt;/em&gt; Cambridge University Press, Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Zero-Inflated Poisson Regression.&lt;/em&gt; Institute for Digital Research and Education Statistical Consulting. &lt;a href=&#34;https://stats.idre.ucla.edu/r/dae/zip/&#34; class=&#34;uri&#34;&gt;https://stats.idre.ucla.edu/r/dae/zip/&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Berrar, 2019. &lt;em&gt;Introduction to Non-parametric Bootstrap.&lt;/em&gt; Research Gate. &lt;a href=&#34;https://www.researchgate.net/&#34; class=&#34;uri&#34;&gt;https://www.researchgate.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Do and Batzoglou, 2008. &lt;em&gt;What is the expectaion maximization algorithm?.&lt;/em&gt; Nature Biotechnology.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encylcopedia. &lt;a href=&#34;https://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Google Oxford American Dictionary. &lt;a href=&#34;https://www.google.com&#34; class=&#34;uri&#34;&gt;https://www.google.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;d’Auzay, et al., 2019. &lt;em&gt;Statistics of progress variable and mixture fraction gradients in an open turbulent jet spray flame.&lt;/em&gt; Fuel.&lt;/li&gt;
&lt;li&gt;Brownlee, 2019. &lt;em&gt;A Gentle Introduction to Expectation-Maximization (EM Algorithm).&lt;/em&gt; Machine Learning Mastery. &lt;a href=&#34;https://www.machinelearningmastery.com&#34; class=&#34;uri&#34;&gt;https://www.machinelearningmastery.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Non-parametric Methods.&lt;/em&gt; R tutorial. &lt;a href=&#34;https://www.r-tutor.com&#34; class=&#34;uri&#34;&gt;https://www.r-tutor.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Precise analysis of DNA–protein binding sequences.&lt;/em&gt; Illumina. &lt;a href=&#34;https://www.illumina.com&#34; class=&#34;uri&#34;&gt;https://www.illumina.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Microarray.&lt;/em&gt; Nature. &lt;a href=&#34;https://www.nature.com&#34; class=&#34;uri&#34;&gt;https://www.nature.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/485299672/flashcards/embed?i=2r4ib&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 2, part 2, vocabulary quiz</title>
      <link>/post/chapter-2-part-2-vocabulary-quiz/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-2-part-2-vocabulary-quiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSfaoamajaVKWjrisvObSuEwqs2BiRCZzkzEg-Vx_prlgWhnog/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;2987&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Exercise solution for Chapter 2, Part 1</title>
      <link>/post/exercise-solution-for-chapter-2/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-chapter-2/</guid>
      <description>


&lt;p&gt;As always, load libraries first.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(tidyverse)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exercise-2.3-from-modern-statistics-for-modern-biologists&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exercise 2.3 from Modern Statistics for Modern Biologists&lt;/h2&gt;
&lt;p&gt;A sequence of three nucleotides codes for one amino acid. There are 4 nucleotides, thus &lt;span class=&#34;math inline&#34;&gt;\(4^3\)&lt;/span&gt; would allow for 64 different amino acids, however there are only 20 amino acids requiring only 20 combinations + 1 for an “end” signal. (The “start” signal is the codon, ATG, which also codes for the amino acid methionine, so the start signal does not have a separate codon.) The code is redundant. But is the redundancy even among codons that code for the same amino acid? In other words, if alanine is coded by 4 different codons, do these codons code for alanine equally (each 25%), or do some codons appear more often than others? Here we use the tuberculosis genome to explore codon bias.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-explore-the-data-mtb&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;a) Explore the data, &lt;code&gt;mtb&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Use &lt;code&gt;table&lt;/code&gt; to tabulate the &lt;code&gt;AmAcid&lt;/code&gt; and &lt;code&gt;Codon&lt;/code&gt; variables.&lt;/p&gt;
&lt;p&gt;Each amino acid is encoded by 1–6 tri-nucleotide combinations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtb = read.table(&amp;quot;example_datasets/M_tuberculosis.txt&amp;quot;, header = TRUE)
codon_no &amp;lt;- rowSums(table(mtb))
codon_no&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Ala Arg Asn Asp Cys End Gln Glu Gly His Ile Leu Lys Met Phe Pro Ser Thr Trp Tyr 
##   4   6   2   2   2   3   2   2   4   2   3   6   2   1   2   4   6   4   1   2 
## Val 
##   4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;PerThousands&lt;/code&gt; of each codon can be visualized, where each plot represents an amino acid and each bar represents a different codon that codes for that amino acid. But what does the &lt;code&gt;PerThousands&lt;/code&gt; variable mean?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mtb, aes(x=Codon, y=PerThous)) +
  geom_col()+
  facet_wrap(~AmAcid, scales=&amp;quot;free&amp;quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-19-exercise-solution-for-chapter-2_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;b-the-perthous-variable&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;b) The &lt;code&gt;PerThous&lt;/code&gt; variable&lt;/h1&gt;
&lt;p&gt;How was the &lt;code&gt;PerThous&lt;/code&gt; variable created?&lt;/p&gt;
&lt;p&gt;The sum of all of the numbers of codons gives you the total number of codons in the M. tuberculosis genome: &lt;code&gt;all_codons&lt;/code&gt;. Remember that this is not the size of the M. tuberculosis genome, but the number of codons in all M. tuberculosis genes. To get the size of the genome, multiply each codon by 3 (for each nucleotide) and add all non-coding nucleotides (which we do not know from this data set).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_codons = sum(mtb$Number)
all_codons&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1344223&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;PerThousands&lt;/code&gt; variable is derived by dividing the number of occurrences of the codon of interest by the total number of codons. Because this number is small and hard to interpret, multiplying it by 1000 gives a value that is easy to make sense of. Here is an example for proline. The four values returned align to the four codons that each code for proline.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pro  =  mtb[mtb$AmAcid == &amp;quot;Pro&amp;quot;, &amp;quot;Number&amp;quot;]
pro / all_codons * 1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 31.560240  6.121752  3.405685 17.032144&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;c-codon-bias&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;c) Codon bias&lt;/h1&gt;
&lt;p&gt;Write an R function that you can apply to the table to find which of the amino acids shows the strongest codon bias, i.e., the strongest departure from uniform distribution among its possible spellings.&lt;/p&gt;
&lt;p&gt;First, let’s look at the expected frequencies of each codon.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codon_expected &amp;lt;- data.frame(codon_no) %&amp;gt;%
  rownames_to_column(var = &amp;quot;AmAcid&amp;quot;) %&amp;gt;%
  mutate(prob_codon = 1/codon_no)
codon_expected&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    AmAcid codon_no prob_codon
## 1     Ala        4  0.2500000
## 2     Arg        6  0.1666667
## 3     Asn        2  0.5000000
## 4     Asp        2  0.5000000
## 5     Cys        2  0.5000000
## 6     End        3  0.3333333
## 7     Gln        2  0.5000000
## 8     Glu        2  0.5000000
## 9     Gly        4  0.2500000
## 10    His        2  0.5000000
## 11    Ile        3  0.3333333
## 12    Leu        6  0.1666667
## 13    Lys        2  0.5000000
## 14    Met        1  1.0000000
## 15    Phe        2  0.5000000
## 16    Pro        4  0.2500000
## 17    Ser        6  0.1666667
## 18    Thr        4  0.2500000
## 19    Trp        1  1.0000000
## 20    Tyr        2  0.5000000
## 21    Val        4  0.2500000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, calculate the observed frequencies for each codon seen in the data set and use the chi-squared test statistic to determine if the difference between expected and observed codon frequencies is even or if some codon sequences are used more than others.&lt;/p&gt;
&lt;p&gt;To start, you can group the data by amino acid and then determine a few things about
the amino acid or the possible codons for it, including the total observations
across all codons for the amino acid (&lt;code&gt;total&lt;/code&gt;), the number of codons for that
amino acid (&lt;code&gt;n_codons&lt;/code&gt;), and the expected count for each codon for that amino acid
(the total number of observations for that amino acid divided by the number of
codons, giving an expected number that’s the same for all codons of an amino
acid; &lt;code&gt;expected&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codon_compared &amp;lt;- mtb %&amp;gt;% 
  group_by(AmAcid) %&amp;gt;% 
  mutate(total = sum(Number),
         n_codons = n(),
         expected = total / n_codons)
codon_compared&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64 x 7
## # Groups:   AmAcid [21]
##    AmAcid Codon Number PerThous  total n_codons expected
##    &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 Gly    GGG    25874    19.2  132810        4   33202.
##  2 Gly    GGA    13306     9.9  132810        4   33202.
##  3 Gly    GGT    25320    18.8  132810        4   33202.
##  4 Gly    GGC    68310    50.8  132810        4   33202.
##  5 Glu    GAG    41103    30.6   62870        2   31435 
##  6 Glu    GAA    21767    16.2   62870        2   31435 
##  7 Asp    GAT    21165    15.8   77852        2   38926 
##  8 Asp    GAC    56687    42.2   77852        2   38926 
##  9 Val    GTG    53942    40.1  114991        4   28748.
## 10 Val    GTA     6372     4.74 114991        4   28748.
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;mutate&lt;/code&gt; function is used after &lt;code&gt;group_by&lt;/code&gt; to do all this
within each amino acid group of codons, but without collapsing to one row per
amino acid, as a &lt;code&gt;summarize&lt;/code&gt; call would.&lt;/p&gt;
&lt;p&gt;To convince yourself that this has worked out correctly, you can repeat
the plot we made before and see that the bars for the expected values are
always equal across all codons for an amino acid:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(codon_compared, aes(x=Codon, y=expected)) +
     geom_col()+
     facet_wrap(~AmAcid, scales=&amp;quot;free&amp;quot;) +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-19-exercise-solution-for-chapter-2_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally, we can calculate the chi-squared (&lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;) statistic and compare it to the
chi-squared distribution to get the p-value when testing against the null hypothesis
that the amino acid observations are uniformly distributed across codons. The &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;
is calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\chi^2 = \sum_i{\frac{(O_i-E_i)^2}{E_i}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(O_i\)&lt;/span&gt; is the observed value of data point &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; (&lt;code&gt;Number&lt;/code&gt; in our data); and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(E_i\)&lt;/span&gt; is the expected value of data point &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; (&lt;code&gt;expected&lt;/code&gt; in our data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In our data, we can calculate the contribution to the total &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistic
from each data point (in this case, each codon within an amino acid) using
&lt;code&gt;mutate&lt;/code&gt;, and then
add these values up using &lt;code&gt;group_by&lt;/code&gt; to group by amino acid followed by
&lt;code&gt;summarize&lt;/code&gt; to sum up across all the data points for an amino acid.
The other information we need to get is the number of codons for the
amino acid, because we’ll need this to determine the degrees of freedom
for the chi-squared distribution. Next, we used &lt;code&gt;mutate&lt;/code&gt; with
&lt;code&gt;pchisq&lt;/code&gt; to determine the p-values within each amino acid group for the
test against the null that the codons are uniformly distributed for that
amino acid (i.e., that there isn’t codon bias). These p-values turn out to
be super small, so we’re using a technique to get the log-transform versions of
them instead, which we explain a bit more later. Finally, we used &lt;code&gt;arrange&lt;/code&gt; to
list the amino acids by evidence against uniform distribution of the codons,
from most evidence against (smallest p-value so most negative log(p-value))
to least evidence against (although still plenty of evidence against) and added
an &lt;code&gt;index&lt;/code&gt; with the ranking for each codon by adding a column with the sequence
of numbers from 1 to the number of rows in the data (&lt;code&gt;n()&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codon_compared %&amp;gt;% 
  filter(n_codons &amp;gt; 1) %&amp;gt;% 
  group_by(AmAcid) %&amp;gt;% 
  mutate(chi_squared = ((Number - expected)^2/expected)) %&amp;gt;% 
  summarise(chi_squared = sum(chi_squared),
            n = n()) %&amp;gt;% 
  mutate(p_value = pchisq(chi_squared, df = n-1, log = TRUE, lower.tail = FALSE)) %&amp;gt;% 
  arrange(p_value) %&amp;gt;% 
  mutate(rank = 1:n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 19 x 5
##    AmAcid chi_squared     n p_value  rank
##    &amp;lt;fct&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
##  1 Leu        135432.     6 -67700.     1
##  2 Ala         75620.     4 -37805.     2
##  3 Arg         72183.     6 -36076.     3
##  4 Thr         58767.     4 -29378.     4
##  5 Val         58737.     4 -29363.     5
##  6 Ile         56070.     3 -28035.     6
##  7 Gly         52534.     4 -26262.     7
##  8 Pro         45400.     4 -22695.     8
##  9 Ser         36742.     6 -18357.     9
## 10 Asp         16208.     2  -8109.    10
## 11 Phe         13444.     2  -6727.    11
## 12 Asn         11404.     2  -5707.    12
## 13 Gln          9376.     2  -4693.    13
## 14 Lys          6382.     2  -3195.    14
## 15 Glu          5947.     2  -2978.    15
## 16 His          5346.     2  -2678.    16
## 17 Tyr          4738.     2  -2373.    17
## 18 Cys          2958.     2  -1483.    18
## 19 End           928.     3   -464.    19&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you may notice, these log transforms of the p-values (which we got rather than untransformed p-values in the &lt;code&gt;pchisq&lt;/code&gt; call because we used the option &lt;code&gt;log = TRUE&lt;/code&gt;) are large in magnitude and negative (so very tiny once you take the exponent if you re-transformed them to p-values) values. If you tried to calculate the untransformed p-values (and we did!), this number is so small (0.00000000e+00) that it is too small for R—it shows up as exactly zero in R, even though it actually is a very tiny, but still non-zero, number. To get around this issue, we told &lt;code&gt;pchisq&lt;/code&gt; to work on these p-values as log transforms, and then we left the p-value as that log-transformed value. A group of numbers that are log transformed will be in the same order as their untransformed versions, so we don’t need to convert back to figure out which amino acid had that smallest p-value. We can just sort the amino acids from most negative to less negative using these log-transformed versions of the p-values. We now have the amino acids ranked from most biased codons (1) to least (19).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 2 Part 1 vocabulary quiz</title>
      <link>/post/chapter-2-vocabulary-quiz/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-2-vocabulary-quiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSd_F2yhNwWK-GMCUuQTLVIQobe46lplbhWOjdq2rIBmHrN-hQ/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;3357&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>How to create an exercise solution blog post</title>
      <link>/post/how-to-create-an-exercise-solution-blog-post/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/how-to-create-an-exercise-solution-blog-post/</guid>
      <description>


&lt;p&gt;Each of you will be responsible once or twice over the semester to create
a blog post that provides a clean, clearly-presented solution to the
in-class exercise for the week. This blog post provides the technical
instructions for writing and submitting that exercise.&lt;/p&gt;
&lt;p&gt;Your exercise solution should be posted &lt;strong&gt;before&lt;/strong&gt; the next class meeting.
Since it will need to be reviewed by the faculty before it can be officially
posted, please plan to submit it by the &lt;strong&gt;Tuesday after&lt;/strong&gt; the class for your
exercise. Student assignments for the exercises are given in the
Schedule section of our course website.&lt;/p&gt;
&lt;div id=&#34;overview-of-creating-a-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview of creating a post&lt;/h2&gt;
&lt;p&gt;You will be submitting your exercise solution as a blog post. Creating
one for our website will follow all the same steps as creating a blog
post for a vocabulary list, just with different content. Please read
the &lt;a href=&#34;https://kind-neumann-789611.netlify.com/post/creating-a-vocabulary-list-blog-post/&#34;&gt;post on creating a vocabulary list&lt;/a&gt;
and follow the steps there to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Update your fork of the website&lt;/li&gt;
&lt;li&gt;Make a new blog post&lt;/li&gt;
&lt;li&gt;Use RMarkdown syntax to write the blog post&lt;/li&gt;
&lt;li&gt;Submit the blog post&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;content-for-the-blog-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Content for the blog post&lt;/h2&gt;
&lt;p&gt;The blog post should provide a walk-through of the solution to that week’s in-course
exercise. We have posted an example for &lt;a href=&#34;https://kind-neumann-789611.netlify.com/post/exercise-solution-for-chapter-1/&#34;&gt;the exercise for Chapter 1&lt;/a&gt;
to give you an idea of what you should aim to write.&lt;/p&gt;
&lt;p&gt;Generally, this exercise will be a resource for everyone in the class, to make sure
they’ve understood the exercise, as well as to see how someone else tackled the problem.
Your solution should cover all parts of the exercise (for example, if there’s a
part A and B, you should cover both). You can start by writing it as you would if you
were assigned the exercise as a homework problem, but then you should do a second step
of revision to provide some context and dig a bit deeper into how you tackled
the question. Since we are only requiring you to write up exercise answers once
or twice over the semester (rather than submitting homework for exercises every
week), we expect this product to be more in-depth and polished than a typical
homework solution.&lt;/p&gt;
&lt;p&gt;First, make sure that you have provided text explaining what the
exercise asks for, in case the reader hasn’t recently read the exercise prompt.
Second, please add a few details either about how you tackled the problem through code
or how the statistical principles covered in the exercise could apply to other problems
you’ve come across in your research or coursework.&lt;/p&gt;
&lt;p&gt;To help in preparing your post, plan to spend the exercise time in class during the
week of your exercise visiting the different groups of students working on the
exercise. You can talk to them about how they’re approaching the problem, how they
interpret it, etc., to help you develop your own answer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tips&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tips&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Be sure to refresh yourself on all the Markdown formatting tags you can use to improve
the appearance of your post. Be sure to include things like section headings and
italics or bold as appropriate. RStudio’s website has some nice cheatsheets on
RMarkdown that can help.&lt;/li&gt;
&lt;li&gt;Make sure you include R code if appropriate. If you put parentheses around an
assignment expression in R, it will print out the assigned object and make the
assignment in the same call—you might find this useful in writing concise code
while still showing what’s in the objects you create.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;$&lt;/code&gt; and &lt;code&gt;$$&lt;/code&gt; tags in RMarkdown to include mathematical equations in your blog post
when appropriate.&lt;/li&gt;
&lt;li&gt;If you need to read in a dataset for R code in your blog post, save it in the
website directory’s “content/post/example_datasets” subdirectory. If your data
comes from an online source or from an R library, you won’t need to do this,
only if you need a “local” copy of the datafile to run your RMarkdown code.&lt;/li&gt;
&lt;li&gt;You are welcome to draw from (and cite) other statistics textbooks or dictionaries
if you’d like to in explaining the problem and your approach to it.&lt;/li&gt;
&lt;li&gt;For the code, look at vignettes and helpfiles, especially for packages you are not
familiar with.&lt;/li&gt;
&lt;li&gt;For a lot of Bioconductor packages, object-oriented programming is used pretty
heavily. This means that associated data in R packages will often be stored in a
format that you haven’t used yet. Look up more information on data classes used in
your exercise if you aren’t familiar with them. You can use the &lt;code&gt;class&lt;/code&gt; function
to determine the class of an object as well as the name of the package that defines
that class. The &lt;code&gt;str&lt;/code&gt; function is often helpful for exploring a data object class, as well.
Many of the Bioconductor object classes will have special &lt;em&gt;accessor methods&lt;/em&gt;, which are
functions that allow you to extract certain elements from the object—check the helpfile
for the object class, as these methods are often listed there with examples.&lt;/li&gt;
&lt;li&gt;Googling can also be very helpful for learning more about functions, packages, and
datasets in R, especially if you don’t yet know what package the item is from.&lt;/li&gt;
&lt;li&gt;Most Bioconductor packages have very nice vignettes available online and from your
R session once you have installed the package. These are a great place to start to find
out more about how to use the functions and object classes that come with the package.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 2, Part 2</title>
      <link>/post/vocabulary-for-chapter-2-8-2-12/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-2-8-2-12/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;These sections introduced Markov chains and the Bayesian paradigm. Markov chain transitions were used to model dependencies along DNA sequences. The vocabulary terms are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Markov chain
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a sequence where given the current state, the next state is conditionally independent of all previous states
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bayesian paradigm
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
approaching statistics from the perspective that probability can be viewed as a degree of belief in an event
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Beta distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a probability distribution defined on the interval [0, 1] often used to model probabilities in Bayesian statistics
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Exponential distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a probability distribution defined on the positive real numbers that can be used to model the time between events in a Poisson point process
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Prior
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a probability distribution describing our knowledge of a hypothesis/parameter before incorporating new data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Posterior
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a probability distribution describing our knowledge of a hypothesis/parameter after incorporating new data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Haplotype
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a collection of DNA sequence variants (e.g., alleles) that are spatially close on a chromosome, are usually inherited together, and thus are genetically linked
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Marginal distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the distribution of a sub-collection of variables after integrating out the remaining variables in the collection.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Monte Carlo integration
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a technique for numerical integration where the value of an integral is estimated by simulating data
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Quantile-quantile plot (QQ-plot)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
a plot comparing the quantiles from one distribution (often a theoretical distribution) to the quantiles of another distribution (often from a sample)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Maximum a posteriori (MAP) estimate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the mode of the posterior distribution associated with the quantity of interest
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Escherichia coli
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
facultative anaerobic, rod-shaped, coliform bacterium commonly found in the lower intestine of warm-blooded organisms
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Epigenetics
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the study of heritable phenotype changes that do not involve alterations in the DNA sequence
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Log-likelihood ratio
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the log of the likelihood under one set of assumptions divided by the likelihood under another set of assumptions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bimodality
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
when a distribution has two modes
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Mixture
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
in the context of statistics, when the distribution of interest is a combination of two or more different probability distributions
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Codon
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A three-nucleotide sequence that specifies the amino acid to be created next (or to start or stop synthesis)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Codon bias
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the differences in how often each spelling of an amino acid occurs in coding DNA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Genetic code
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
the set of instructions in a gene that tell the cell how to make a specific protein
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitons above are based in part or whole on listed definitions in the following sources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;http://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NIH Genetics Home Reference. &lt;a href=&#34;https://ghr.nlm.nih.gov/&#34; class=&#34;uri&#34;&gt;https://ghr.nlm.nih.gov/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NCBI Genetics Review. &lt;a href=&#34;https://www.ncbi.nlm.nih.gov&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/362954560/flashcards/embed?i=1bqje7&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exercise solution for Chapter 1</title>
      <link>/post/exercise-solution-for-chapter-1/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/exercise-solution-for-chapter-1/</guid>
      <description>


&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1.8 (p. 17)&lt;/strong&gt; Is the mitochondrial sequence of &lt;em&gt;C. elegans&lt;/em&gt;
consistent with a model of equally likely nucleotides?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This exercise asks us to explore the frequency of each of the four nucleotides
(A, C, G, and T) in the genome of &lt;em&gt;C. elegans&lt;/em&gt;, a type of worm used frequently
in scientific research.&lt;/p&gt;
&lt;p&gt;This solution requires that several R extension packages be loaded in your R
session. If you do not have these packages installed to your computer yet, you
should follow &lt;a href=&#34;https://kind-neumann-789611.netlify.com/post/chapter-1-exercise-setup/&#34;&gt;instructions we’ve posted
separately&lt;/a&gt;
describing the required set-up for this exercise. Once you have installed these
packages on your computer, you can load them into your current R session using
the &lt;code&gt;library&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;BSgenome.Celegans.UCSC.ce2&amp;quot;)
library(&amp;quot;Biostrings&amp;quot;)

library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;knitr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;part-a&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part A&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Explore the nucleotide frequencies of chromosome M by using a dedicated
function in the &lt;em&gt;Biostrings&lt;/em&gt; package from Bioconductor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Part A of the question asks us to explore the nucleotide frequency of the &lt;em&gt;C.
elegans&lt;/em&gt; genome. This genome is available in the &lt;code&gt;Celegans&lt;/code&gt; data that comes with
the &lt;code&gt;BSgenome.Clegans.UCSC.ce2&lt;/code&gt; package and is stored within a &lt;code&gt;BSgenome&lt;/code&gt; class,
which is a special object class provided by the &lt;code&gt;Biostrings&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;There is a dedicated function called &lt;code&gt;letterFrequency&lt;/code&gt; in the &lt;code&gt;Biostrings&lt;/code&gt;
package that can be used to count the frequency of letters in a string (like a
genome) in an R object like this. In a call to this function, you must also
include the possible letters in your “alphabet”—that is, the possible letters
that each position in your string could take.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(nuc_freq &amp;lt;- letterFrequency(Celegans$chrM, letters=c(&amp;quot;A&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;T&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    A    C    G    T 
## 4335 1225 2055 6179&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To explore and plot this data, I put this summary data into a &lt;code&gt;tibble&lt;/code&gt;, so I
could more easily use &lt;code&gt;tidyverse&lt;/code&gt; tools with the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nuc_freq_df &amp;lt;- tibble(nucleotide = names(nuc_freq), 
             n = nuc_freq)
nuc_freq_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##   nucleotide     n
##   &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt;
## 1 A           4335
## 2 C           1225
## 3 G           2055
## 4 T           6179&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this format, you can use &lt;code&gt;tidyverse&lt;/code&gt; tools to explore the data a bit more.
For example, you can determine the total number of nucleotides in the genome
and, with that calculate the proportion of each nucleotide across the genome.
Along with the &lt;code&gt;kable&lt;/code&gt; function from the &lt;code&gt;knitr&lt;/code&gt; package, I created a formatted
table with this information:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nuc_freq_df %&amp;gt;% 
  mutate(prop = n / sum(n)) %&amp;gt;% 
  kable(digits = 2, 
        caption = &amp;quot;Nucleotide frequencies and proportions in *C. elegans*&amp;quot;,
        col.names = c(&amp;quot;Nucleotide&amp;quot;, &amp;quot;Frequency&amp;quot;, &amp;quot;Proportion&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-4&#34;&gt;Table 1: &lt;/span&gt;Nucleotide frequencies and proportions in &lt;em&gt;C. elegans&lt;/em&gt;&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Nucleotide&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Frequency&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Proportion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4335&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.31&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1225&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.09&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;G&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2055&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;T&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6179&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.45&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For some presentations, it might be clearer to present this information in a
slightly different table format, using &lt;code&gt;pivot_longer&lt;/code&gt; and then &lt;code&gt;pivot_wider&lt;/code&gt; to
reformat the table for presentation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nuc_freq_df %&amp;gt;% 
  mutate(prop = n / sum(n),
         n = prettyNum(n, big.mark = &amp;quot;,&amp;quot;),
         prop = prettyNum(prop, digits = 2)) %&amp;gt;% 
  pivot_longer(cols = c(&amp;quot;n&amp;quot;, &amp;quot;prop&amp;quot;)) %&amp;gt;% 
  pivot_wider(names_from = &amp;quot;nucleotide&amp;quot;) %&amp;gt;% 
  mutate(name = case_when(
    name == &amp;quot;n&amp;quot; ~ &amp;quot;Frequency of nucleotide&amp;quot;,
    name == &amp;quot;prop&amp;quot; ~ &amp;quot;Proportion of all nucleotides&amp;quot;
  )) %&amp;gt;%  
  rename(` ` = name) %&amp;gt;% 
  kable(align = c(&amp;quot;rcccc&amp;quot;), 
        caption = &amp;quot;Nucleotide frequencies and proportions in *C. elegans*&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-5&#34;&gt;Table 2: &lt;/span&gt;Nucleotide frequencies and proportions in &lt;em&gt;C. elegans&lt;/em&gt;&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;A&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;C&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;G&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;T&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Frequency of nucleotide&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4,335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1,225&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2,055&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6,179&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Proportion of all nucleotides&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.31&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.089&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.45&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is a plot of the frequency of each of the four nucleotides for the &lt;em&gt;C.
elegans&lt;/em&gt; nucleotide:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(nuc_freq_df, aes(x = nucleotide, y = n)) + 
  geom_col(fill = &amp;quot;lavender&amp;quot;, color = &amp;quot;black&amp;quot;) + 
  theme_classic() + 
  scale_y_continuous(label = scales::comma) + 
  theme(axis.title = element_blank()) + 
  labs(title = expression(paste(italic(&amp;quot;C. elegans&amp;quot;), &amp;quot; neucleotide frequency&amp;quot;)),
       caption = expression(paste(&amp;quot;Based on data from the &amp;quot;, italic(&amp;quot;BSgenome.Celegans.UCSC.ce2&amp;quot;), 
                                  &amp;quot; package.&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-exercise-solution-for-chapter-1_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This graph uses a few elements to improve its appearance that you might want to
explore if you’re not already familiar with them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;labs&lt;/code&gt; function is used to add both a title and a caption to the plot.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;paste&lt;/code&gt;, &lt;code&gt;expression&lt;/code&gt;, and &lt;code&gt;italic&lt;/code&gt; functions are used together to put “C.
elegans” and an R package name in italics in some of the labels on the plot.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;scales&lt;/code&gt; package is used inside a scale layer for the &lt;code&gt;ggplot2&lt;/code&gt; code to
make the y-axis labels a bit nicer.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;theme&lt;/code&gt; calls are used to apply a simpler overall theme than the default and to
remove the x- and y-axis titles (with &lt;code&gt;element_blank&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;The color and fill of the bars are customized in the geom layer (&lt;code&gt;geom_col&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From this plot, it certainly looks like the nucleotides are &lt;strong&gt;not&lt;/strong&gt; uniformly
distributed in the &lt;em&gt;C. elegans&lt;/em&gt; genome. This question will be investigated more
in the next part of the exercise.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-b&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part B&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Test whether the &lt;em&gt;C. elegans&lt;/em&gt; data are consistent with the uniform
model (all nucleotide frequencies the same) using a simulation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The second part of the exercise asks us to test whether the observed nucleotide
data for &lt;em&gt;C. elegans&lt;/em&gt; is consistent with the uniform model that all nucleotide
frequencies are the same.&lt;/p&gt;
&lt;p&gt;First, we can simulate several datasets under this null model and see how a plot
of nucleotide frequencies compares to the plot that we obtained with the observed
&lt;em&gt;C. elegans&lt;/em&gt; data. To make these plots, I first simulated 20 samples under the
null model that the distribution is uniform across the four nucleotides, using
the &lt;code&gt;rmultinom&lt;/code&gt; function with the &lt;code&gt;size&lt;/code&gt; argument set to the number of nucleotides in
the original &lt;em&gt;C. elegans&lt;/em&gt; genome data and the &lt;code&gt;prob&lt;/code&gt; argument set to have an equal
probability of each nucleotide at each spot on the genome:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sim_nuc_freq &amp;lt;- rmultinom(n = 20, 
                          size = sum(nuc_freq_df$n), 
                          prob = rep(1 / 4, 4)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
## [1,] 3505 3354 3451 3485 3474 3466 3503 3510 3368  3337  3409  3406  3554  3462
## [2,] 3360 3435 3438 3480 3369 3441 3405 3404 3498  3518  3500  3472  3370  3450
## [3,] 3400 3524 3394 3343 3478 3442 3425 3399 3502  3574  3534  3402  3411  3457
## [4,] 3529 3481 3511 3486 3473 3445 3461 3481 3426  3365  3351  3514  3459  3425
##      [,15] [,16] [,17] [,18] [,19] [,20]
## [1,]  3396  3601  3492  3456  3480  3391
## [2,]  3504  3452  3415  3434  3416  3467
## [3,]  3506  3435  3418  3456  3432  3421
## [4,]  3388  3306  3469  3448  3466  3515&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I moved this into a tibble so I could more easily rearrange and plot the data using
facetting in &lt;code&gt;ggplot2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_nuc_freq_df &amp;lt;- as_tibble(sim_nuc_freq) %&amp;gt;% 
  mutate(nucleotide = c(&amp;quot;A&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;T&amp;quot;)) %&amp;gt;% 
  pivot_longer(-nucleotide, names_to = &amp;quot;sample&amp;quot;) %&amp;gt;% 
  mutate(sample = sample %&amp;gt;% str_remove(&amp;quot;V&amp;quot;) %&amp;gt;% as.numeric()) %&amp;gt;% 
  arrange(sample, nucleotide)

sim_nuc_freq_df %&amp;gt;% 
  slice(1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
##    nucleotide sample value
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
##  1 A               1  3505
##  2 C               1  3360
##  3 G               1  3400
##  4 T               1  3529
##  5 A               2  3354
##  6 C               2  3435
##  7 G               2  3524
##  8 T               2  3481
##  9 A               3  3451
## 10 C               3  3438&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(sim_nuc_freq_df, aes(x = nucleotide, y = value)) + 
  geom_col(fill = &amp;quot;lavender&amp;quot;, color = &amp;quot;black&amp;quot;) + 
  theme_classic() + 
  scale_y_continuous(label = scales::comma) + 
  theme(axis.title = element_blank()) + 
  labs(title = &amp;quot;Simulated neucleotide frequencies under a uniform model&amp;quot;) +
  facet_wrap(~ sample) + 
  expand_limits(y = max(nuc_freq_df$n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-exercise-solution-for-chapter-1_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The y-axis limits were expanded here to cover the same range as that shown for the
observed &lt;em&gt;C. elegans&lt;/em&gt; nucleotide frequencies, to help make it easier to compare these plots
with the plot of our observed data. These plots of data simulated under the null model do
show some variation in frequencies among the nucleotides, but it’s certainly much less than
in the observed data for &lt;em&gt;C. elegans&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Next, I repeated this simulation process, but I increased the number of simulations to 1,000:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_nuc_freq_df &amp;lt;- rmultinom(n = 1000, 
                          size = sum(nuc_freq_df$n), 
                          prob = rep(1 / 4, 4)) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  mutate(nucleotide = c(&amp;quot;A&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;T&amp;quot;)) %&amp;gt;% 
  pivot_longer(-nucleotide, names_to = &amp;quot;sample&amp;quot;) %&amp;gt;% 
  mutate(sample = sample %&amp;gt;% str_remove(&amp;quot;V&amp;quot;) %&amp;gt;% as.numeric()) %&amp;gt;% 
  arrange(sample, nucleotide)

sim_nuc_freq_df %&amp;gt;% 
  slice(1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
##    nucleotide sample value
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
##  1 A               1  3387
##  2 C               1  3512
##  3 G               1  3461
##  4 T               1  3434
##  5 A               2  3522
##  6 C               2  3388
##  7 G               2  3432
##  8 T               2  3452
##  9 A               3  3549
## 10 C               3  3412&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using this dataframe of simulations, we can measure the mean, minimum, and maximum frequencies
of each nucleotide across all 1,000 simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(sim_summary &amp;lt;- sim_nuc_freq_df %&amp;gt;% 
  group_by(nucleotide) %&amp;gt;% 
  summarize(mean_freq = mean(value),
            min_freq = min(value), 
            max_freq = max(value)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 4
##   nucleotide mean_freq min_freq max_freq
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;    &amp;lt;int&amp;gt;
## 1 A              3450.     3296     3649
## 2 C              3443.     3270     3600
## 3 G              3454.     3272     3601
## 4 T              3447.     3290     3609&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To help compare this with the observed data, we can create a table with information from
both the original data and the simulations under the null model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nuc_freq_df %&amp;gt;% 
  left_join(sim_summary, by = &amp;quot;nucleotide&amp;quot;) %&amp;gt;% 
  mutate_at(c(&amp;quot;mean_freq&amp;quot;, &amp;quot;min_freq&amp;quot;, &amp;quot;max_freq&amp;quot;, &amp;quot;n&amp;quot;), 
            prettyNum, big.mark = &amp;quot;,&amp;quot;, digits = 0) %&amp;gt;% 
  mutate(simulations = paste0(mean_freq, &amp;quot; (&amp;quot;, min_freq, &amp;quot;, &amp;quot;, max_freq, &amp;quot;)&amp;quot;)) %&amp;gt;% 
  select(nucleotide, n, simulations) %&amp;gt;% 
  kable(col.names = c(&amp;quot;Nucleotide&amp;quot;,              
        &amp;quot;Frequency in C. elegans genome&amp;quot;,
        &amp;quot;Mean frequency (minimum frequency, maximum frequency) across 1,000 simulations&amp;quot;), 
        align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Nucleotide&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Frequency in C. elegans genome&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Mean frequency (minimum frequency, maximum frequency) across 1,000 simulations&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4,335&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3,450 (3,296, 3,649)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1,225&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3,443 (3,270, 3,600)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;G&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2,055&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3,454 (3,272, 3,601)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;T&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6,179&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3,447 (3,290, 3,609)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This helps clarify how unusual the observed data would be under the null model—the
counts of all four nucleotides in the &lt;em&gt;C. elegans&lt;/em&gt; genome are completely outside the
range of frequencies in the simulated data.&lt;/p&gt;
&lt;p&gt;Another way to look at this is with histograms of the distribution of frequencies
of each nucleotide under the null model compared to the observed frequencies in
the &lt;em&gt;C. elegans&lt;/em&gt; nucleotide:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(sim_nuc_freq_df, aes(x = value)) + 
  geom_histogram(binwidth = 10) + 
  facet_wrap(~ nucleotide) + 
  theme_classic() + 
  scale_x_continuous(name = &amp;quot;Frequency of nucleotide in the simulation under the null model&amp;quot;,
                     labels = scales::comma) + 
  scale_y_continuous(name = &amp;quot;# of simulations (out of 1,000)&amp;quot;) + 
  geom_vline(data = nuc_freq_df, aes(xintercept = n), color = &amp;quot;red&amp;quot;) + 
  labs(title = expression(paste(&amp;quot;Nucleotide frequency in &amp;quot;,
                                italic(&amp;quot;C. elegans&amp;quot;), 
                                &amp;quot; compared null model simulations&amp;quot;)),
       caption = &amp;quot;Red line shows the frequency observed for the nucleotide in C. elegans&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-exercise-solution-for-chapter-1_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally, to help in answering this question, it would be interesting to look at a
single measure for each simulation (and for the observed data) rather than comparing
each nucleotide one at a time. Chapter 1 gives the equation for a statistic to
measure variability in multinomial data by calculating the sum of squares for the
differences between the observed and expected count of nucleotides for each of the
four nucleotides in a sample (p. 12).&lt;/p&gt;
&lt;p&gt;I calculated this statistic for the observed data and then for each of the 1,000
simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(obs_stat &amp;lt;- nuc_freq_df %&amp;gt;% 
  mutate(expected = mean(n),
         stat_input = (n - expected) ^ 2 / expected) %&amp;gt;% 
  summarize(variability_stat = sum(stat_input)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   variability_stat
##              &amp;lt;dbl&amp;gt;
## 1            4387.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_stat &amp;lt;- sim_nuc_freq_df %&amp;gt;% 
  mutate(expected = mean(value), 
         stat_input = (value - expected) ^ 2 / expected) %&amp;gt;% 
  group_by(sample) %&amp;gt;% 
  summarize(variability_stat = sum(stat_input))

sim_stat %&amp;gt;% 
  slice(1:5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   sample variability_stat
##    &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
## 1      1             2.37
## 2      2             2.71
## 3      3             3.95
## 4      4             9.27
## 5      5             4.01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a plot of the distribution of this statistic across the 1,000 simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(sim_stat, aes(x = variability_stat)) + 
  geom_rect(data = sim_stat, aes(xmin = quantile(variability_stat, prob = 0.025),
                                 xmax = quantile(variability_stat, prob = 0.975),
                                 ymin = 0, ymax = Inf), 
            fill = &amp;quot;beige&amp;quot;, alpha = 0.5) +
  geom_histogram(bins = 30, fill = &amp;quot;white&amp;quot;, color = &amp;quot;tan&amp;quot;, alpha = 0.5) +
  theme_classic() + 
  labs(title = &amp;quot;Variability from expected values&amp;quot;,
       subtitle = &amp;quot;Values from simulations under the null&amp;quot;,
       x = &amp;quot;Value of variability statistic&amp;quot;, 
       y = &amp;quot;Number of simulations with given value&amp;quot;,
       caption = &amp;quot;The shaded yellow area shows the region of the central 95% of\nstatistic values for the 1,000 simulations under the null model.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-11-exercise-solution-for-chapter-1_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The value of this statistic for the observed nucleotide frequencies for &lt;em&gt;C.
elegans&lt;/em&gt; is 4387, which is much larger (indicating greater variability
from expected values under the null model) than the value observed under most of
the simulations. It is, in fact, far outside the central 95% range of values
observed in simulations.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabularly for Chapter 2, Part 1</title>
      <link>/post/vocabularly-for-chapter-2-part-1/</link>
      <pubDate>Sun, 09 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabularly-for-chapter-2-part-1/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The first portion of Chapter 2 (2.1-2.7) is focused on statistical modeling of data. It introduces a number of distributions commonly used in statistics, as well as model fitting estimation procedures (e.g. maximum likelihood estimation).&lt;/p&gt;
The vocabulary words for Chapter 2, part 1, are:
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
statistical inference / up / statistical approach
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An upward-reasoning approach that start with data and works towards defining a model that might possibly explain the data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
deduction
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Starting from a mathematical/statistical model with known parameters and computing the probability of observing an event.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
null model
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The model associated with the null hypothesis, which formulates an “uninteresting” baseline.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
goodness-of-fit
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Evaluation of whether a theorectical distribution/model is appropriate for a data set.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rootogram
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Diagram to assess model goodness-of-fit for a data set. Bar chart where the bars “hang” from their theorectical values and will approximately line up with horizontal axis if the model is a good fit to the data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
maximum likelihood estimator (MLE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A rule, or mathematical formula, that outputs an estimate of a parameter for a model, where that estimate maximizes the probability of the observed data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
conservative (approach)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An analysis approach that errs on the side of caution to avoid concluding an alternative hypothesis (e.g. detecting a signal) when it is not true.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
vectorization
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In regard to function evaluation, if a vector is supplied to a function that expects a scalar, R will apply the function to each element of the vector.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
likelihood function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The probability of the data under a model expressed as a function of the model parameter(s).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
estimation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Process of using data to perform inference on population parameters.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
statistical testing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Formal decision process to determine if a null model is appropriate for the observed data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
regression
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Relating how an outcome measure depends on one or more covariates.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
residual
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Deviation between the observed data and the expected value of the data point according to a model.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
generalized linear model
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A class of models for non-continuous or non-negative data that allows regression of an outcome on observed covariates. An extension of linear regression.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
chi-squared distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distribution on the non-negative real numbers that is often used in assessing goodness-of-fit (e.g. models fit to contingency tables).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
quantile-quantile (QQ) plot
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Used to compare two distributions (or samples). Deviations in the plot from the y=x line suggest differences between the two distributions.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
quantile
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Value corresponding to a percentile of a distribution.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
empirical cumulative distribution function (ECDF)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Function with input value x gives as output the probability that a random variable from the distribution is less than or equal to x. Function is defined using a sample and assigning probability 1/n to each data point.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
chi-squared statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A summary statistic of a data set that has a theorectical chi-squared distribution.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
base pairing
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The pattern that adenine (A) and thymine (T) are paired (appear with equal frequency) in the DNA of an organism, and similarly cytosine (C) and guianine (G) are paired.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
contingency table
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Table of counts summarizing the number of times combinations of factor levels were observed in the data set.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Hardy-Weinberg equilibrium (HWE)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Assuming random mating, this principle characterizes the distribution of genotype frequencies as a function of the relative frequencies of each allele.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
position weight matrix (PWM) / position-specific scoring matrix (PSSM)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Table giving the probability of each nucleotide at each position
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sequence logo
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A graphical summary of the position weight matrix or position-specific scoring matrix.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/483285431/flashcards/embed?i=2ldef3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 1 exercise setup</title>
      <link>/post/chapter-1-exercise-setup/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-1-exercise-setup/</guid>
      <description>


&lt;p&gt;The code instructions in the exercise statement appear to be outdated. The code below worked on my machine. Note that when asked whether I would like to update packages from the binary version, I said no. (When I said yes, &lt;code&gt;R&lt;/code&gt; gave an error.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!requireNamespace(&amp;quot;BiocManager&amp;quot;, quietly = TRUE))
  install.packages(&amp;quot;BiocManager&amp;quot;)
BiocManager::install(c(&amp;quot;Biostrings&amp;quot;, &amp;quot;BSgenome.Celegans.UCSC.ce2&amp;quot;,&amp;quot;BSgenome&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see the various data genome data sets available by loading the &lt;code&gt;BSgenome&lt;/code&gt; library and typing &lt;code&gt;available.genomes()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once you have the needed packages installed, you can access the sequence data for this exercise via the following commands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressMessages(library(&amp;quot;BSgenome.Celegans.UCSC.ce2&amp;quot;))
Celegans&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Worm genome:
## # organism: Caenorhabditis elegans (Worm)
## # provider: UCSC
## # provider version: ce2
## # release date: Mar. 2004
## # release name: WormBase v. WS120
## # 7 sequences:
## #   chrI   chrII  chrIII chrIV  chrV   chrX   chrM                              
## # (use &amp;#39;seqnames()&amp;#39; to see all the sequence names, use the &amp;#39;$&amp;#39; or &amp;#39;[[&amp;#39; operator
## # to access a given sequence)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seqnames(Celegans)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;chrI&amp;quot;   &amp;quot;chrII&amp;quot;  &amp;quot;chrIII&amp;quot; &amp;quot;chrIV&amp;quot;  &amp;quot;chrV&amp;quot;   &amp;quot;chrX&amp;quot;   &amp;quot;chrM&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Celegans$chrM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   13794-letter &amp;quot;DNAString&amp;quot; instance
## seq: CAGTAAATAGTTTAATAAAAATATAGCATTTGGGTT...TATTTATAGATATATACTTTGTATATATCTATATTA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(Celegans$chrM)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;DNAString&amp;quot;
## attr(,&amp;quot;package&amp;quot;)
## [1] &amp;quot;Biostrings&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(Celegans$chrM)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13794&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Biostrings packages provides functions to summarize the sequence. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;Biostrings&amp;quot;)
lfM = letterFrequency(Celegans$chrM, letters=c(&amp;quot;A&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;T&amp;quot;))
lfM&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    A    C    G    T 
## 4335 1225 2055 6179&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(lfM)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13794&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 1 vocabulary quiz</title>
      <link>/post/chapter-1-vocabulary-quiz/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/chapter-1-vocabulary-quiz/</guid>
      <description>


&lt;p&gt;The vocabulary quiz will be live here during the start of the course.&lt;/p&gt;
&lt;iframe src=&#34;https://docs.google.com/forms/d/e/1FAIpQLSc6dQBUXr_diDWTwwGfUe3z39zwCQH56R0tNljKlcKr9zzyGg/viewform?embedded=true&#34; width=&#34;640&#34; height=&#34;3200&#34; frameborder=&#34;0&#34; marginheight=&#34;0&#34; marginwidth=&#34;0&#34;&gt;
Loading…
&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>How to create a vocabulary list blog post</title>
      <link>/post/creating-a-vocabulary-list-blog-post/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/creating-a-vocabulary-list-blog-post/</guid>
      <description>


&lt;p&gt;As one of your assignments for this class, you are responsible for creating a blog
post with all the vocabulary and definitions for one week of the course. This
blog post will explain how you can create and publish that blog post on our
course website.&lt;/p&gt;
&lt;div id=&#34;create-the-blog-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Create the blog post&lt;/h1&gt;
&lt;div id=&#34;update-your-fork-of-the-website&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Update your fork of the website&lt;/h2&gt;
&lt;p&gt;You should have already forked our website to add your details for the “Person”
section. You can use this same fork to add your blog post, but you should make sure
you get your fork up-to-date with the current version of the website before you do.&lt;/p&gt;
&lt;p&gt;A fork of a repository does not stay up-to-date with the original repository it
copied by itself. Instead, unless you update it, it will continue to be a snapshot
of the original repository (plus any changes you’ve made to your copy) as of
the time when you forked it. If the original has made a lot of changes since you
made your fork, it might be very hard to make a clean pull request as there will
be (potentially) lots of conflicts because of changes made to the original. It’s
considered polite to make sure that you’re working with an up-to-date fork of
a repository if you want to make a pull request back to the original.&lt;/p&gt;
&lt;p&gt;To update your fork of the original repository, open your “csu_msmb.Rproj” file
to open our website’s R Project on your computer. This should open RStudio with
the website’s project open (check the top right corner of your RStudio window to
confirm—it should say “csu_msmb”).&lt;/p&gt;
&lt;p&gt;There is a little blue gear symbol in the “Git” pane in RStudio. Click on the down
arrow to the right of it and select “Shell…”. This should open a bash shell on
your computer. (If your computer uses Windows, there’s a chance that it might open
something other than a bash shell. In that case, you can change your preferences in
RStudio to reconfigure to always use a bash shell terminal when you ask for a shell
from RStudio.)&lt;/p&gt;
&lt;p&gt;In this shell, you need to run two &lt;code&gt;git&lt;/code&gt; commands. First, you’ll add a remote branch
to your repository. You already have one remote branch called “origin”—that’s the
GitHub repository that you have in your account, which you forked from the original.
Now you’ll add the &lt;em&gt;original&lt;/em&gt; (the GitHub repository in my account) as another remote
branch. Each branch has its own name, and you can use that name to refer to it in later
&lt;code&gt;git&lt;/code&gt; commands. The convention, if you add an original repository that you forked from
as a remote, is to name that remote branch “upstream”. Run the following code in your
bash shell to add the original GitHub repository as a remote branch with the name
“upstream”:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git remote add upstream git@github.com:geanders/csu_msmb.git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that you have added the original as a remote, you can pull in any commits that were
made to it since you originally forked it. There are a few ways you can do that, but one
way to do it in one step is with git’s &lt;code&gt;pull&lt;/code&gt; command. This fetches the changes and merges
them into your local version of the repository, all in one step. Run the following code in
your bash shell to do that:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git pull upstream master&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ideally, all this will have worked seamlessly (if not, check with the faculty and we can
help you troubleshoot). Close your bash shell and check your version
of the “csu_msmb” project to see if it looks like it’s up-to-date with the original. You can
go to the “Commit” button in the “Git” tab, and there is a “History” selection in the window
that pops up. Look through that and make sure that you see recent commits to confirm that
your version is now up-to-date.&lt;/p&gt;
&lt;p&gt;Finally, this has updated your local version, but not your GitHub remote. Go ahead and use the
green up arrow in RStudio’s “Git” pane to push your updated local version up to GitHub. Now
both your local (“master”) and remote (“origin”) branches should be up-to-date with our
original version, so it will make it much easier to merge in your changes.&lt;/p&gt;
&lt;p&gt;If you’d like to learn more about this process, there’s a really nice blog post
&lt;a href=&#34;https://philna.sh/blog/2018/08/21/git-commands-to-keep-a-fork-up-to-date/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;making-a-new-blog-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making a new blog post&lt;/h2&gt;
&lt;p&gt;In &lt;code&gt;blogdown&lt;/code&gt;, each blog post is an RMarkdown document. The stuff at the very top
of the file (the YAML with details like the title and author) will look a bit
different than plain RMarkdown files, but once you get into the body of the post,
you should find that the rules are very similar to RMarkdown.&lt;/p&gt;
&lt;p&gt;You will be creating a blog post that will include a table with the vocabulary
list as well as a few other elements. There are a few ways you can add a new
blog post file in &lt;code&gt;blogdown&lt;/code&gt;. You’re welcome to use any method you’d like, but
if you’re not sure where to start, this is one way.&lt;/p&gt;
&lt;p&gt;Make sure that you have RStudio open to the project for our course’s website. If you
do, you should see &lt;code&gt;csu_msmb&lt;/code&gt; in the upper right hand corner of your RStudio session.
(If not, go to &lt;code&gt;File&lt;/code&gt; -&amp;gt; &lt;code&gt;Open Project...&lt;/code&gt; and navigate through your file directory
to your local version of our project directory and open the &lt;code&gt;csu_msmb.RProj&lt;/code&gt; file there.)&lt;/p&gt;
&lt;p&gt;Next, you can use an RStudio “Addin” to make a new blog post using a nice user
interface. These Addins are all alternatives to things you could do with a
function call in R, but the Addin often provides a more immediately
user-friendly interface for you to enter options. For example, the Addin for
creating a blog post does all the actions of a &lt;code&gt;blogdown&lt;/code&gt; function called
&lt;code&gt;new_post&lt;/code&gt;, but instead of needing to remember the parameter name to use for the
author listing and the title and all that, you can just fill the information
into a nice form and go from there.&lt;/p&gt;
&lt;p&gt;To find the new post Addin, look at the top of your RStudio session window. You
should see “Addins” with a down arrow beside it. Click on the down arrow. When
you do, you should see a “New Post” option. Select this option. A form should
pop up with spaces for you to fill in the title, author, and some other details.&lt;/p&gt;
&lt;p&gt;Fill this form out in the following way:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Title:&lt;/strong&gt; This should be “Vocabulary for Chapter [x]”, but with “[x]” replaced
with your chapter number.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Author:&lt;/strong&gt; Make sure you put your name exactly as listed in the “People” section
of the website. This will help the website generator connect this post with your
user profile, so when someone reads it they’ll get your picture and a link to
find out more about you at the end of the post.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Date:&lt;/strong&gt; This is where you put the publication date of your blog post, and it
has a pretty cool feature. Even if you write your blog post earlier, the post
will not be published on the blog &lt;em&gt;until&lt;/em&gt; the date listed in this section. That means
that you can start writing your blog on one day but know that it won’t show up online
until later. It also means you can start work on your blog, but a half-finished
draft won’t show up online until you get to the publication date. For right now,
set the current date in this section, so that your blog post will show up locally as
you work on it, but later you’ll actually change this date so that, when you submit
your pull request, your post won’t show up until the faculty have had the chance to
suggest some changes and for you to make any needed fixes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Categories and tags:&lt;/strong&gt; For both the “Categories” and the “Tags”, be sure to
include &lt;code&gt;vocabulary&lt;/code&gt; and &lt;code&gt;Chapter [x]&lt;/code&gt; (with [x] replaced with your chapter’s number).
These tags will let everyone on our website quickly find all the blog posts on your
chapter or all the vocabulary lists.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Format:&lt;/strong&gt; You have several choices for the type of file to use to write your
blog post. Since we’re going to be using some R code to make the table look pretty,
you’ll need to pick one of the options that allows for R code chunks, so that rules
out plain Markdown. I recommend that you use “.Rmd”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once you make these entries, click the button labeled “Done”. This creates an
RMarkdown file for your blog post and opens it for you. Here’s an example of
me doing this process if I were writing the vocabulary list for Chapter 16:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/post_addin.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can see, in the RMarkdown file that’s created and opened, that all these
details end up getting inserted into the YAML at the top of the RMarkdown file.
If you ever need to change anything (like the date or the title), you can
change it here in the RMarkdown file. Do so carefully, though—YAML can be
pretty picky about things like spacing and special characters (hyphens, for
example).&lt;/p&gt;
&lt;p&gt;If you ever need to find this file later, all of the blog posts are saved in a
special place in our project’s directory: in the &lt;code&gt;content&lt;/code&gt; subdirectory, there’s
a subdirectory called &lt;code&gt;post&lt;/code&gt; that contains both the RMarkdown files used to
write the posts and the output (an HTML file) that is created by the RMarkdown
each time you save the file. You might notice that they all have long file
names—the file name for a blog post is a combinataion of its publication date
and its “slug”, which is some abbreviation of the original title. If you really
want, you can change what the slug will be when you first create the blog post,
but I don’t think you really need to.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;writing-in-the-blog-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Writing in the blog post&lt;/h2&gt;
&lt;iframe src=&#34;https://giphy.com/embed/XIqCQx02E1U9W&#34; width=&#34;480&#34; height=&#34;269&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;
&lt;/iframe&gt;
&lt;p&gt;
&lt;a href=&#34;https://giphy.com/gifs/XIqCQx02E1U9W&#34;&gt;via GIPHY&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Within the body of the blog post RMarkdown file (in other words, below the
&lt;code&gt;---&lt;/code&gt; that marks the end of the YAML section), you can write the blog post
just as you would any RMarkdown document. This means that you can use
things like &lt;code&gt;**&lt;/code&gt; to mark bold text, &lt;code&gt;*&lt;/code&gt; for italics, and &lt;code&gt;#&lt;/code&gt;, &lt;code&gt;##&lt;/code&gt;, etc., for
section headings.&lt;/p&gt;
&lt;p&gt;It also means that you can insert chunks of R code that will run and add
their output within the post. Unlike in regular RMarkdown, you usually won’t
have to press the &lt;code&gt;Knit&lt;/code&gt; button to knit the document. Instead, the blog post
should re-knit every time you save the file. You can check to see by looking
at the &lt;code&gt;Viewer&lt;/code&gt; pane to look at the current version of the site (if it doesn’t
show the site automatically, load the &lt;code&gt;blogdown&lt;/code&gt; package and then run
&lt;code&gt;serve_site&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;If you have not worked much with RMarkdown before, you might want to check
out some references on how it works. There are several great articles on the
&lt;a href=&#34;https://rmarkdown.rstudio.com/articles.html&#34;&gt;RMarkdown website&lt;/a&gt; that can help.&lt;/p&gt;
&lt;p&gt;In your blog post, go ahead and draft a first paragraph that describes the
key concepts covered in the chapter. Also, create third-level section headings
(i.e., use &lt;code&gt;###&lt;/code&gt; to mark the section heading) for “Sources consulted or cited”
and “Practice”. Save your blog post file and check to see if these changes
have been made in the version of the website in your &lt;code&gt;Viewer&lt;/code&gt; pane!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/start_post.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;create-the-vocabulary-list&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Create the vocabulary list&lt;/h1&gt;
&lt;p&gt;Now, for the content of your post. You’ll be creating a vocabulary list, as well
as embedding a Quizlet practice app, so that your classmates can learn the
vocabulary for the chapter. This list will be what everyone is responsible for
in the weekly vocabulary quiz.&lt;/p&gt;
&lt;p&gt;You can see an example of a vocabulary blog post for
&lt;a href=&#34;https://kind-neumann-789611.netlify.com/post/vocabulary-for-chapter-1/&#34;&gt;Chapter 1&lt;/a&gt;. You can use
this as a template for your own post.&lt;/p&gt;
&lt;div id=&#34;identify-the-vocabulary-terms-you-need-to-define&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Identify the vocabulary terms you need to define&lt;/h2&gt;
&lt;p&gt;First, you will need to decide which words from the chapter to define. We expect
that you will include &lt;strong&gt;all&lt;/strong&gt; the bolded terms for your chapter.
Here are some guidelines for deciding on the vocabulary terms to define for your
chapter:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You should include all words in the chapter that are given in bold. Be sure to
look for bolded terms in the sidenotes and end-of-chapter exercises, too! Occassionally,
the authors use bold for subheadings (see the “Why R and Bioconductor?” section in
the Introduction or the “Summary of this chapter” section of Chapter 1). These
subheadings do not need to be included in the vocabulary list for the chapter.&lt;/li&gt;
&lt;li&gt;If you find one or more common synonyms for a term, you can include that with
the term in the list (e.g., “variability / spread / dispersion”).&lt;/li&gt;
&lt;li&gt;Feel free to change a term from singular to plural or vice versa if it helps you
in writing the term’s definition. Similarly, if the bolded term does not include
all the words that would be helpful (e.g., the bolded term is “sufficient”, but
the term of interest is “sufficient statistic”), you can add a word or two to the
bolded term.&lt;/li&gt;
&lt;li&gt;The bolded terms in the book tend to favor statistical terms over biological ones.
If there are some biological terms you needed to look up when you read the chapter,
or that you think some people in the class might not know,
feel free to add them to your vocabulary list.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-.tsv-file-with-terms-and-definitions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a .tsv file with terms and definitions&lt;/h2&gt;
&lt;p&gt;While you could directly add the vocabulary into an RMarkdown table, we are asking you
to save it into a plain text &lt;code&gt;.tsv&lt;/code&gt; file, which will then be read into the RMarkdown
document to form a table. We doing this because it creates a few advantages. First,
if we have the vocabulary list in a dataframe (which we get when we read it in from
a plain text file), we can use some cool R packages to format the table nicely, without
having to learn loads of new Markdown or HTML formatting tricks. Second, we want to also
use the vocabulary list as input to a &lt;a href=&#34;https://quizlet.com/latest&#34;&gt;Quizlet&lt;/a&gt; list, which
will let us embed a practice app with flashcards and quizzes. One of the easiest ways
to create a Quizlet list is to copy in vocabulary list directly in the &lt;code&gt;tsv&lt;/code&gt; format,
so this approach makes that secondary use easy.&lt;/p&gt;
&lt;p&gt;In our website’s repository, there is a special subdirectory for saving vocabulary list
&lt;code&gt;.tsv&lt;/code&gt; files, with one for each chapter. In the Project directory, go to &lt;code&gt;content&lt;/code&gt; -&amp;gt;
&lt;code&gt;post&lt;/code&gt; -&amp;gt; &lt;code&gt;vocab_list&lt;/code&gt;. This is where you want to save the &lt;code&gt;.tsv&lt;/code&gt; file for your chapter.&lt;/p&gt;
&lt;p&gt;To create the file, in RStudio go to the “File” tab in the menu at the top and select
“New File” -&amp;gt; “Text File”. This will open a file in RStudio in plain text format. Save the
file as “chapter_[x].tsv” (but replace “[x]” with your chapter number). Make sure you save
it in the “vocab_list” subdirectory of the project with the rest of the vocabulary list files.&lt;/p&gt;
&lt;p&gt;Now write your vocabulary terms and definitions in this &lt;code&gt;.tsv&lt;/code&gt;. This file extension stands
for “tab-separated”, so to format the file correctly, you should:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Put each term / definition pair on its own line. Because some terms will be long, they
may visibly “wrap” in the text file you have open, but as long as you don’t press the
“Return” key, they should still be on one line of the file. To doublecheck, you may want
to make sure that you have line-numbering on in RStudio and make sure that only one line
number is listed for each term on the left hand side of the file.&lt;/li&gt;
&lt;li&gt;Press the “Tab” key to add a tab between the term and definition on each line. This should
be the &lt;em&gt;only&lt;/em&gt; place you have tabs in the file. R will look for tabs to figure out where to
split between vocabulary terms and there definitions (as will Quizlet when you copy the
terms into the list there). Sometimes it won’t look like the tab’s added a lot of space,
but that’s no problem—the computer can see it even if you can’t!&lt;/li&gt;
&lt;li&gt;Don’t put any header information at the start of the file. Just start directly with your
first vocabulary term.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/make_vocab_tsv.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you’d like to see an example, check out the “chapter_1.tsv” file in the “vocab_lists”
subdirectory. This is the file that serves as input for the Chapter 1 vocabulary list
blog post.&lt;/p&gt;
&lt;p&gt;Here are some guidelines for writing your definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is fine to use wording from the chapter text or to use wording directly from
other websites or sources. However, you &lt;strong&gt;must&lt;/strong&gt; include a list of any of the
sources that you used to write your definitions at the bottom of the vocabulary
blog post. Further, if you are using sources besides the course textbook, make sure
that the definition is appropriate in the context of our course. Often, words will
have a number of different definitions across different disciplines. Try to use
more formal sources (e.g., textbooks, other published books) rather than less
formal websites to find definitions whenever possible. See the
&lt;a href=&#34;https://kind-neumann-789611.netlify.com/post/vocabulary-for-chapter-1/&#34;&gt;Chapter 1&lt;/a&gt; vocabulary list
for an example of what we expect for using and listing references.&lt;/li&gt;
&lt;li&gt;If a vocabulary term was defined in a previous chapter’s vocabulary list, feel free
to reuse the definition.&lt;/li&gt;
&lt;li&gt;Our library has excellent resources that you can use to help write your definitions,
including textbooks and dictionaries specific to biology and statistics.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-r-code-to-show-the-list-in-the-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adding R code to show the list in the post&lt;/h2&gt;
&lt;p&gt;I’ve written up some R code that will read in the vocabulary list and make it
into a nicely formatted table in the HTML version of the blog post. You can
re-use this R code in your post, you’ll just need to change the name of the
input file to the one for your chapter’s file.&lt;/p&gt;
&lt;p&gt;This R code uses a few R packages beyond the base R code. If you haven’t installed
these packages yet, you’ll need to before the code will run. You’ll need to install:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;knitr&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dplyr&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;readr&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kableExtra&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once you have these, below your paragraph summarizing the chapter’s theme, write:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The vocabulary words for Chapter [x] are:”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(but with your chapter’s number) and then paste in the following code and change
&lt;code&gt;chapter_1.tsv&lt;/code&gt; in the code to the correct file name for the .tsv file you created
for your chapter’s vocabulary.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r echo = FALSE, message = FALSE, warning = FALSE}
# Load packages
library(dplyr)
library(readr)
library(knitr)
library(kableExtra)

# Read in vocabulary from tsv into a dataframe
# This is where you&#39;ll need to replace the file name with your own
vocab &lt;- read_tsv(&#34;vocab_lists/chapter_1.tsv&#34;,
                  col_names = c(&#34;term&#34;, &#34;definition&#34;))

# Print the dataframe as a nice-looking table
vocab %&gt;% 
  kable(align = c(&#34;rl&#34;), 
        col.names = c(&#34;&#34;, &#34;&#34;)) %&gt;% 
  kable_styling(bootstrap_options = c(&#34;striped&#34;, &#34;hover&#34;,
                                      &#34;condensed&#34;)) %&gt;% 
  column_spec(1, bold = T, border_right = T) %&gt;%
  column_spec(2, width = &#34;30em&#34;)
```&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code reads in the data from your .tsv file and then formats it in a nice way.
If you’d like to understand it better, try commenting out some lines and see how it
changes the output. One of my favorite piece of this code, one that I think might
come in useful for you later, is &lt;code&gt;column_spec(2, width = &#34;30em&#34;)&lt;/code&gt;. This sets the
width of one of the columns to be 30 ems (the width of the letter “m” in whatever
font you’re using). By setting the width, the table won’t automatically expand to
fit the text you put in the column onto one row. Instead, it will allow the text
to “wrap”, going onto separate lines if the definition entry is long enough.&lt;/p&gt;
&lt;p&gt;If you want to find out more about creating really fancy tables from RMarkdown,
check out the documentation on the &lt;code&gt;kableExtra&lt;/code&gt; package. What you can do (and how)
is different, depending on whether you’re outputting to a pdf or a HTML file, so there’s
separate documentation for each.&lt;/p&gt;
&lt;p&gt;Once you add this code in, I’ve found that you actually do need to press the &lt;code&gt;Knit&lt;/code&gt;
button sometimes. If you don’t see your list when you save your file, or if it doesn’t
update properly as you make changes to your file, try knitting with the &lt;code&gt;Knit&lt;/code&gt; button
and that should help.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/add_vocab_code.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-and-embedding-a-quizlet-app&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating and embedding a Quizlet app&lt;/h2&gt;
&lt;p&gt;The last piece of the blog post is the practice section. For this, you’ll create
a vocabulary list on &lt;a href=&#34;quizlet.com&#34;&gt;Quizlet&lt;/a&gt;, which you can then embed in the
blog post, so the other students can practice right on our site.&lt;/p&gt;
&lt;p&gt;You’ll need to sign up for a Quizlet account first. The free account is fine.&lt;/p&gt;
&lt;p&gt;Next, create a new vocabulary list. There’s a “Create” button for making new lists
on the main page. While you can add vocabulary by hand, you can also post in a
whole list if it’s in a tab-separated or comma-separated format. Copy in the contents
of your vocabulary list &lt;code&gt;.tsv&lt;/code&gt; file. You can preview the terms lower on the page
once you do, to make sure that all the terms and definitions came in correctly.
If everything looks good, click on the buttons for “Import” and then “Create”.&lt;/p&gt;
&lt;p&gt;This will create your list and take you to a page where you can try out your
flashcards. On this page, there’s also a button with three dots. If you click on
this, there’s a choice of “Embed”. When you &lt;strong&gt;embed&lt;/strong&gt; HTML content, you are
inserting an application from one website within another one. Embedding is a
really fun trick for enriching blog posts and other RMarkdown documents that
are rendered to HTML. For example, you can also embed Shiny apps, YouTube
videos, and Google maps in your RMarkdown using the same process we’ll use here.&lt;/p&gt;
&lt;p&gt;When you select “Embed”, a pop-up window will open with some HTML code. Copy
this and then paste it in the “Practice” section of your vocabulary blog post.
Be sure to leave a blank line above and below the text you paste. When you
look at your blog post in a web browser now, you should see the practice
flashcards embedded in the “Practice” section.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/make_quizlet_app.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;submit-the-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Submit the post&lt;/h1&gt;
&lt;iframe src=&#34;https://giphy.com/embed/dOIDOBVNKmcFi&#34; width=&#34;480&#34; height=&#34;200&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;
&lt;/iframe&gt;
&lt;p&gt;
&lt;a href=&#34;https://giphy.com/gifs/blog-book-blaxk-dOIDOBVNKmcFi&#34;&gt;via GIPHY&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;So far, you’ve made these changes to your local copy of our website’s
repository. To submit the changes to us, you’ll need to push your changes
to your remote version of the repository (the one in &lt;em&gt;your&lt;/em&gt; GitHub account)
and then submit a pull request to us for us to pull those changes into the
original website repository (the one in &lt;em&gt;my&lt;/em&gt; GitHub account). This process
should feel pretty familiar—it’s pretty much what you did to submit your
changes to your profile information for the website on the first day of class.&lt;/p&gt;
&lt;p&gt;As with other steps, there are several ways you can do this, and if you have an
idea of how to get it done, any way is fine. If you don’t know where to start,
though, you can follow along in this section for one way to do it.&lt;/p&gt;
&lt;div id=&#34;pushing-your-changes-to-your-remote-repo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pushing your changes to your remote repo&lt;/h2&gt;
&lt;p&gt;First, you’ll need to get any changes you’ve made from your local
repository up to your remote version on GitHub.&lt;/p&gt;
&lt;p&gt;First, &lt;strong&gt;commit&lt;/strong&gt; any changes that you’ve made through the &lt;code&gt;Git&lt;/code&gt; window in your
RStudio session. This will record the changes you’ve made in the &lt;code&gt;git&lt;/code&gt; record
for your local repository.&lt;/p&gt;
&lt;p&gt;Next, you’ll need to &lt;strong&gt;push&lt;/strong&gt; these commits to the remote repository, to send
these changes to GitHub. In the &lt;code&gt;Git&lt;/code&gt; window in RStudio, there’s a green up
button. Push that. It should send all your changes up to your GitHub version of
the repository. To check, go online to your GitHub account and look through
your repositories for your fork of “csu_msmb”. Click on “Commits” to see a
history of the commits to the repository—your latest ones should be at the top
of the list.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;submitting-a-pull-request-to-the-original-repo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Submitting a pull request to the original repo&lt;/h2&gt;
&lt;p&gt;At this point, you’ve made changes, checked them, and pushed them to your GitHub version of
the repository. Remember, though, that you forked the repository from our original one, and
so you’ve been working with a copy of the repository this whole time, rather than changing
our original version.&lt;/p&gt;
&lt;p&gt;To get your changes incorporated into our original version, you’ll need to request that we
&lt;strong&gt;pull&lt;/strong&gt; your changes into the original repository. To do this, you can submit a &lt;strong&gt;pull request&lt;/strong&gt;
through GitHub. Go to the main page for your fork of the GitHub repository and look for
a button that says “New pull request”. When you click this, it will walk you through making
a pull request. You’ll have a space to write a message describing the changes you’re
recommending in the pull request.&lt;/p&gt;
&lt;p&gt;If you’d like more details on this information, GitHub has &lt;a href=&#34;https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request&#34;&gt;help documentation
on pull
requests&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;edit-and-re-submit-the-post-based-on-faculty-feedback&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Edit and re-submit the post based on faculty feedback&lt;/h1&gt;
&lt;p&gt;The other faculty members and I will get a notice when you submit your pull request. We’ll
take a look and will probably have some suggestions for the wording of some of the
vocabulary terms. We’ll give you some feedback through the pull request page, and then
we’ll work together to get the list finalized before it’s published for the rest of the
class.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to add your profile details to our course website</title>
      <link>/post/add-profile-details/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/add-profile-details/</guid>
      <description>


&lt;p&gt;One goal of this course is to continue developing your data science programming
skills. This will include plenty of work on R programming, but also more to
help you learn tools for reproducible research, like
&lt;a href=&#34;https://rmarkdown.rstudio.com/&#34;&gt;RMarkdown&lt;/a&gt; and &lt;a href=&#34;https://git-scm.com/&#34;&gt;git&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We will be using our course website as a collaboration tool during this course.
This website was created using &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt;,
which allows you to create and update a blogging website with R and RStudio. We
are using a &lt;a href=&#34;https://github.com/geanders/csu_msmb&#34;&gt;GitHub repository&lt;/a&gt; to share
all the code for this website and serving the site using &lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;During this course, you will have two graded products that you will need to
submit as blog posts to our site. One will be a glossary of vocabulary terms for
one chapter of the book, listing key words and their definitions for the
chapter. The second will be the “official” version of one week’s in-course exercise.&lt;/p&gt;
&lt;p&gt;To help get you up to speed with using blogdown, GitHub, and RMarkdown with
our site, we’ll start by having you update your profile details for our website.
We’ll also use this to give you all a chance to introduce yourselves to each
other and to us. This post covers the details for how to do that.&lt;/p&gt;
&lt;div id=&#34;required-set-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Required set-up&lt;/h1&gt;
&lt;p&gt;This exercise, and this course as a whole, requires a certain set-up
on your computer:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;R installed on your laptop&lt;/li&gt;
&lt;li&gt;RStudio installed on your laptop&lt;/li&gt;
&lt;li&gt;git installed on your laptop&lt;/li&gt;
&lt;li&gt;Your own GitHub account&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you already have all this set-up, you can skip to the next section.
Otherwise, this section has details on completing this set up.&lt;/p&gt;
&lt;div id=&#34;install-r-on-your-laptop&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Install R on your laptop&lt;/h2&gt;
&lt;p&gt;You can install R from the &lt;a href=&#34;https://cran.rstudio.com/&#34;&gt;Comprehensive R Archive Network (CRAN)&lt;/a&gt;.
Search for the version appropriate for your computer’s operating system.&lt;/p&gt;
&lt;p&gt;If you already have R installed, check your version number. If it’s older than
six months or so, you should probably update your version for the class. You can
use the &lt;code&gt;sessionInfo()&lt;/code&gt; function to find out details about your current R
session, including the version of R you’re currently running:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Mojave 10.14.6
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## loaded via a namespace (and not attached):
##  [1] compiler_3.6.3  magrittr_1.5    bookdown_0.18   tools_3.6.3    
##  [5] htmltools_0.4.0 yaml_2.2.1      Rcpp_1.0.4.6    stringi_1.4.6  
##  [9] rmarkdown_2.1   blogdown_0.18   knitr_1.28      stringr_1.4.0  
## [13] digest_0.6.25   xfun_0.13       rlang_0.4.6     evaluate_0.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the return from this call, for example, I can tell that I have
R version 3.6.3 (2020-02-29).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;install-rstudio-on-your-laptop&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Install RStudio on your laptop&lt;/h2&gt;
&lt;p&gt;You can download RStudio directly
&lt;a href=&#34;https://rstudio.com/products/rstudio/download/&#34;&gt;from their website&lt;/a&gt;. The free
Desktop version will work great for this course. If your version of RStudio is
more than a year old, you should probably update it for this course. To check
your version of R Studio, open R Studio, go to the “RStudio” tab at the top,
and click on “About RStudio”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;install-git-on-your-laptop&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Install git on your laptop&lt;/h2&gt;
&lt;p&gt;The software &lt;strong&gt;git&lt;/strong&gt; is version control software, which will help you record and
track changes that you’ve made to code and other plain text documents.&lt;/p&gt;
&lt;p&gt;It’s free to download. Go to &lt;a href=&#34;https://git-scm.com/downloads&#34; class=&#34;uri&#34;&gt;https://git-scm.com/downloads&lt;/a&gt; and select the version
for your operating system. For this software, you’re probably okay if you
downloaded it a little while ago (although if more than two years or so, you might
want to update).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-a-github-account&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Get a GitHub account&lt;/h2&gt;
&lt;p&gt;You will need a (free) GitHub account for this course. You can sign up for one
(if you don’t already have one) at &lt;a href=&#34;https://github.com/&#34; class=&#34;uri&#34;&gt;https://github.com/&lt;/a&gt;. While there are some
fancier paid plans available, the free account will work great for this class.&lt;/p&gt;
&lt;p&gt;When you sign up, you’ll get to choose a GitHub handle. You might want to make
this something that will be easy for people to remember. For example, if your
name is still available, that would be a great option. This handle will form
part of the address to all of your GitHub repositories, so it is convenient if
it is easy for people you work with to remember (mine, unfortunately, is not!).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;about-blogdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;About &lt;em&gt;blogdown&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;blogdown&lt;/code&gt; package is an R package created by Yihui Xie that allows you
to use R and RStudio to create and update your own webpage with a blog. The
appeal of being able to do this with R is that you can write blog posts
using RMarkdown, so you can include executable R code in each post.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;blogdown&lt;/code&gt; creates your site using the &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; framework.
Hugo is software that can build static websites (i.e., ones that can be
served to viewers without needing database backends or other fancy things).
People have created different templates for Hugo-generated websites, and these
templates provide the structure and framework, while you can adapt the content.&lt;/p&gt;
&lt;p&gt;This means that our website (which is, essentially, a collection of files in
a directory written in a form that a web browser can convert to a pretty
website) includes a lot of files and code that come straight from a template
that someone else wrote, and then places here and there where we can add or
change the files to make the website ours.&lt;/p&gt;
&lt;p&gt;One of the ways that you can change the website is to add posts. You’ll be
doing this later in the course by contributing two blog posts of your own,
one on the vocabulary for a chapter and one with the “official” version of
the exercise for a chapter. We’ll cover more on how to add a blog post later
in the course.&lt;/p&gt;
&lt;p&gt;The other way that you can change the website is to change some of its
“front page” data. The website has a section on “People”, with the
profiles of everyone in the class. The information shown in this section
is all saved in plain text files in our website’s file directory. Today,
you’ll change you details in the file dedicated to you and then send those
changes back to us so we can update the online version of the site.&lt;/p&gt;
&lt;p&gt;You will need to install two pieces of software to work on our
website. First, you’ll need the R package &lt;code&gt;blogdown&lt;/code&gt;. You can install
this package in the normal way, using &lt;code&gt;install.packages&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;blogdown&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you have &lt;code&gt;blogdown&lt;/code&gt;, you can install the Hugo software using a function
in the &lt;code&gt;blogdown&lt;/code&gt; package, &lt;code&gt;install_hugo&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(blogdown)
install_hugo()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For both these installations, your computer will need to be online or you’ll
get an error.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-a-fork-of-our-repository-on-your-computer&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting a fork of our repository on your computer&lt;/h1&gt;
&lt;p&gt;All our websites files are posted in a GitHub repository at &lt;a href=&#34;https://github.com/geanders/csu_msmb&#34; class=&#34;uri&#34;&gt;https://github.com/geanders/csu_msmb&lt;/a&gt;. With this (or any) GitHub repository,
you can suggest changes by &lt;strong&gt;forking&lt;/strong&gt; the repository, cloning the fork to
your computer, making and committing the changes, pushing those commits
back up to your fork of the repository on GitHub, and then submitting
a &lt;strong&gt;pull request&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;forking-a-github-repository&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Forking a GitHub repository&lt;/h2&gt;
&lt;iframe src=&#34;https://giphy.com/embed/3o6fJ8baw3aDgUQnJu&#34; width=&#34;480&#34; height=&#34;240&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;
&lt;/iframe&gt;
&lt;p&gt;
&lt;a href=&#34;https://giphy.com/gifs/thegoodplace-season-2-nbc-3o6fJ8baw3aDgUQnJu&#34;&gt;via GIPHY&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;When you &lt;strong&gt;fork&lt;/strong&gt; a GitHub repository, you get a copy of that repository that you
can play around with and change yourself, without it affecting the original
repository. It’s essentially just copying the whole repository, with all its
files, into a repository on your GitHub account.&lt;/p&gt;
&lt;p&gt;The only thing that makes it different from a plain copy (and what makes it
really powerful in some cases) is that, if you decide that your changes might
make the &lt;em&gt;original&lt;/em&gt; repository better, you can submit a &lt;strong&gt;pull request&lt;/strong&gt;. This
requests that the owners of the original repository update it to incorporate the
changes you’ve made on your fork of the repository. The original authors can
review each of the &lt;strong&gt;commits&lt;/strong&gt; you’ve made, so they can even cherry-pick your
changes if they want.&lt;/p&gt;
&lt;p&gt;GitHub also lets the original authors see if there are any &lt;strong&gt;merge conflicts&lt;/strong&gt;
created from changes that they’ve made to the original repository since you
forked it. This can let the original authors see how hard it will be to
incorporate all of your changes in the forked version with their version of the
repository.&lt;/p&gt;
&lt;p&gt;To fork the repository with our course’s website materials, all you’ll need to
do is go to our &lt;a href=&#34;https://github.com/geanders/csu_msmb&#34;&gt;GitHub repository for the course
website&lt;/a&gt; (while you’re signed in to
GitHub) and click on the “Fork” button towards the right of the page. Now go and
check in the “Repositories” section of your own GitHub account—you should see that
you now have a forked copy of the “csu_msmb” repository.&lt;/p&gt;
&lt;p&gt;In this exercise, you’ll work with the fork of the repository, and then once you’ve
made your changes, you submit a pull request, so that we can get your changes
back into the main webpage.&lt;/p&gt;
&lt;p&gt;If you need more help on how to fork a repository, GitHub has a &lt;a href=&#34;https://help.github.com/en/github/getting-started-with-github/fork-a-repo&#34;&gt;help
page&lt;/a&gt;
on the topic that might be useful.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cloning-the-fork-to-your-computer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cloning the fork to your computer&lt;/h2&gt;
&lt;p&gt;Next, you’ll want to get a copy of your forked repository onto your own computer,
where you can work with it, make changes, and preview the website with your
updates.&lt;/p&gt;
&lt;p&gt;To do this, you’ll &lt;strong&gt;clone&lt;/strong&gt; your fork of the repository onto your computer.
The version of the repository on GitHub is called the &lt;strong&gt;remote&lt;/strong&gt; branch of the
repository and the version you get on your computer once you’ve cloned it is
the &lt;strong&gt;local&lt;/strong&gt; branch. By cloning (instead of just downloading), you’ll maintain
a connection between the remote and local versions through git, which will allow
you to push changes that you make and commit on your own computer up to the
remote branch on GitHub.&lt;/p&gt;
&lt;p&gt;Go to GitHub, make sure you are logged into your account, and navigate to your
forked version of the repository for this class. There should be a button to the
right of the page that says “Clone or download” (you may need to scroll down to
find it).&lt;/p&gt;
&lt;p&gt;When you click on this button, it will give you a choice between
“SSH” and “HTTPS” for the protocol to use to connect your local and remote branches
of the repository. You’re welcome to try either, but I usually (on a Mac) have
better luck with “SSH”. Occasionally, people running Windows in my courses have
had better luck with “HTTPS”, although for most folks “SSH” seems to work fine.
Once you choose which protocol to use, you can copy the snippet of code that is
given in the pop-up.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/github_clone_button.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next, you’ll run this code from a &lt;strong&gt;bash shell&lt;/strong&gt; on your own computer to clone the
repository. You first will need to open a shell. If you’re on a Mac, you can do that
with the “Terminal” application. With Windows, you’ll probably need to use the
bash shell that comes with the Windows version of git. Search your programs for
“bash” or “git bash” and see if you see something that looks promising.&lt;/p&gt;
&lt;p&gt;Once you open a shell, you’ll see a command prompt, like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;username$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can type &lt;strong&gt;shell commands&lt;/strong&gt; here and then press “Return” to run them. You
should first move into the directory where you want to clone the repository.
Your “Desktop” might be a good place for it for now (unless you have some
organization you use for course-related files). The &lt;code&gt;cd&lt;/code&gt; shell command lets you
“change directory”. If you don’t put anything after &lt;code&gt;cd&lt;/code&gt;, it will change to
your &lt;strong&gt;home directory&lt;/strong&gt;. Otherwise, it will move to the directory you specify.
For example, if the “Desktop” directory is a subdirectory of my home directory,
I could move into it by running:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;cd Desktop&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have not use shell commands much before and are having any problems
navigating to the directory you’d like, let us know in class, and one of us can
help you.&lt;/p&gt;
&lt;p&gt;Once you are in this directory, you’ll paste &lt;code&gt;git clone&lt;/code&gt; followed by the command
you copied from the “Clone or download” button on GitHub. It will probably look
something like this (but with your GitHub handle in place of “geanders”):&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git clone git@github.com:geanders/csu_msmb.git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/bash_clone_git_repo.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When you run this, you may have to put in your GitHub username and password. You
may also get some questions about whether you really want to download the
repository (you do). If everything’s successful, you should see that there’s a new
directory called “csu_msmb” in which directory you decided to put it (“Desktop”,
for example).&lt;/p&gt;
&lt;p&gt;This directory has a special file in it that makes it an &lt;strong&gt;R Project&lt;/strong&gt;—a special
version of a file directory with some extra structure and saved preferences. Make
sure that you open the project as a whole when you work on it in R Studio, rather than
opening just by clicking on one of the files. To do this, you can go in R Studio
to &lt;code&gt;&#34;File&#34;&lt;/code&gt; -&amp;gt; &lt;code&gt;&#34;Open Project...&#34;&lt;/code&gt; and then navigate through your file directory
to the “csu_msmb” directory you just cloned.&lt;/p&gt;
&lt;p&gt;If you need more help, GitHub has a &lt;a href=&#34;https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository&#34;&gt;help
page&lt;/a&gt;
with more on how to clone a repository from GitHub to your own computer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;changing-and-committing-in-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Changing and committing in RStudio&lt;/h2&gt;
&lt;p&gt;When you have R Studio open to an R Project that is using git version control,
R Studio will include a “Git” pane. You can use this pane to &lt;strong&gt;commit&lt;/strong&gt; changes you
make to files in the repository, write messages explaining those commits, and
&lt;strong&gt;push&lt;/strong&gt; your changes to your remote branch of the repository on GitHub.&lt;/p&gt;
&lt;p&gt;When you commit a change, that change is written into a log of every change made
to the files in the repository. You can later look through these commits, so you’ll
want the commit messages to make sense when you read them in the future. When you’re
collaborating with others, the commit messages will help you see what each other
are doing.&lt;/p&gt;
&lt;p&gt;When you first commit a change, the commit is only saved in your local branch.
To send it up to the remote branch of the repository on GitHub, you’ll need to
&lt;strong&gt;push&lt;/strong&gt; those commits. Once you push your local commits, your GitHub repository
should exactly mirror your local repository.&lt;/p&gt;
&lt;p&gt;As soon as you make a change to a file in the repository that’s being track by
git, that file will show up in the Git pane, with a little check box beside it.
When you’re ready to commit a change, click on the “Commit” button on the top left
of the Git pane. This will open a pop-up box.&lt;/p&gt;
&lt;p&gt;In this box, click the check boxes for all the changed files on the left you’d
like to include in the commit. Then write a short &lt;strong&gt;commit message&lt;/strong&gt;, describing
the changes you’ve made. You should try to fit it all in the first line of the
“commit message” window. If you can’t, write a short description in the first line,
skip a line, and then you can write as much as you want.&lt;/p&gt;
&lt;p&gt;Once you’ve written your commit message, click on the “commit” button. This will
record this commit. To check that it has, you can go to the “History” tab and
make sure the commit shows up as the last thing in your history.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/committing.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;updating-your-profile-details&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Updating your profile details&lt;/h1&gt;
&lt;div id=&#34;rendering-blogdown-websites-in-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rendering blogdown websites in RStudio&lt;/h2&gt;
&lt;p&gt;Once you’ve opened the R Project with our website, you can use the
&lt;code&gt;blogdown&lt;/code&gt; package to serve the website. This will &lt;em&gt;only&lt;/em&gt; update and
show the website on your computer (&lt;em&gt;not&lt;/em&gt; change our main website online),
but it lets you check that everything’s working and preview what the
site will look like online.&lt;/p&gt;
&lt;p&gt;RStudio’s “Viewer” pane can work as a &lt;strong&gt;web browser&lt;/strong&gt;. This means that it can
show our website. When you have opened the R Project with the cloned
repository of our website (“csu_msmb”), try running the following in your
R console to render the site:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(blogdown)
serve_site()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/serve_site.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If everything worked, you should be able to see a version of the website in your
RStudio “Viewer” pane. If you’d like to see it in your usual web browser, click
on the “Show in new window” button on the top left of the “Viewer” pane (this
looks like a little rectangle with an arrow on it). This will open the website
in your default web browser.&lt;/p&gt;
&lt;p&gt;Take a look at the web address when you do—it should start with &lt;code&gt;127.0.0.1&lt;/code&gt;.
This is a &lt;strong&gt;loopback address&lt;/strong&gt;—an IP address that refers back to your local
computer (&lt;strong&gt;localhost&lt;/strong&gt;), rather than an outside web servers. Anytime you’re
building a website and checking it locally, you’ll see this in the web address
when you open the site in a web browser. (You can even &lt;a href=&#34;https://www.amazon.com/Theres-Place-127-0-0-1-Address-Geek/dp/B07PF54LYT/ref=pd_sbs_193_t_0/134-9564811-5189968?_encoding=UTF8&amp;amp;pd_rd_i=B07PF54LYT&amp;amp;pd_rd_r=8bcd759f-27a2-443f-a9b8-596744041403&amp;amp;pd_rd_w=hzmrB&amp;amp;pd_rd_wg=nlhQV&amp;amp;pf_rd_p=5cfcfe89-300f-47d2-b1ad-a4e27203a02a&amp;amp;pf_rd_r=S0HM3N9YTGK1JXEK2H3T&amp;amp;psc=1&amp;amp;refRID=S0HM3N9YTGK1JXEK2H3T&#34;&gt;get T shirts with “There’s no place like
127.0.0.1”&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;As you work through the next parts of the exercise, the rendered website in the
Viewer pane should update every time you save your changes to files in the
website. If you have the website open in your default browser, too, you might
want to refresh the site with the normal “Refresh” button for your browser.
If things ever seem like they’ve gotten out of sink, you can always re-run
&lt;code&gt;serve_site()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;navigating-the-websites-file-directory-to-find-your-profile&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Navigating the website’s file directory to find your profile&lt;/h2&gt;
&lt;p&gt;We all have our own author profile in a subdirectory within the
website’s files. To find yours, go to the “content” subdirectory
of the website files and then the “authors” subdirectory within that.
You should see a subdirectory there with your name. Click on that
and you’ll see the two files that make up your author profile,
&#34;_index.md&#34; and “avatar.jpg”.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/navigating_to_profile.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;updating-your-information-in-_index.md&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Updating your information in &#34;_index.md&#34;&lt;/h2&gt;
&lt;p&gt;Your details are all given in the &#34;_index.md&#34; file in your author subdirectory.
To update your details on the website, you’ll need to change your details in this
file.&lt;/p&gt;
&lt;p&gt;The file is written in a Markup language called &lt;strong&gt;YAML&lt;/strong&gt;. If you’ve used RMarkdown
before, you might recognize this syntax from the information that goes at the
very top of each RMarkdown file.&lt;/p&gt;
&lt;p&gt;In your &#34;_index.md&#34; file, anywhere there is a placeholder, like “[Year]”
or “[Institution]”, replace the placeholder with your own information.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/change_placeholders.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Be very careful when changing things like spaces and hyphens in the structure,
as YAML is based on parsing these elements. As with any Markup language, as
you are learning it, it’s best to try to render the final document often as
you make changes, so you can make sure the changes make it through like you want
and so you can catch any problems quickly.&lt;/p&gt;
&lt;p&gt;Make sure you change the following sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bio:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;education:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;email:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;interests:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name:&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;organizations:&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of the sections in &lt;code&gt;social:&lt;/code&gt; are commented out, including the information
for buttons for GitHub, GoogleScholar, and Twitter. If you have accounts through
any of these services, you can add these buttons with your updated information.
Just delete the &lt;code&gt;#&lt;/code&gt; at the beginning of all lines in that section and then
change the handle or web address information so that it links to your
account for that service. In this section, also update your email address, with
&lt;code&gt;mailto:&lt;/code&gt; at the beginning, for the email icon.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/update_social_section.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The very bottom of the file, under the &lt;code&gt;---&lt;/code&gt;, provides space for you to write
a paragraph summarizing who you are and your academic / research interests.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/screencapture_gifs/add_summary_paragraph.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Be sure to save the file after you’ve made all your changes.&lt;/p&gt;
&lt;p&gt;For an example of a completed &#34;_index.md&#34; file, you can see mine &lt;a href=&#34;https://raw.githubusercontent.com/geanders/csu_msmb/master/content/authors/brooke-anderson/_index.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;updating-your-avatar-picture&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Updating your avatar picture&lt;/h2&gt;
&lt;p&gt;There’s also a place in your author profile directory to include a photo to
represent yourself. To change from the default (the blue guy), replace the
“avatar.jpg” file in your author profile directory with the JPG of your choice,
and use &lt;em&gt;the same file name&lt;/em&gt; (“avatar.jpg”).&lt;/p&gt;
&lt;p&gt;It would be helpful for you to use a photo of yourself, since that will help
us put names with faces, but if you don’t have one or would prefer
not to use your own photo, feel free to pick any photo (for which you have
appropriate permissions) to use.&lt;/p&gt;
&lt;p&gt;You might need to crop your photo some to get it to show up in the circle on
the website correctly. Try with your uncropped picture once, check the website
in the RStudio Viewer pane to see how it looks, and then if it doesn’t work,
play around with cropping it until you’re happy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;submitting-your-updates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Submitting your updates&lt;/h1&gt;
&lt;div id=&#34;pushing-the-commits-back-to-github&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pushing the commits back to GitHub&lt;/h2&gt;
&lt;p&gt;When you are ready to push all the changes you’ve committed to your local branch, you can
do this from the Git pane in R Studio. In this pane, there are two arrows: a green up
arrow and a blue down arrow. Click on the green up arrow to push the commits from your
computer (the local branch) to GitHub (the remote branch). Visit your GitHub page for
the repository (or refresh it if you already had it open) and check if your changes
have successfully been pushed to the remote branch.&lt;/p&gt;
&lt;p&gt;If you haven’t created an SSH key and shared it with GitHub, you may be asked
for your GitHub password every time you try to push. This will get to be a pain,
so you’ll probably want to set up an SSH key. For more on how to do this (as
well as other help with using RStudio with version control), check out
&lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/200532077-Version-Control-with-Git-and-SVN&#34;&gt;RStudio’s help documentation on the
topic&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;requesting-that-we-pull-your-changes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Requesting that we pull your changes&lt;/h2&gt;
&lt;iframe src=&#34;https://giphy.com/embed/B6ZOD3aNT3Lxe&#34; width=&#34;480&#34; height=&#34;284&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;
&lt;/iframe&gt;
&lt;p&gt;
&lt;a href=&#34;https://giphy.com/gifs/cats-bowl-pull-B6ZOD3aNT3Lxe&#34;&gt;via GIPHY&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;At this point, you’ve made changes, checked them, and pushed them to your GitHub version of
the repository. Remember, though, that you forked the repository from our original one, and
so you’ve been working with a copy of the repository this whole time, rather than changing
our original version.&lt;/p&gt;
&lt;p&gt;To get your changes incorporated into our original version, you’ll need to request that we
&lt;strong&gt;pull&lt;/strong&gt; your changes into the original repository. To do this, you can submit a &lt;strong&gt;pull request&lt;/strong&gt;
through GitHub. Go to the main page for your fork of the GitHub repository and look for
a button that says “New pull request”. When you click this, it will walk you through making
a pull request. You’ll have a space to write a message describing the changes you’re
recommending in the pull request.&lt;/p&gt;
&lt;p&gt;If you’d like more details on this information, GitHub has &lt;a href=&#34;https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request&#34;&gt;help documentation
on pull
requests&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Vocabulary for Chapter 1</title>
      <link>/post/vocabulary-for-chapter-1/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/post/vocabulary-for-chapter-1/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Chapter 1 covers generative modeling for discrete data. It introduces a number of terms covering
probablity and statistical modeling, as well as a few biological terms. The vocabulary words for
Chapter 1 are:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
probability model
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A mathematical description of the possible outcomes of an experiment and the probability of each of those outcomes.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
vector
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In programming, a one-dimensional array of data, all with the same data type.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
discrete event
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In statistics, an event that can take a finite or countable number of values (e.g., number of deaths in a community by day).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
categorical variable
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A variable that can belong to one of a finite set of levels.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
levels
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of a categorical variable, the set of values to which the variable can be assigned.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
factor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of statistical programming, a data type that can take one of a limited number of possible values (e.g., sex, nationality).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
exchangeable
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A property of a vector of random variables that implies the order in which the variables appear in the vector doesn’t matter.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
sufficient statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A (summary) statistic that contains all the information about the model parameters that is in the original, uncondensed form of the data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bernoulli distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A probability distribution describing a random variable that can take on two possible outcomes (e.g., win / loss).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
parameter
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A numerical value that describes a population.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
complementary
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A description of two events who are mutually exclusive and whose probabilities sum to one (i.e., either one event or the other is guaranteed to happen, but not both).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
binomial random variable
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A variable whose values occur according to a binomial probability distribution.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
probability mass distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A function giving the probability that a discrete random variable is equal to a given value.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Poisson distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A probability distribution for count data that has support on the non-negative integers. This distribution is also used to approximate a binomial distribution when the probability of success is small and the number of trials is large.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
epitope / antigen determinent
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Site on a macromolecular antigen to which an antibody binds. This is the part of an antigen that is recognized by the immune system.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Enzyme-linked immunosorbent assay (ELISA)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An assay that is used to detect specific epitopes at different positions along a protein.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
conditional on
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Given
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
cumulative distribution function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A function giving the probability that a random variable is less than any specified value.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
extreme value analysis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Analysis focused on the behavior of the very large or the very small outcomes of a random distribution, allowing an exploration of the probability of rare events.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rare event
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Something that occurs with a very low probability.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
rank statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A data vector sorted least to greatest.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Monte Carlo method
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method that uses computer simulation from a generative model to determine probabilities of events.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
probability or generative modeling
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of modeling where all the parameters are known and the mathematical theory allows us to work by deduction.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
deduction
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A top-down method of reasoning, starting from a theory or principle rather than from data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
statistical modeling
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A method of modeling where the distribution of the data is not known.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
fit
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of statistical modeling, estimating the parameters of a model based on observed data.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
multinomial
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A generalization of the binomial distribution to cases where there are a finite set of possible outcomes (e.g., a roll of a die).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
power / true positive rate
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The probability of detecting something if it is there.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
null hypothesis
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Often, a hypothesis of “no association” that is used as a counterpart to a more interesting alternative hypothesis in hypothesis testing.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
matrix
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In programming, a two-dimensional array of data, all with the same data type.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
expected value
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The average (mean) value of a random variable.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
variability / spread / dispersion
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In statistics, the amount by which a set of observations deviate from their mean.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
statistic
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A numerical characteristic of a sample and known constants (i.e. no unknown parameters).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
null distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The probability distribution under the null hypothesis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
alternative
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of a generating process and hypothesis testing, the generating process that is considered in comparison to the generating process under the null hypothesis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
chi-squared distribution
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A distribution on the non-negative real numbers that is often used in assessing goodness-of-fit (e.g. models fit to contingency tables).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
p-value
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The probability of seeing the observed data or something more extreme under the generative model associated with the null hypothesis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
probability density function
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A function giving the relative likelihood that a continuous random variable is equal to a given value. When this function is integrated over the sample space, it equals 1.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
default
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of arguments to an R function, the value that is used if no custom value is specified.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
C. elegans genome nucleotide frequency
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
How often adenine, cytosine, guanine, and thymine occur in the DNA of a roundwork often used in scientific research.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
Bioconductor
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Open-source software that provides contributed programs for bioinformatic data analysis.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
codon
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A three-nucleotide sequence that specifies the amino acid to be created next (or to start or stop synthesis).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
DNA read
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An inferred sequence of base pairs for a single DNA fragment, based on sequencing.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
nucleotide
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In the context of DNA, one of four compounds (adenine (A); cytosince (C); guanine (G); and tymine (T)) that make up the basic information unit.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
genome
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
An organism’s complete set of DNA, including all of its genes.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
replication cycle
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
In biology, the process that begins with the infection of a host cell by a virus and ends with the release of mature progeny virus particles.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
point mutation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A change, addition, or deletion of a single nucleotide in a gene sequence.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
genotype
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
The genetic make-up of an individual’s cells, including how the individual’s genetic make-up differs from others’.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
diploid
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
Having genetic material in two complete sets of chromosomes, from two parents.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
protein
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A compound made up of amino acids; one of the four types of macromolecules that make up living organisms.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
antibody
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A type of protein made by certain white blood cells in response to an antigen.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;font-weight: bold;border-right:1px solid;&#34;&gt;
antigen
&lt;/td&gt;
&lt;td style=&#34;text-align:left;width: 30em; &#34;&gt;
A foreign substance in the body to which the immune system reacts.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;sources-consulted-or-cited&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sources consulted or cited&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some of the definitions above are based in part or whole on listed definitions
in the following sources.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Holmes and Huber, 2019. &lt;em&gt;Modern Statistics for Modern Biology.&lt;/em&gt; Cambridge University Press,
Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Everitt and Skrondal, 2010. &lt;em&gt;The Cambridge Dictionary of Statistics (Fourth Edition).&lt;/em&gt; Cambridge University Press, Cambridge, United Kingdom.&lt;/li&gt;
&lt;li&gt;Bioconductor: Open Source Software for Bioinformatics. &lt;a href=&#34;https://www.bioconductor.org/&#34; class=&#34;uri&#34;&gt;https://www.bioconductor.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wikipedia: The Free Encyclopedia. &lt;a href=&#34;https://en.wikipedia.org/wiki/Main_Page&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Main_Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NIH Genetics Home Reference. &lt;a href=&#34;https://ghr.nlm.nih.gov/&#34; class=&#34;uri&#34;&gt;https://ghr.nlm.nih.gov/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NCI Dictionary of Cancer Terms. &lt;a href=&#34;https://www.cancer.gov/publications/dictionaries/cancer-terms&#34; class=&#34;uri&#34;&gt;https://www.cancer.gov/publications/dictionaries/cancer-terms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;practice&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Practice&lt;/h3&gt;
&lt;iframe src=&#34;https://quizlet.com/473473135/flashcards/embed?i=2ldef3&amp;amp;x=1jj1&#34; height=&#34;500&#34; width=&#34;100%&#34; style=&#34;border:0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
