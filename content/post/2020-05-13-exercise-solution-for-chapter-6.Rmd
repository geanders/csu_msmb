---
title: Exercise Solution for Chapter 6
author: Sherry WeMott
date: '2020-05-13'
slug: exercise-solution-for-chapter-6
categories:
  - Chapter 6
  - exercises
tags:
  - Chapter 6
  - exercises
subtitle: ''
summary: ''
authors: []
lastmod: '2020-05-13T20:48:35-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

## Chapter 6, Exercise 6.4

>Make a less extreme example of correlated test statistics than the data duplication at the end of Section 6.5. Simulate data with true null hypotheses only, and let the data morph from having completely independent replicates (columns) to highly correlated as a function of some continuous-valued control parameter. Check type-I error control (e.g., with the p-value histogram) as a function of this control parameter.

We'll go through a few data clean up and exploration steps first, then we'll walk through the code related specifically to the exercise a little further down in the post. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=F, message=F, warning=F}
library(tidyverse)
library(purrr)
library(ggbeeswarm)
```

For this exercise we use the PlantGrowth dataset from the `datasets` package in R. The dataset includes results from an experiment on plant growth comparing yields (as measured by dried weight of plants) obtained under a control and two different treatment conditions. 

```{r}
data("PlantGrowth")
head(PlantGrowth)
```

Here we're plotting the outcomes of the three groups (`ctrl`, `trt1`, and `trt2`)

```{r fig.height = 2, fig.width = 3, fig.align = "center"}
PlantGrowth %>% 
   mutate(group = fct_recode(group, 
                            Control = "ctrl", 
                            `Treatment 1` = "trt1", 
                            `Treatment 2` = "trt2")) %>% 
  ggplot(aes(x = group, y = weight)) + 
  geom_beeswarm() + 
  labs(x = "")
```
Often in research one of the simplest comaparisons of data we can make is between two groups. The t-test is one of the many statistics used in hypothesis testing and can help us determine if the differences between two group means is "significant" or if the differences could have happened by chance. The test statistic is defined as: 

$t=c\frac{m^1-m^2}{s}$

Next we'll apply a t-test comparing weights in the `ctrl` group to the `trt2` group. We're testing against the null hypothesis that there is no difference in mean dried plant weights between the two groups. 

```{r}
PlantGrowth %>% 
  filter(group %in% c("ctrl", "trt2")) %>% 
    t.test(weight ~ group, data  = .) 
```
Here's the tidy version: 

```{r}
library("broom")
PlantGrowth %>% 
  filter(group %in% c("ctrl", "trt2")) %>% 
  t.test(weight ~ group, data  = .) %>% 
    tidy()
```

Then we'll duplicate the data, adding a second copy of the dataframe, before running the t-test. Notice that the p-value is smaller (now less than 0.05) even though the group means haven't changed. This is due solely to the increase in sample size. 

However, we've violated the t-test assumption of independence. Paired or duplicated data is dependent and would be more appropriately tested by a two-sample paired test. If the data sampled for a t-test violates one or more of the t-test assumptions, such as independence or normal distribution, results can be incorrect and misleading. 

```{r}
PlantGrowth %>% 
  bind_rows(PlantGrowth) %>% # Add the duplicate of the dataset
  filter(group %in% c("ctrl", "trt2")) %>% 
  t.test(weight ~ group, data  = .) %>% 
  tidy()
```

Here we resample only half the data; so the size of the data set is the same as the original dataset (n = 30), but now half of the observations are fully dependent (exactly the same) as other observations in the dataset. The p-value increases from 0.004 with a fully duplicated dataset to 0.423 with half the data duplicated.  

```{r}
PlantGrowth %>% 
  sample_frac(size = 0.5) %>% 
  bind_rows(., .) %>% 
  filter(group %in% c("ctrl", "trt2")) %>% 
  t.test(weight ~ group, data  = .) %>% 
  tidy()
```
Permutation test data resample to check Type 1 error control: 
```{r}
pg1 <- PlantGrowth %>% 
  sample_frac(size = 0.5) 

pg1_null = with(
  dplyr::filter(pg1, group %in% c("ctrl", "trt2")),
    replicate(10000,
      abs(t.test(weight ~ sample(group))$statistic)))

ggplot(tibble(`|t|` = pg1_null), aes(x = `|t|`)) +
  geom_histogram(binwidth = 0.1, boundary = 0)
```
Now we'll take the dataset with half resampled, and add random noise to each observation. 

```{r}
pg2 <- pg1 %>% 
  mutate(noise = rnorm(15, mean = 0, sd = 0.2), 
         weight = weight + noise) %>% 
  select(-noise)
pg2

pg1 %>% 
  bind_rows(pg2) %>% 
  filter(group %in% c("ctrl", "trt2")) %>% 
  t.test(weight ~ group, data  = .) %>% 
  tidy()
```



Permutation test data with half duplicated and random noise added:

```{r}
pg2_null = with(
  dplyr::filter(pg2, group %in% c("ctrl", "trt2")),
    replicate(10000,
      abs(t.test(weight ~ sample(group))$statistic)))

ggplot(tibble(`|t|` = pg2_null), aes(x = `|t|`)) +
  geom_histogram(binwidth = 0.1, boundary = 0)  

```

```{r}
library(kableExtra)
data <- c('original', 'doubled without random noise', 'same size as original, half observations replicated', 'half replicated, random noise added to each replicate')
n <- c(30, 60, 30 ,30)
test_statistic <- c(-2.13, -3.1, -3.03, -0.72)
p_value <- c(0.479, 0.003, 0.009, 0.48)
data_summary <- data.frame(data, n, test_statistic, p_value)
data_summary %>% 
   kable(align = c("l")) %>% 
  kable_styling(bootstrap_options = c("striped", "hover",
                                      "condensed")) %>% 
  column_spec(1, bold = T, border_right = T) %>% 
  column_spec(2:3, width = "6em")


```
