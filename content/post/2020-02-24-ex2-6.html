--- 
title: Exercise solution for Chapter 2, Part 2
author: Sarah Cooper
date: '2020-02-24'
slug: ex-2-6
categories: 
  - exercises
  - Chapter 2
tags: 
  - exercises
  - Chapter 2
subtitle: ''
summary: ''
authors: [sarah-cooper]
lastmod: '2020-02-24T2klo:16:10-07:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div id="exercise-2.6" class="section level1">
<h1>Exercise 2.6</h1>
<p>The first part of the exercise asks you to:</p>
<blockquote>
<p>Choose your own prior for the parameters of the beta distribution. You can do this by sketching it here: <a href="https://jhubiostatistics.shinyapps.io/drawyourprior" class="uri">https://jhubiostatistics.shinyapps.io/drawyourprior</a>.</p>
</blockquote>
<p>After sketching a plot, I chose the parameters to set up a prior: <span class="math inline">\(\alpha\)</span> = 2.47 and <span class="math inline">\(\beta\)</span> = 8.5.</p>
</div>
<div id="using-this-prior" class="section level1">
<h1>Using this prior</h1>
<p>Next, the exercise asks you:</p>
<blockquote>
<p>Once you have set up a prior, re-analyse the data from Section 2.9.2, where we saw Y = 40 successes out of n = 300 trials.</p>
</blockquote>
<p>To be able to use the <code>loglikelihood</code> function from the text, I first needed to redefine it here:</p>
<pre class="r"><code>loglikelihood = function(theta, n = 300, k = 40) { ## Function definition from the textbook
  log(choose(n, k)) + k * log(theta) + (n - k) * log(1 - theta)
}</code></pre>
<p>Then, I created a vector of <span class="math inline">\(\theta\)</span> values between 0 and 1, spaced 0.001 units wide. The plot below shows different possible values of <span class="math inline">\(\theta\)</span> and the log likelihood for each of these values:</p>
<pre class="r"><code>thetas = seq(0, 1, by = 0.001)
plot(thetas, loglikelihood(thetas), xlab = expression(theta),
     ylab = expression(paste(&quot;log f(&quot;, theta, &quot; | y)&quot;)),type = &quot;l&quot;)</code></pre>
<p><img src="/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Next, I used <code>rbeta</code> to draw 1,000,000 random samples from a beta distribution with my new picks for the parameters for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>:</p>
<pre class="r"><code>rtheta = rbeta(1000000, shape1 = 2.47, shape2 = 8.5)</code></pre>
<p>After running the above, for each of these <span class="math inline">\(\theta\)</span> values, we then generate a random sample of <span class="math inline">\(Y\)</span> as observed in the histogram (with orange bars):</p>
<pre class="r"><code>y = vapply(rtheta, function(th) {
  rbinom(1, prob = th, size = 300)
}, numeric(1))
hist(y, breaks = 50, col = &quot;orange&quot;, main = &quot;&quot;, xlab = &quot;&quot;)</code></pre>
<p><img src="/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Our next step is to use this information to generate a posterior distribution of <span class="math inline">\(\theta\)</span> at a fixed <span class="math inline">\(Y\)</span> value. In this example they used <span class="math inline">\(Y=40\)</span>.</p>
<p>After running the above, for each of these thetas, we generated simulated values for the posterior distribution of <span class="math inline">\(\theta\)</span> at <span class="math inline">\(Y=40\)</span> as observed in this histogram (with green bars).</p>
<pre class="r"><code>thetaPostEmp = rtheta[ y == 40 ]
hist(thetaPostEmp, breaks = 40, col = &quot;chartreuse4&quot;, main = &quot;&quot;,
     probability = TRUE, xlab = expression(&quot;posterior&quot;~theta), ylim=c(0,40))</code></pre>
<p><img src="/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>densPostTheory  =  dbeta(thetas, 42.47, 268.5)</code></pre>
<p>You can check how this compares to the theoretical posterior distribution
for <span class="math inline">\(\theta\)</span> at <span class="math inline">\(Y = 40\)</span>:</p>
<pre class="r"><code>hist(thetaPostEmp, breaks = 40, col = &quot;chartreuse4&quot;, main = &quot;&quot;,
  probability = TRUE, xlab = expression(&quot;posterior&quot;~theta))
lines(thetas, densPostTheory, type=&quot;l&quot;, lwd = 3)</code></pre>
<p><img src="/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We can also check the means of both distributions computed above.</p>
<pre class="r"><code>mean(thetaPostEmp) # Empirical</code></pre>
<pre><code>## [1] 0.1365518</code></pre>
<pre class="r"><code>dtheta = thetas[2]-thetas[1]
sum(thetas * densPostTheory * dtheta) # Theoretical</code></pre>
<pre><code>## [1] 0.1365727</code></pre>
<div id="monte-carlo-integration" class="section level2">
<h2>Monte Carlo integration</h2>
<p>We can use Monte Carlo integration instead and then check the agreement between our Monte Carlo sample <code>thetaPostMC</code> and our sample <code>thetaPostEmp</code> with a QQ plot:</p>
<pre class="r"><code>thetaPostMC = rbeta(n = 1e6, 42.47, 268.5)
mean(thetaPostMC)</code></pre>
<pre><code>## [1] 0.1365943</code></pre>
<pre class="r"><code>qqplot(thetaPostMC, thetaPostEmp, type = &quot;l&quot;, asp = 1)
abline(a = 0, b = 1, col = &quot;blue&quot;)</code></pre>
<p><img src="/post/2020-02-24-ex2-6_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>densPost2 = dbeta(thetas, 42.47, 268.5)
mcPost2   = rbeta(1e6, 42.47, 268.5)
sum(thetas * densPost2 * dtheta)  # mean, by numeric integration</code></pre>
<pre><code>## [1] 0.1365727</code></pre>
<pre class="r"><code>mean(mcPost2)                     # mean, by MC</code></pre>
<pre><code>## [1] 0.1365695</code></pre>
<pre class="r"><code>thetas[which.max(densPost2)]      # MAP estimate</code></pre>
<pre><code>## [1] 0.134</code></pre>
<pre class="r"><code>quantile(mcPost2, c(0.025, 0.975))</code></pre>
<pre><code>##      2.5%     97.5% 
## 0.1007354 0.1769548</code></pre>
</div>
</div>
